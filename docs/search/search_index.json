{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Compression of Voxel Models This is the documentation of my research project at TU Dresden. This documentation was written using MkDocs . Warning You can browse this offline by hosting it as a static web page on a local server. Many functions such as searching or syntax highlighting won't work when opening this project with a file:// scheme. To name an example, use python3 -m http.server 8000 in the root directory to host this page locally on port 8000.","title":"Compression of Voxel Models"},{"location":"index.html#compression-of-voxel-models","text":"This is the documentation of my research project at TU Dresden. This documentation was written using MkDocs . Warning You can browse this offline by hosting it as a static web page on a local server. Many functions such as searching or syntax highlighting won't work when opening this project with a file:// scheme. To name an example, use python3 -m http.server 8000 in the root directory to host this page locally on port 8000.","title":"Compression of Voxel Models"},{"location":"cuboid_extraction.html","text":"Cuboid Extraction Motivation Voxel models of certain types have large volumes of voxels. These types include extruded heightmaps, medical scans, video game worlds and voxel art. Other types such as voxelized polygonal models may also be filled up instead of being kept hollow. The volumes may often be misaligned with the octree structure. Consider a single 2x2x2 cube in the center of an octree. All 8 subtrees of the octree would have to encode an individual voxel of this cube, which is far from optimal. In addition, decoding volumes which are completely filled simplifies the decoding process. These volumes could be extracted and encoded as cuboids like {triple<u8> pos, triple<u8> size} within a container that has dimensions up to 256^3. However we extract cuboids, those should be as large in volume as possible. This way, we cover the most voxels with our pairs of positions. The highest-volume container should be found, then extracted and the next-highest-volume container found, etc. We invest 6 bytes into the extraction, so our volume needs to be 48 to break even (e.g. 4x4x3 ). Absolutely Stupid Method extreme complexity but optimal results Since a cuboid is just a pair of positions, we can simply iterate over all pairs of positions. We then iterate over all voxels in the cuboid to test whether they exist. For a d*d*d model containing v voxels the complexity is thus O(d^3 * d^3 * d^3) or O(d^9) or O(v^3) . This is some clown-world-tier complexity and should not find its way into any serious implementation. Due to its simplicity, it could be used to verify the correctness of more complex approaches though. XYZ-Merge best possible complexity not optimal An XYZ-merge works by merging all neighboring voxels into lines on one axis first. Then neighboring lines are merged into planes on the second axis. Then neighboring planes are merged into cuboids on the last axis. The results are not optimal and may differ depending on the order of axes. At worst, we can't merge anything and thus iterate over every voxel in each of the steps once. The complexity is O(d^3 * 3) = O(d^3) or O(v) . Heightmap-Based Approaches All following approaches are based on the idea, that we can simplify this problem to a 2-dimensional one. One axis is being used as a height-axis, ideally the smallest one if the model is not cubical. We then use a sweeping-plane approach where at each coordinate, we draw a heightmap which extends into our chosen direction. Finding the largest volume in the model is reduced to finding the maximum of the largest volumes for all heightmaps. Constructing Heightmaps from Voxel-Models Here is an illustration of how this is done, in 2 dimensions, where \"up\" in text is the height axis: 0123456789 0123456789 7 ### -> 1110000000 6 #### ## # -> 2221011010 5 ## ### # # -> 3302120101 4 ##### # ## -> 4413201012 3 ## # # # -> 5504010100 2 ######## -> 6612121200 1 ######### -> 7726232310 0 ## ## #### -> 8807303420 In this illustration, # would be encoded as 1 and would be encoded as 0 Each slice from 0 to 7 is one histogram in 2 dimensions or a heightmap in 3 dimensions. We can construct these very efficiently by just taking the heightmap at one height above and incrementing each height, unless we find an empty voxel ( 0 ). Constructing Bitmaps from Heightmaps Finding the largest cuboid in a voxel-model has been reduced to finding the largest cuboid in all its heightmaps. The problem is once again reduced to finding the largest area of 1 s in a bitmap, which can be done in O(n*n) . This is done by looking at all different height-values of the heightmap. At every height, a bitmap is constructed. In our bitmap of equal dimensions, 1 represents that the height at the location is >= the height. Example: 389200 111000 323350 ------> 101110 500020 (h=3) 100000 211141 000010 Finding the largest area of 1 in an n*n rectangle has O(n^2) complexity or O(1) per pixel, when using a sweeping-line algorithm and searching for the greatest area in the resulting histograms: https://www.geeksforgeeks.org/maximum-size-rectangle-binary-sub-matrix-1s/ The volume of the greatest cuboid is then the current height multiplied with the size of the greatest area of 1 which we find. Expected values To understand the following approaches, one must realize that the highest cuboid is not necessarily the largest. For example, a very flat pyramid may have a shape which is only great in volume towards the base. For an n*n heightmap with n height, we can find the cuboid with the largest volume for all heights by finding the largest cuboid at each individual height. This forces us to check every single height. Naive Method high complexity optimal results The naive method simply to iterate over all heights. We then require O(d^2 * d^2) complexity where one d^2 represents the size of the base and the other d^2 represents the amount of pairs of heights. This would be O(v^(4/3)) , which is not as bad as the stupid approach but still polynomial. Modified Kadane's-Algorithm THIS SECTION IS WIP - complexity yet unknown - hopefully optimal results This can be done by using a sweeping-plane algorithm, where each plane is a heightmap which encodes how many voxels extrude upwards, starting from each one of its pixels. The problem is thus reduced to finding the greatest cuboid on a heightmap, which can be done somewhat efficiently using Kadane's algorithm, where any `0` is treated as negative infinity and the heights are cut-off at some maximum height dynamically during the search. For a `n*n` map, Kadane's algorithm has a complexity of `O(n^3)` or `O(n)` per pixel. Whether this is usable has to be investigated further. Golden-Section-Search (not sure if this actually works) best known complexity optimal We can achieve logarithmic complexity per voxel. The approach to this is very similar to the naive method, but based on a crucial observation. The maximum volumes at each minimum height form a unimodal function. Our search is still based on finding the greatest are of 1 in a bitmap, but we choose our heights in a smarter way instead of iterating over all heights. Consider a histogram such as: ^ 7| # 6|# # # 5|# # ### # # 4|# # ### ## ### ## # 3|# ## ### ### ### ####### ## 2|#### ### ### #### ### ####### ### 1|##### #### ### ##### ############### #### -+----------------------------------------------> |0123456789abcdefghijklmnopqrstuvwxyzABCDEFGH The greatest areas for each height are: 7: 07 (3:1, 3:7) 6: 07 (3:1, 3:7) found by extruding (3:1, 3:6) >>5: 15 (8:1, a:5) >>4: 15 (8:1, a:5) >>>>3: 21 (w:1, C:3) >>>>2: 21 (w:1, C:3) >>1: 15 (o:1, C:1) Note that the maximum volumes at each height only form a unimodal function if we extrude our found area as far up as possible. Searching for the maximum or minimum of a unimodal function can be done with logarithmic complexity. The final complexity would thus be O(n^2 * log_2 n) or O(log_2 n) per pixel.","title":"Cuboid Extraction"},{"location":"cuboid_extraction.html#cuboid-extraction","text":"","title":"Cuboid Extraction"},{"location":"cuboid_extraction.html#motivation","text":"Voxel models of certain types have large volumes of voxels. These types include extruded heightmaps, medical scans, video game worlds and voxel art. Other types such as voxelized polygonal models may also be filled up instead of being kept hollow. The volumes may often be misaligned with the octree structure. Consider a single 2x2x2 cube in the center of an octree. All 8 subtrees of the octree would have to encode an individual voxel of this cube, which is far from optimal. In addition, decoding volumes which are completely filled simplifies the decoding process. These volumes could be extracted and encoded as cuboids like {triple<u8> pos, triple<u8> size} within a container that has dimensions up to 256^3. However we extract cuboids, those should be as large in volume as possible. This way, we cover the most voxels with our pairs of positions. The highest-volume container should be found, then extracted and the next-highest-volume container found, etc. We invest 6 bytes into the extraction, so our volume needs to be 48 to break even (e.g. 4x4x3 ).","title":"Motivation"},{"location":"cuboid_extraction.html#absolutely-stupid-method","text":"extreme complexity but optimal results Since a cuboid is just a pair of positions, we can simply iterate over all pairs of positions. We then iterate over all voxels in the cuboid to test whether they exist. For a d*d*d model containing v voxels the complexity is thus O(d^3 * d^3 * d^3) or O(d^9) or O(v^3) . This is some clown-world-tier complexity and should not find its way into any serious implementation. Due to its simplicity, it could be used to verify the correctness of more complex approaches though.","title":"Absolutely Stupid Method"},{"location":"cuboid_extraction.html#xyz-merge","text":"best possible complexity not optimal An XYZ-merge works by merging all neighboring voxels into lines on one axis first. Then neighboring lines are merged into planes on the second axis. Then neighboring planes are merged into cuboids on the last axis. The results are not optimal and may differ depending on the order of axes. At worst, we can't merge anything and thus iterate over every voxel in each of the steps once. The complexity is O(d^3 * 3) = O(d^3) or O(v) .","title":"XYZ-Merge"},{"location":"cuboid_extraction.html#heightmap-based-approaches","text":"All following approaches are based on the idea, that we can simplify this problem to a 2-dimensional one. One axis is being used as a height-axis, ideally the smallest one if the model is not cubical. We then use a sweeping-plane approach where at each coordinate, we draw a heightmap which extends into our chosen direction. Finding the largest volume in the model is reduced to finding the maximum of the largest volumes for all heightmaps.","title":"Heightmap-Based Approaches"},{"location":"cuboid_extraction.html#constructing-heightmaps-from-voxel-models","text":"Here is an illustration of how this is done, in 2 dimensions, where \"up\" in text is the height axis: 0123456789 0123456789 7 ### -> 1110000000 6 #### ## # -> 2221011010 5 ## ### # # -> 3302120101 4 ##### # ## -> 4413201012 3 ## # # # -> 5504010100 2 ######## -> 6612121200 1 ######### -> 7726232310 0 ## ## #### -> 8807303420 In this illustration, # would be encoded as 1 and would be encoded as 0 Each slice from 0 to 7 is one histogram in 2 dimensions or a heightmap in 3 dimensions. We can construct these very efficiently by just taking the heightmap at one height above and incrementing each height, unless we find an empty voxel ( 0 ).","title":"Constructing Heightmaps from Voxel-Models"},{"location":"cuboid_extraction.html#constructing-bitmaps-from-heightmaps","text":"Finding the largest cuboid in a voxel-model has been reduced to finding the largest cuboid in all its heightmaps. The problem is once again reduced to finding the largest area of 1 s in a bitmap, which can be done in O(n*n) . This is done by looking at all different height-values of the heightmap. At every height, a bitmap is constructed. In our bitmap of equal dimensions, 1 represents that the height at the location is >= the height. Example: 389200 111000 323350 ------> 101110 500020 (h=3) 100000 211141 000010 Finding the largest area of 1 in an n*n rectangle has O(n^2) complexity or O(1) per pixel, when using a sweeping-line algorithm and searching for the greatest area in the resulting histograms: https://www.geeksforgeeks.org/maximum-size-rectangle-binary-sub-matrix-1s/ The volume of the greatest cuboid is then the current height multiplied with the size of the greatest area of 1 which we find.","title":"Constructing Bitmaps from Heightmaps"},{"location":"cuboid_extraction.html#expected-values","text":"To understand the following approaches, one must realize that the highest cuboid is not necessarily the largest. For example, a very flat pyramid may have a shape which is only great in volume towards the base. For an n*n heightmap with n height, we can find the cuboid with the largest volume for all heights by finding the largest cuboid at each individual height. This forces us to check every single height.","title":"Expected values"},{"location":"cuboid_extraction.html#naive-method","text":"high complexity optimal results The naive method simply to iterate over all heights. We then require O(d^2 * d^2) complexity where one d^2 represents the size of the base and the other d^2 represents the amount of pairs of heights. This would be O(v^(4/3)) , which is not as bad as the stupid approach but still polynomial.","title":"Naive Method"},{"location":"cuboid_extraction.html#modified-kadanes-algorithm","text":"THIS SECTION IS WIP - complexity yet unknown - hopefully optimal results This can be done by using a sweeping-plane algorithm, where each plane is a heightmap which encodes how many voxels extrude upwards, starting from each one of its pixels. The problem is thus reduced to finding the greatest cuboid on a heightmap, which can be done somewhat efficiently using Kadane's algorithm, where any `0` is treated as negative infinity and the heights are cut-off at some maximum height dynamically during the search. For a `n*n` map, Kadane's algorithm has a complexity of `O(n^3)` or `O(n)` per pixel. Whether this is usable has to be investigated further.","title":"Modified Kadane's-Algorithm"},{"location":"cuboid_extraction.html#golden-section-search-not-sure-if-this-actually-works","text":"best known complexity optimal We can achieve logarithmic complexity per voxel. The approach to this is very similar to the naive method, but based on a crucial observation. The maximum volumes at each minimum height form a unimodal function. Our search is still based on finding the greatest are of 1 in a bitmap, but we choose our heights in a smarter way instead of iterating over all heights. Consider a histogram such as: ^ 7| # 6|# # # 5|# # ### # # 4|# # ### ## ### ## # 3|# ## ### ### ### ####### ## 2|#### ### ### #### ### ####### ### 1|##### #### ### ##### ############### #### -+----------------------------------------------> |0123456789abcdefghijklmnopqrstuvwxyzABCDEFGH The greatest areas for each height are: 7: 07 (3:1, 3:7) 6: 07 (3:1, 3:7) found by extruding (3:1, 3:6) >>5: 15 (8:1, a:5) >>4: 15 (8:1, a:5) >>>>3: 21 (w:1, C:3) >>>>2: 21 (w:1, C:3) >>1: 15 (o:1, C:1) Note that the maximum volumes at each height only form a unimodal function if we extrude our found area as far up as possible. Searching for the maximum or minimum of a unimodal function can be done with logarithmic complexity. The final complexity would thus be O(n^2 * log_2 n) or O(log_2 n) per pixel.","title":"Golden-Section-Search (not sure if this actually works)"},{"location":"methods.html","text":"Analyzed Methods RLE (Run-Length Encoding) encode geometry separately from colors first use a universal, easy-to-decade format u32 {u1 bitToEncode, u31 length} then discuss how that format can be made more efficient compare allocating different amounts of bits for length try encoding more than just a bit with RLE, also try pairs and triplets, up to a maximum of 1 byte compare compression ratios and pick the sweet-spot between length and bits Sparse Voxel Octrees","title":"Analyzed Methods"},{"location":"methods.html#analyzed-methods","text":"","title":"Analyzed Methods"},{"location":"methods.html#rle-run-length-encoding","text":"encode geometry separately from colors first use a universal, easy-to-decade format u32 {u1 bitToEncode, u31 length} then discuss how that format can be made more efficient compare allocating different amounts of bits for length try encoding more than just a bit with RLE, also try pairs and triplets, up to a maximum of 1 byte compare compression ratios and pick the sweet-spot between length and bits","title":"RLE (Run-Length Encoding)"},{"location":"methods.html#sparse-voxel-octrees","text":"","title":"Sparse Voxel Octrees"},{"location":"statistical_tests.html","text":"Statistical Tests to Determine Voxel Model Properties The following list should give an overview over possible properties which voxel models are suspected to have. A description of an algorithm and/or pseudocude is used to provide a potential test. Spatial Locality of Different Methods of Iteration Over Voxel Models There are various different ways of iterating over a voxel model. We will consider only two or three, which are relevant to us. Nested Loop Iteration This is the traditional method of iterating over multi-dimensional arrays. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[x][y][z]; It is extremely efficient for traversing memory because it seemlessly iterates over memory locations, as long as the axes of iteration are in the right order. The distances between two positions are at best 1 and at worst SIZE_X + SIZEY . However, the spatial locality is much worse when looking at more than one position. For say, 10 positions the distance between the first and last will be 10, which is comparably far. Z-Order Iteration Z-Order iteration traverses space with much higher locality. It works by traversing all nodes of an octree depth-first. 3D-Vectors can be converted into \"octree positions\" by interleaving the bits of the coordinates into a single number. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[interleave_bits(x, y, z)]; ) Hilbert-Curve Iteration Hilbert-Curves have even higher locality than Z-Order iterations, but are considerably better in locality. See https://slideplayer.com/slide/3370293/ for construction. In short, space is filled in the following order, which is a Gray Code. [[0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 0]] The entry direction for one of these pieces is +Z and the exit-direction is -Y. This pattern is repeated recursively, but the smaller building blocks have to be mirrored and rotated to fit together seemlessly into a larger block. The tremendously useful property here is that the distance between two points in the iteration is at most 1 . Testing Spatial Locality Spatial locality can simply be tested by comparing the average distance between each pair of points, triple of points, etc. within an iteration. When more than two points are tested, the distances of each unique pair of points can be summed up or averaged. Hilber-Curve Iteration is expected to deliver the best results on most, if not all scales. Correlation of Color and Geometry Deltas It is expected that color correlates with positions. This means that positions which are close to each other should also have similar colors. To verify this property, each unique pair of points can be iterated over. The euclidean distance in geometry-space (scaled down to a unit-cube) as well as the euclidean distance in the RGB color space should be plotted. The correlation can then be calculated from all data entries. struct Entry { double geoDistance; double colDistance; }; struct ColoredPoint { vec3 geo; vec3 col; } std::vector<double[2]> entries; for (const std::pair<ColoredPoint, ColoredPoint> &pair : allPoints) { double geoDistance = pair.first.geo.distanceTo(pair.second.geo); double colDistance = pair.first.col.distanceTo(pair.second.col); entries.emplace_back(geoDistance, colDistance); }","title":"Statistical Tests to Determine Voxel Model Properties"},{"location":"statistical_tests.html#statistical-tests-to-determine-voxel-model-properties","text":"The following list should give an overview over possible properties which voxel models are suspected to have. A description of an algorithm and/or pseudocude is used to provide a potential test.","title":"Statistical Tests to Determine Voxel Model Properties"},{"location":"statistical_tests.html#spatial-locality-of-different-methods-of-iteration-over-voxel-models","text":"There are various different ways of iterating over a voxel model. We will consider only two or three, which are relevant to us.","title":"Spatial Locality of Different Methods of Iteration Over Voxel Models"},{"location":"statistical_tests.html#nested-loop-iteration","text":"This is the traditional method of iterating over multi-dimensional arrays. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[x][y][z]; It is extremely efficient for traversing memory because it seemlessly iterates over memory locations, as long as the axes of iteration are in the right order. The distances between two positions are at best 1 and at worst SIZE_X + SIZEY . However, the spatial locality is much worse when looking at more than one position. For say, 10 positions the distance between the first and last will be 10, which is comparably far.","title":"Nested Loop Iteration"},{"location":"statistical_tests.html#z-order-iteration","text":"Z-Order iteration traverses space with much higher locality. It works by traversing all nodes of an octree depth-first. 3D-Vectors can be converted into \"octree positions\" by interleaving the bits of the coordinates into a single number. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[interleave_bits(x, y, z)]; )","title":"Z-Order Iteration"},{"location":"statistical_tests.html#hilbert-curve-iteration","text":"Hilbert-Curves have even higher locality than Z-Order iterations, but are considerably better in locality. See https://slideplayer.com/slide/3370293/ for construction. In short, space is filled in the following order, which is a Gray Code. [[0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 0]] The entry direction for one of these pieces is +Z and the exit-direction is -Y. This pattern is repeated recursively, but the smaller building blocks have to be mirrored and rotated to fit together seemlessly into a larger block. The tremendously useful property here is that the distance between two points in the iteration is at most 1 .","title":"Hilbert-Curve Iteration"},{"location":"statistical_tests.html#testing-spatial-locality","text":"Spatial locality can simply be tested by comparing the average distance between each pair of points, triple of points, etc. within an iteration. When more than two points are tested, the distances of each unique pair of points can be summed up or averaged. Hilber-Curve Iteration is expected to deliver the best results on most, if not all scales.","title":"Testing Spatial Locality"},{"location":"statistical_tests.html#correlation-of-color-and-geometry-deltas","text":"It is expected that color correlates with positions. This means that positions which are close to each other should also have similar colors. To verify this property, each unique pair of points can be iterated over. The euclidean distance in geometry-space (scaled down to a unit-cube) as well as the euclidean distance in the RGB color space should be plotted. The correlation can then be calculated from all data entries. struct Entry { double geoDistance; double colDistance; }; struct ColoredPoint { vec3 geo; vec3 col; } std::vector<double[2]> entries; for (const std::pair<ColoredPoint, ColoredPoint> &pair : allPoints) { double geoDistance = pair.first.geo.distanceTo(pair.second.geo); double colDistance = pair.first.col.distanceTo(pair.second.col); entries.emplace_back(geoDistance, colDistance); }","title":"Correlation of Color and Geometry Deltas"},{"location":"uncompressed.html","text":"Uncompressed Format The uncompressed format used for reference in this project is a 32-bit list of voxels. In this case a voxel is a triple of coordinates and an ARGB integer, meaning that voxels can be partially transparent. Example Implementation Here is a simple example implementation of a 32-bit voxel list in Rust. struct voxel { i32 x; i32 y; i32 z; u8 a; u8 r; u8 g; u8 b; } let mut voxel_list = Vec<voxel>::new(); Justification - Voxel Arrays vs. Voxel Lists There are at least two popular methods of representing voxels in an uncompressed way: 3D-array of colors, aka. voxel array array of coordinate/color pairs, aka. voxel list The first method is often used in software on a small scale. Arrays allow for random access in O(1) . They are also used in other research, such as High Resolution Sparse Voxel DAGs . Despite its popularity, arrays are unsuitable for measuring compression ratios because the entropy of the voxel data poorly correlates with the size of this representation. For instance, two voxels at (1, 1, 1) and (1000, 1000, 1000) require 1 gigavoxel of space due to all the empty space between the two voxels. However, in the best case where all voxels are present, this method has only constant overhead: that which is necessary to store the dimensions of the array. The second representation -which is the one used here- will require space that linearly scales with the amount of non-empty voxels. Note that in the worst case, this could require four times the space of the first method due to the coordinates being stored explicitly. This kind of overhead is still preferable to the potential (near) complete waste of space of the first method. To summarize, here is a quick overview: Voxel Array Voxel List worst case overhead (space) O(\\infty) 1 O(4n) 2 best case overhead (space) \\Omega(1) \\Omega(4n) 2 random access (time) O(1) O(n) Serialization Serialization of this representation is trivial because the data structure in memory is similar of not identical to its serialized counterpart. Here, the VL32 file format is used. Unbounded because two voxels can be infinitely far apart, creating infinite wasted space / overhead \u21a9 The constant factor of 4 is irrelevant in this notation, but illustrates the extent of the overhead \u21a9 \u21a9","title":"Uncompressed Format"},{"location":"uncompressed.html#uncompressed-format","text":"The uncompressed format used for reference in this project is a 32-bit list of voxels. In this case a voxel is a triple of coordinates and an ARGB integer, meaning that voxels can be partially transparent.","title":"Uncompressed Format"},{"location":"uncompressed.html#example-implementation","text":"Here is a simple example implementation of a 32-bit voxel list in Rust. struct voxel { i32 x; i32 y; i32 z; u8 a; u8 r; u8 g; u8 b; } let mut voxel_list = Vec<voxel>::new();","title":"Example Implementation"},{"location":"uncompressed.html#justification-voxel-arrays-vs-voxel-lists","text":"There are at least two popular methods of representing voxels in an uncompressed way: 3D-array of colors, aka. voxel array array of coordinate/color pairs, aka. voxel list The first method is often used in software on a small scale. Arrays allow for random access in O(1) . They are also used in other research, such as High Resolution Sparse Voxel DAGs . Despite its popularity, arrays are unsuitable for measuring compression ratios because the entropy of the voxel data poorly correlates with the size of this representation. For instance, two voxels at (1, 1, 1) and (1000, 1000, 1000) require 1 gigavoxel of space due to all the empty space between the two voxels. However, in the best case where all voxels are present, this method has only constant overhead: that which is necessary to store the dimensions of the array. The second representation -which is the one used here- will require space that linearly scales with the amount of non-empty voxels. Note that in the worst case, this could require four times the space of the first method due to the coordinates being stored explicitly. This kind of overhead is still preferable to the potential (near) complete waste of space of the first method. To summarize, here is a quick overview: Voxel Array Voxel List worst case overhead (space) O(\\infty) 1 O(4n) 2 best case overhead (space) \\Omega(1) \\Omega(4n) 2 random access (time) O(1) O(n)","title":"Justification - Voxel Arrays vs. Voxel Lists"},{"location":"uncompressed.html#serialization","text":"Serialization of this representation is trivial because the data structure in memory is similar of not identical to its serialized counterpart. Here, the VL32 file format is used. Unbounded because two voxels can be infinitely far apart, creating infinite wasted space / overhead \u21a9 The constant factor of 4 is irrelevant in this notation, but illustrates the extent of the overhead \u21a9 \u21a9","title":"Serialization"},{"location":"dag/dag.html","text":"Directed Acyclic Graph","title":"Directed Acyclic Graph"},{"location":"dag/dag.html#directed-acyclic-graph","text":"","title":"Directed Acyclic Graph"},{"location":"file_formats/structlang.html","text":"Structure Language (StructLang) StructLang is a data specification language used within the scope of this project. It uses a syntax similar to Rust and C to mathematically specify a syntax for binary data. Comments Comments begin with a // and continue until the end of the line. Alternatively, a comment block which begins with /* and ends with */ can be used. Settings Some global settings may be necessary to write a proper specification. Syntax set = \"set\" identifier \"=\" value; Examples set byte_bits = 32 set default_byte_order = big_endian set default_signed_representation = twos_complement List of Settings Identifier Type Description byte_bits unsigned integer number of bits in one byte default_byte_order modifier default byte order (endianness) of types default_signed_representation modifier default representation of signed integers Type Definitions Definitions define data types. Syntax def = \"def\" type \"=\" {modifier} base_type; type is the identifier of the type modifier a type modifier base_type the base type which this type is specializing Example def i32 = signed 32_bit twos_complement integer def u8 = unsigned 8_bit integer def string = null_terminated u8[] Arrays Arrays are blocks of one type which are stored using a single variable. Syntax array_type = type \"[\" size | \"\" \"]\"; Examples u8[4096] buffer // a constant-sized array u32 size u8[size] var_buffer // a variable-sized array u8[] endless_buffer // an array which extends until the end of the data Structures Defines a structure of other types. These types can also be structures. The first (uppermost) type in a struct is also the first element in the serialized data. Syntax struct = \"struct\" identifier \"{\" type identifier ... \"}\"; Example struct Color { u8 red u8 green u8 blue } Enumerations Defines a list of constants of some type. Syntax enum = \"enum\", identifier, \":\", type, \"{\", {identifier, \"=\", value}, \"}\"; Examples enum Size : string { SMALL = \"S\" MEDIUM = \"M\" LARGE = \"L\" EXTRA_LARGE = \"XL\" } enum ArgbColor : u32 { RED = 0xffff0000 GREEN = 0xff00ff00 BLUE = 0xff0000ff } Templated Structures Sometimes a structure depends on content found in a header or other structures. Templates can change how a structure is laid out using variables. Syntax struct = \"struct\" type \"<\" type {identifier \",\"} \">\" \"{\" ... \"}\"; Example struct varint<u8 bits> { if bits == 8 { u8 data } else if bits == 16 { u16 data } else if bits == 32 { u32 data } else { error \"Invalid bits variable\" } }","title":"Structure Language (StructLang)"},{"location":"file_formats/structlang.html#structure-language-structlang","text":"StructLang is a data specification language used within the scope of this project. It uses a syntax similar to Rust and C to mathematically specify a syntax for binary data.","title":"Structure Language (StructLang)"},{"location":"file_formats/structlang.html#comments","text":"Comments begin with a // and continue until the end of the line. Alternatively, a comment block which begins with /* and ends with */ can be used.","title":"Comments"},{"location":"file_formats/structlang.html#settings","text":"Some global settings may be necessary to write a proper specification.","title":"Settings"},{"location":"file_formats/structlang.html#syntax","text":"set = \"set\" identifier \"=\" value;","title":"Syntax"},{"location":"file_formats/structlang.html#examples","text":"set byte_bits = 32 set default_byte_order = big_endian set default_signed_representation = twos_complement","title":"Examples"},{"location":"file_formats/structlang.html#list-of-settings","text":"Identifier Type Description byte_bits unsigned integer number of bits in one byte default_byte_order modifier default byte order (endianness) of types default_signed_representation modifier default representation of signed integers","title":"List of Settings"},{"location":"file_formats/structlang.html#type-definitions","text":"Definitions define data types.","title":"Type Definitions"},{"location":"file_formats/structlang.html#syntax_1","text":"def = \"def\" type \"=\" {modifier} base_type; type is the identifier of the type modifier a type modifier base_type the base type which this type is specializing","title":"Syntax"},{"location":"file_formats/structlang.html#example","text":"def i32 = signed 32_bit twos_complement integer def u8 = unsigned 8_bit integer def string = null_terminated u8[]","title":"Example"},{"location":"file_formats/structlang.html#arrays","text":"Arrays are blocks of one type which are stored using a single variable.","title":"Arrays"},{"location":"file_formats/structlang.html#syntax_2","text":"array_type = type \"[\" size | \"\" \"]\";","title":"Syntax"},{"location":"file_formats/structlang.html#examples_1","text":"u8[4096] buffer // a constant-sized array u32 size u8[size] var_buffer // a variable-sized array u8[] endless_buffer // an array which extends until the end of the data","title":"Examples"},{"location":"file_formats/structlang.html#structures","text":"Defines a structure of other types. These types can also be structures. The first (uppermost) type in a struct is also the first element in the serialized data.","title":"Structures"},{"location":"file_formats/structlang.html#syntax_3","text":"struct = \"struct\" identifier \"{\" type identifier ... \"}\";","title":"Syntax"},{"location":"file_formats/structlang.html#example_1","text":"struct Color { u8 red u8 green u8 blue }","title":"Example"},{"location":"file_formats/structlang.html#enumerations","text":"Defines a list of constants of some type.","title":"Enumerations"},{"location":"file_formats/structlang.html#syntax_4","text":"enum = \"enum\", identifier, \":\", type, \"{\", {identifier, \"=\", value}, \"}\";","title":"Syntax"},{"location":"file_formats/structlang.html#examples_2","text":"enum Size : string { SMALL = \"S\" MEDIUM = \"M\" LARGE = \"L\" EXTRA_LARGE = \"XL\" } enum ArgbColor : u32 { RED = 0xffff0000 GREEN = 0xff00ff00 BLUE = 0xff0000ff }","title":"Examples"},{"location":"file_formats/structlang.html#templated-structures","text":"Sometimes a structure depends on content found in a header or other structures. Templates can change how a structure is laid out using variables.","title":"Templated Structures"},{"location":"file_formats/structlang.html#syntax_5","text":"struct = \"struct\" type \"<\" type {identifier \",\"} \">\" \"{\" ... \"}\";","title":"Syntax"},{"location":"file_formats/structlang.html#example_2","text":"struct varint<u8 bits> { if bits == 8 { u8 data } else if bits == 16 { u16 data } else if bits == 32 { u32 data } else { error \"Invalid bits variable\" } }","title":"Example"},{"location":"file_formats/vl32.html","text":"32-Bit Voxel List (VL32) VL32 is a simple intermediate file format used in the code of this research project. Specification It is a rudimentary file format which can be specified in only a few lines of StructLang: def u8 = unsigned 8_bit integer def i32 = big_endian twos_complement signed 32_bit integer struct main { voxel[] voxels } struct voxel { i32 x i32 y i32 z argb32 color } struct argb32 { u8 alpha u8 red u8 green u8 blue } Voxels with a color that has an alpha of zero are treated as void. Use Case VL32 is largely used for benchmarking compression efficiency. Any compression effort should yield significantly higher entropy than this format. One of the significant advantages is that there doesn't need to be any header information. When reading, voxels are simply loaded until the EOF is reached. Also there is no difference in data size between the file encoded on disk and its typical in-memory representation, such as a std::vector of voxels.","title":"32-Bit Voxel List (VL32)"},{"location":"file_formats/vl32.html#32-bit-voxel-list-vl32","text":"VL32 is a simple intermediate file format used in the code of this research project.","title":"32-Bit Voxel List (VL32)"},{"location":"file_formats/vl32.html#specification","text":"It is a rudimentary file format which can be specified in only a few lines of StructLang: def u8 = unsigned 8_bit integer def i32 = big_endian twos_complement signed 32_bit integer struct main { voxel[] voxels } struct voxel { i32 x i32 y i32 z argb32 color } struct argb32 { u8 alpha u8 red u8 green u8 blue } Voxels with a color that has an alpha of zero are treated as void.","title":"Specification"},{"location":"file_formats/vl32.html#use-case","text":"VL32 is largely used for benchmarking compression efficiency. Any compression effort should yield significantly higher entropy than this format. One of the significant advantages is that there doesn't need to be any header information. When reading, voxels are simply loaded until the EOF is reached. Also there is no difference in data size between the file encoded on disk and its typical in-memory representation, such as a std::vector of voxels.","title":"Use Case"},{"location":"related/literature.html","text":"Literature References Efficient Sparse Voxel Octrees Authors: Samuli Laine, Tero Karras Publisher: NVIDIA Research Publication Date: 2010-02-01 Published in: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) Links: NVIDIA Research , PDF Last Viewed: 2020-05-04 Geometry and Attribute Compression for Voxel Scenes Authors: Bas Dado, Timothy R. Kol, Pablo Bauszat, Jean-Marc Thiery, Elmar Eisemann Publisher: Delft University of Technology Publication Date: 2015-12-16 Also published in: EUROGRAPHICS 2016, Volume 35 (2016), Number 2 Links: TUDelft , PDF Last Viewed: 2020-05-04 High Resolution Sparse Voxel DAGs Authors: Viktor Ka\u0308mpe, Erik Sintorn, Ulf Assarsson Publisher: Chalmers University of Technology Publication Date: 2013-07 Published in: ACM Transactions on Graphics , Vol 32, No. 4 Links: ACM Digital Library , PDF Last Viewed: 2020-05-04 VOLA: A Compact Volumetric Format for 3D Mapping and Embedded Systems Authors: Jonathan Byrne, Le\u0301onie Buckley, Sam Caulfield, David Moloney Publisher: Advanced Architecture Group, Intel, Ireland Publication Date: 2018-01 Conference: 4th International Conference on Geographical Information Systems Theory, Applications and Management Published in: Proceedings of the 4th International Conference on Geographical Information Systems Theory, Applications and Management - Volume 1: GISTAM Links: Researchgate , PDF Last Viewed: 2020-05-04 Qubicle File Specification Articles Authors: Minddesk Software GmbH Publication Dates: 2015-10-02, 2016-01-11 Published in: getqubicle.com Links: QEF Spec. , QB Spec. , QBT Spec. Last Viewed: 2020-05-04","title":"Literature References"},{"location":"related/literature.html#literature-references","text":"","title":"Literature References"},{"location":"related/literature.html#efficient-sparse-voxel-octrees","text":"Authors: Samuli Laine, Tero Karras Publisher: NVIDIA Research Publication Date: 2010-02-01 Published in: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) Links: NVIDIA Research , PDF Last Viewed: 2020-05-04","title":"Efficient Sparse Voxel Octrees"},{"location":"related/literature.html#geometry-and-attribute-compression-for-voxel-scenes","text":"Authors: Bas Dado, Timothy R. Kol, Pablo Bauszat, Jean-Marc Thiery, Elmar Eisemann Publisher: Delft University of Technology Publication Date: 2015-12-16 Also published in: EUROGRAPHICS 2016, Volume 35 (2016), Number 2 Links: TUDelft , PDF Last Viewed: 2020-05-04","title":"Geometry and Attribute Compression for Voxel Scenes"},{"location":"related/literature.html#high-resolution-sparse-voxel-dags","text":"Authors: Viktor Ka\u0308mpe, Erik Sintorn, Ulf Assarsson Publisher: Chalmers University of Technology Publication Date: 2013-07 Published in: ACM Transactions on Graphics , Vol 32, No. 4 Links: ACM Digital Library , PDF Last Viewed: 2020-05-04","title":"High Resolution Sparse Voxel DAGs"},{"location":"related/literature.html#vola-a-compact-volumetric-format-for-3d-mapping-and-embedded-systems","text":"Authors: Jonathan Byrne, Le\u0301onie Buckley, Sam Caulfield, David Moloney Publisher: Advanced Architecture Group, Intel, Ireland Publication Date: 2018-01 Conference: 4th International Conference on Geographical Information Systems Theory, Applications and Management Published in: Proceedings of the 4th International Conference on Geographical Information Systems Theory, Applications and Management - Volume 1: GISTAM Links: Researchgate , PDF Last Viewed: 2020-05-04","title":"VOLA: A Compact Volumetric Format for 3D Mapping and Embedded Systems"},{"location":"related/literature.html#qubicle-file-specification-articles","text":"Authors: Minddesk Software GmbH Publication Dates: 2015-10-02, 2016-01-11 Published in: getqubicle.com Links: QEF Spec. , QB Spec. , QBT Spec. Last Viewed: 2020-05-04","title":"Qubicle File Specification Articles"},{"location":"related/overview.html","text":"Overview over Related Work","title":"Overview over Related Work"},{"location":"related/overview.html#overview-over-related-work","text":"","title":"Overview over Related Work"},{"location":"rle/rle.html","text":"Run-Length Encoding Run-Length Encoding (RLE) is a form of lossless data compression which stores elements of said data using a single value and a count or \"run-length\". Viability for Voxel Compression RLE is viable in those cases, where there are long runs of identical or very similar data. Due to voxel arrays often containing huge amounts of empty space, they also contain long runs of 0x0 RGB values (or whatever other value represents empty voxels) which could be run-length-compressed. This mitigates their greatest downside compared to voxel lists , their empty-space-overhead. Existing Implementation: Qubicle Binary File Format The Qubicle Binary (QB) file format has an option for compressing models using RLE. It is still in use, although it has been superseded by the Qubicle Binary Tree (QBT) file format which uses zlib instead of custom RLE. Models are mode of matrices , which are arrays, usually sized 128 3 or smaller 1 . When compressing matrices , each slice (xy-plane) is being run-length-encoded. The RLE implementation uses in-band-signaling . The CODEFLAG = 2 escape sequence signals a following pair of count and data, whereas the NEXTSLICEFLAG = 6 signals the end of the current slice . Criticism This implementation is deeply flawed, in that it fails to exploit an obvious non-conflicting escape sequence: A color with an alpha of zero is invisible, regardless of its other components. In the QB format, the escape sequences correspond due pitch black colors with an alpha of 2 or 6 respectively, which is almost invisible. Alpha channels can also be used to store visibility maps instead, where such values would be far more common. Such a problem could have been easily mitigated by using different values for the escape sequences or by not storing colors in RGBA or BGRA format. In-Band- vs Out-Of-Band- Signaling The main distinction in RLE methods can be made between In-Band Signaling And Out-Of-Band Signaling . In-Band Signaling This method uses the alphabet of the data which it attempts to compress. For instance, if the data consists of only alphabetic ASCII characters, then digits could be used to encode the counts. Or for ASCII characters which are stored in 8-bit integers, the uppermost, unused bit could be used to signal that the remaining seven bits are the count. In any case, this method is best when the addition of the count does not conflict with the existing data. Otherwise, an escape sequence is necessary. For instance, to encode any 8-bit integer sequence, the value 0xff could be used to \"escape\" the data and be followed up by the count and the actual byte to be encoded, including 0xff . \\text{aaabbbcfdeef} \\rightarrow \\text{3a3bcfd2ef} Out-Of-Band Signaling This method encodes all of the data in pairs of count and data instead of leaving single characters intact. Its main advantage is the simplicity of parsing and an identical effect for all types of data. While a particular escape sequence might be a poor choice for some specific data set, this method does not require an escape sequence and thus doesn't suffer from the problem. To avoid bloating the data in size, further measures must be taken such as having a sequence which can signal a sequence of different characters as well as a sequence of identical characters. For instance, negative counts could be used to signal multiple different characters. \\text{aaabbbcfdeef} \\rightarrow \\text{3a3b1c1f1d2e1f} Summary In-Band signaling should be used in cases where certain values in the data are unused, allowing for an escape sequence with no conflicts with other data. If there are not just a handful of values but an entire bit per byte which is unused (such as in ASCII ), then this method becomes especially viable. Otherwise, OOB signaling is preferable, as it gives much more flexibility to the implementing developer and doesn't produce any conflicts with the data to be compressed. For most of its lifetime, Qubicle did not support matrices greater than 128 in each dimension. However, the file format technically allows for greater sizes due to a 32-bit integer being used for each dimension. \u21a9","title":"Run-Length Encoding"},{"location":"rle/rle.html#run-length-encoding","text":"Run-Length Encoding (RLE) is a form of lossless data compression which stores elements of said data using a single value and a count or \"run-length\".","title":"Run-Length Encoding"},{"location":"rle/rle.html#viability-for-voxel-compression","text":"RLE is viable in those cases, where there are long runs of identical or very similar data. Due to voxel arrays often containing huge amounts of empty space, they also contain long runs of 0x0 RGB values (or whatever other value represents empty voxels) which could be run-length-compressed. This mitigates their greatest downside compared to voxel lists , their empty-space-overhead.","title":"Viability for Voxel Compression"},{"location":"rle/rle.html#existing-implementation-qubicle-binary-file-format","text":"The Qubicle Binary (QB) file format has an option for compressing models using RLE. It is still in use, although it has been superseded by the Qubicle Binary Tree (QBT) file format which uses zlib instead of custom RLE. Models are mode of matrices , which are arrays, usually sized 128 3 or smaller 1 . When compressing matrices , each slice (xy-plane) is being run-length-encoded. The RLE implementation uses in-band-signaling . The CODEFLAG = 2 escape sequence signals a following pair of count and data, whereas the NEXTSLICEFLAG = 6 signals the end of the current slice .","title":"Existing Implementation: Qubicle Binary File Format"},{"location":"rle/rle.html#criticism","text":"This implementation is deeply flawed, in that it fails to exploit an obvious non-conflicting escape sequence: A color with an alpha of zero is invisible, regardless of its other components. In the QB format, the escape sequences correspond due pitch black colors with an alpha of 2 or 6 respectively, which is almost invisible. Alpha channels can also be used to store visibility maps instead, where such values would be far more common. Such a problem could have been easily mitigated by using different values for the escape sequences or by not storing colors in RGBA or BGRA format.","title":"Criticism"},{"location":"rle/rle.html#in-band-vs-out-of-band-signaling","text":"The main distinction in RLE methods can be made between In-Band Signaling And Out-Of-Band Signaling .","title":"In-Band- vs Out-Of-Band- Signaling"},{"location":"rle/rle.html#in-band-signaling","text":"This method uses the alphabet of the data which it attempts to compress. For instance, if the data consists of only alphabetic ASCII characters, then digits could be used to encode the counts. Or for ASCII characters which are stored in 8-bit integers, the uppermost, unused bit could be used to signal that the remaining seven bits are the count. In any case, this method is best when the addition of the count does not conflict with the existing data. Otherwise, an escape sequence is necessary. For instance, to encode any 8-bit integer sequence, the value 0xff could be used to \"escape\" the data and be followed up by the count and the actual byte to be encoded, including 0xff . \\text{aaabbbcfdeef} \\rightarrow \\text{3a3bcfd2ef}","title":"In-Band Signaling"},{"location":"rle/rle.html#out-of-band-signaling","text":"This method encodes all of the data in pairs of count and data instead of leaving single characters intact. Its main advantage is the simplicity of parsing and an identical effect for all types of data. While a particular escape sequence might be a poor choice for some specific data set, this method does not require an escape sequence and thus doesn't suffer from the problem. To avoid bloating the data in size, further measures must be taken such as having a sequence which can signal a sequence of different characters as well as a sequence of identical characters. For instance, negative counts could be used to signal multiple different characters. \\text{aaabbbcfdeef} \\rightarrow \\text{3a3b1c1f1d2e1f}","title":"Out-Of-Band Signaling"},{"location":"rle/rle.html#summary","text":"In-Band signaling should be used in cases where certain values in the data are unused, allowing for an escape sequence with no conflicts with other data. If there are not just a handful of values but an entire bit per byte which is unused (such as in ASCII ), then this method becomes especially viable. Otherwise, OOB signaling is preferable, as it gives much more flexibility to the implementing developer and doesn't produce any conflicts with the data to be compressed. For most of its lifetime, Qubicle did not support matrices greater than 128 in each dimension. However, the file format technically allows for greater sizes due to a 32-bit integer being used for each dimension. \u21a9","title":"Summary"},{"location":"svo/construction.html","text":"SVO Construction When constructing an SVO from a voxel list , the complexity of this process depends on the data fed to the constructing algorithm. Within the scope of this project, the uncompressed format is a list of voxels , but there are further subtle differences. Summary of Construction The following process must be repeated for all voxels v := (p := (x, y, z), c) \\in (\\mathbb{Z}^3, \\mathbb{N}) in the list. Test signed input position p against current SVO dimensions d . If the position is outside of our boundaries, enlarge the SVO to fit p . Subtract the new most negative corner p_{min} of the SVO from p to obtain p_{\\text{normalized}} . Convert p_{\\text{normalized}} to the octree node index n . Use n to traverse the SVO and insert the voxel at the correct location. Optional: If only one octant is used, cut branches belonging to other octants recursively. This step reduces the SVO's depth by at least one layer when applicable. Note To handle signed values, the octree must be extended into both positive and negative octants. Coordinate System There are two coordinate systems with which we must concern ourselves with: world coordinate system (signed) SVO coordinate system (unsigned) The conversion between these two coordinate systems occurs in step 3. The problem which we face is that our SVO is meant to split the world coordinate system into eight equal octants, recursively. The first split occurs at the origin however, the origin (0, 0, 0) must be located in one of these octants. To solve this, we put the origin into the first octant; then all positions with no negative coordinates will lie in just one octant. This allows us to perform the optimisation from step 6 for only unsigned coordinates. It also helps us optimize our boundary test . As a result, for example, an SVO that can contain 4x4x4 voxels will have space from (-2, -2, -2) to (1, 1, 1) . Special Case Where Voxel Coordinates Are Positive If the voxels are sorted with the first voxel being the most negative corner of the model, we have a global p_{min} (see step 3.). All voxels can then be translated by -p_{min} , yielding only positions that belong in the first octant. If x, y, z are already guaranteed to be positive, this condition is obviously also met. In such cases. step 1. and 2. are simplified and step 6. is eliminated. Efficient Boundary Test To check whether a point lies within our SVO, max(abs(x), abs(y), abs(z)) > d would suffice. However, this test is overly pessimistic because we have more negative space instead of positive space. Also, assuming no compiler optimisations, we have to perform six conditional operations: each call to abs() requires one conditional operation a three-argument max() would require two more one more conditional operation is necessary for the > d comparison Assuming unsorted inputs, these six conditional jumps may wreak havoc on the performance of the branch predictor . To remove the pessimism from our test, we define a new function to be used in stead of abs : abs_{\\text{SVO}}(n) = \\begin{cases} -n - 1,& \\text{if } n < 0\\\\ n, & \\text{otherwise} \\end{cases} Implementation uint32_t abs_svo(int32_t n) { return n < 0 ? (-n -1) : n; } bool comp_against_svo_bounds(int32_t x, int32_t y, int32_t z, uint32_t d) { return (abs_svo(x) | abs_svo(y) | abs_svo(z)) >= d; } Such an implementation eliminates five out of six conditional operations on modern compilers, leaving only the final >= comparison. See this Compiler Explorer page for an example. Compiler Optimization of abs_svo Using abs_{\\text{SVO}} actually works in ours and the compiler's favor. This is due to the fact that negating a number in two's complement requires a bitwise negation and an increment. Due to our decrement of the negated number, we eliminate this need. abs_svo(int): mov eax, edi # copy function parameter into result register sar eax, 31 # fill the register with 1s if the number is negative, else with 0s xor eax, edi # xor result register with parameter, performing a conditional bitwise NOT retn # return from the function Manual Optimization of Comparison with d This only works because d is an SVO dimension and thus always guaranteed to be a power of two. The most significant bit of lower numbers is lower than the single bit of a greater power of two. To name an example, 128 will have the 128-bit set, whereas all lower numbers will consist only of less significant bits. Hence, they can be safely combined with an | operation before making the comparison. Summary The overly pessimistic initial comparison could be fixed with -surprisingly- no performance impact. Out of the six necessary conditional operations, we could optimize five away. During a microbenchmark of the original max(abs(x), abs(y), abs(z)) > d comparison vs. our optimized method, no performance difference could be found . However, microbenchmarks are to be taken with a grain of salt and depending on the architecture and the surrounding code, a performance improvement may happen. Octree Node Index The conventional method of addressing positions within a 3D-container would be by using a vector v = (x, y, z) \\in \\mathbb{Z}^3 . Finding a voxel within an octree using v would cumbersome, since it requires recursively testing whether each coordinate is in the lower or the upper half of current subtree. As long as the tree's dimensions are a power of 2, this is actually simplified since this test can be reduced to checking whether a bit is set. For example, 128 is in the upper half of the 256-tree, because the most 128-bit is set, which is not the case for 127. Idea Binary numbers can generally be interpreted as locations in binary trees: _**_ / \\ 0* 1* / \\ / \\ 00 01 10 11 As we can see, the lower bit indicates whether the position is left or right in the lower subtree and the higher bit indicates whether the position is left or right in the upper subtree. The same pattern occurs for octal digits and octrees. (x, y, z) can thus be seen as three positions in separate binary trees which we want to combine into an octree. To convert (x, y, z) to a position in an octree, the bits of (x, y, z) can simply be interleaved. The result will be a single number of octal digits, each of which represents the position within one octree node. Examples This is how coordinates can be mapped to octree indices: \\begin{align} & (6, 8, 9) = (0101_2, 1000_2, 1001_2) \\\\ \\xrightarrow{\\text{interleave}} \\quad& (0,1,1),(1,1,1),(0,0,0),(1,0,1) \\\\ \\xrightarrow{\\text{concatenate}} \\quad& 011,111,000,101_2 = 3705_8 = 1989 \\end{align} Note that in the above example, x is used as the most significant bit of each octal digit, followed by y and z . This is how octree node indices can be mapped to coordinates: \\begin{align} &25 = 31_8 = 011,001_2 \\\\ \\xrightarrow{\\text{to vectors}} \\quad& (0, 1, 1), (0, 0, 1) \\\\ \\xrightarrow{\\text{deinterleave}} \\quad& (00_2, 10_2, 11_2) = (0, 2, 3) \\end{align} Implementation The following C++17 implementation shows how three coordinates (x, y, z) can be efficiently interleaved using binary Magic Numbers. The implementation expands upon one of the Bit Twiddling Hacks by Sean Eron Anderson . // interleaves a given number with two zero-bits after each input bit // the first insertion occurs between the least significant bit and the next higher bit uint64_t ileave_two0(uint32_t input) { constexpr size_t numInputs = 3; constexpr uint64_t masks[] = { 0x9249'2492'4924'9249, 0x30C3'0C30'C30C'30C3, 0xF00F'00F0'0F00'F00F, 0x00FF'0000'FF00'00FF, 0xFFFF'0000'0000'FFFF }; uint64_t n = input; for (int i = 4; i != 1; --i) { const auto shift = (numInputs - 1) * (1 << i); n |= n << shift; n &= masks[i]; } return n; } uint64_t ileave3(uint32_t x, uint32_t y, uint32_t z) { return (ileave_two0(x) << 2) | (ileave_two0(y) << 1) | ileave_two0(z); } Note An implementation for a variable amount of inputs is equally possible, but would significantly increase the code complexity. Most notably, the masks lookup table would need to be generated computationally. C++ was chosen due to its constexpr compile-time context. Traversing the Octree Once the octree node index is computed, traversing the octree becomes simple: For a given index n , we start at the most significant octal digit o and the root node. We follow the branch number o or construct it if it does not exist yet. Insert the voxel's color once a leaf node is found. Repeat until the least significant octal digit is processed. Note Once a nonexistent branch is found in step 2, all deeper branches will also be missing. In such a case, we can enter a different code path that handles this case. Node Implementation An SVO will need to store our voxel colors at some level. We can reduce memory consumption and cache misses by using a small voxel array at the second-to-final depth: // a regular node struct svo_node { svo_node *children[8]; }; // a node that stores colors instead struct svo_array_node { uint32_t colors[8]; } // a node that stores just one color, something that we want to avoid struct svo_leaf_node { uint32_t color; } This code will need to be adjusted so that the nodes are either polymorphic or type unions are used.","title":"SVO Construction"},{"location":"svo/construction.html#svo-construction","text":"When constructing an SVO from a voxel list , the complexity of this process depends on the data fed to the constructing algorithm. Within the scope of this project, the uncompressed format is a list of voxels , but there are further subtle differences.","title":"SVO Construction"},{"location":"svo/construction.html#summary-of-construction","text":"The following process must be repeated for all voxels v := (p := (x, y, z), c) \\in (\\mathbb{Z}^3, \\mathbb{N}) in the list. Test signed input position p against current SVO dimensions d . If the position is outside of our boundaries, enlarge the SVO to fit p . Subtract the new most negative corner p_{min} of the SVO from p to obtain p_{\\text{normalized}} . Convert p_{\\text{normalized}} to the octree node index n . Use n to traverse the SVO and insert the voxel at the correct location. Optional: If only one octant is used, cut branches belonging to other octants recursively. This step reduces the SVO's depth by at least one layer when applicable. Note To handle signed values, the octree must be extended into both positive and negative octants.","title":"Summary of Construction"},{"location":"svo/construction.html#coordinate-system","text":"There are two coordinate systems with which we must concern ourselves with: world coordinate system (signed) SVO coordinate system (unsigned) The conversion between these two coordinate systems occurs in step 3. The problem which we face is that our SVO is meant to split the world coordinate system into eight equal octants, recursively. The first split occurs at the origin however, the origin (0, 0, 0) must be located in one of these octants. To solve this, we put the origin into the first octant; then all positions with no negative coordinates will lie in just one octant. This allows us to perform the optimisation from step 6 for only unsigned coordinates. It also helps us optimize our boundary test . As a result, for example, an SVO that can contain 4x4x4 voxels will have space from (-2, -2, -2) to (1, 1, 1) .","title":"Coordinate System"},{"location":"svo/construction.html#special-case-where-voxel-coordinates-are-positive","text":"If the voxels are sorted with the first voxel being the most negative corner of the model, we have a global p_{min} (see step 3.). All voxels can then be translated by -p_{min} , yielding only positions that belong in the first octant. If x, y, z are already guaranteed to be positive, this condition is obviously also met. In such cases. step 1. and 2. are simplified and step 6. is eliminated.","title":"Special Case Where Voxel Coordinates Are Positive"},{"location":"svo/construction.html#efficient-boundary-test","text":"To check whether a point lies within our SVO, max(abs(x), abs(y), abs(z)) > d would suffice. However, this test is overly pessimistic because we have more negative space instead of positive space. Also, assuming no compiler optimisations, we have to perform six conditional operations: each call to abs() requires one conditional operation a three-argument max() would require two more one more conditional operation is necessary for the > d comparison Assuming unsorted inputs, these six conditional jumps may wreak havoc on the performance of the branch predictor . To remove the pessimism from our test, we define a new function to be used in stead of abs : abs_{\\text{SVO}}(n) = \\begin{cases} -n - 1,& \\text{if } n < 0\\\\ n, & \\text{otherwise} \\end{cases}","title":"Efficient Boundary Test"},{"location":"svo/construction.html#implementation","text":"uint32_t abs_svo(int32_t n) { return n < 0 ? (-n -1) : n; } bool comp_against_svo_bounds(int32_t x, int32_t y, int32_t z, uint32_t d) { return (abs_svo(x) | abs_svo(y) | abs_svo(z)) >= d; } Such an implementation eliminates five out of six conditional operations on modern compilers, leaving only the final >= comparison. See this Compiler Explorer page for an example.","title":"Implementation"},{"location":"svo/construction.html#compiler-optimization-of-abs_svo","text":"Using abs_{\\text{SVO}} actually works in ours and the compiler's favor. This is due to the fact that negating a number in two's complement requires a bitwise negation and an increment. Due to our decrement of the negated number, we eliminate this need. abs_svo(int): mov eax, edi # copy function parameter into result register sar eax, 31 # fill the register with 1s if the number is negative, else with 0s xor eax, edi # xor result register with parameter, performing a conditional bitwise NOT retn # return from the function","title":"Compiler Optimization of abs_svo"},{"location":"svo/construction.html#manual-optimization-of-comparison-with-d","text":"This only works because d is an SVO dimension and thus always guaranteed to be a power of two. The most significant bit of lower numbers is lower than the single bit of a greater power of two. To name an example, 128 will have the 128-bit set, whereas all lower numbers will consist only of less significant bits. Hence, they can be safely combined with an | operation before making the comparison.","title":"Manual Optimization of Comparison with d"},{"location":"svo/construction.html#summary","text":"The overly pessimistic initial comparison could be fixed with -surprisingly- no performance impact. Out of the six necessary conditional operations, we could optimize five away. During a microbenchmark of the original max(abs(x), abs(y), abs(z)) > d comparison vs. our optimized method, no performance difference could be found . However, microbenchmarks are to be taken with a grain of salt and depending on the architecture and the surrounding code, a performance improvement may happen.","title":"Summary"},{"location":"svo/construction.html#octree-node-index","text":"The conventional method of addressing positions within a 3D-container would be by using a vector v = (x, y, z) \\in \\mathbb{Z}^3 . Finding a voxel within an octree using v would cumbersome, since it requires recursively testing whether each coordinate is in the lower or the upper half of current subtree. As long as the tree's dimensions are a power of 2, this is actually simplified since this test can be reduced to checking whether a bit is set. For example, 128 is in the upper half of the 256-tree, because the most 128-bit is set, which is not the case for 127.","title":"Octree Node Index"},{"location":"svo/construction.html#idea","text":"Binary numbers can generally be interpreted as locations in binary trees: _**_ / \\ 0* 1* / \\ / \\ 00 01 10 11 As we can see, the lower bit indicates whether the position is left or right in the lower subtree and the higher bit indicates whether the position is left or right in the upper subtree. The same pattern occurs for octal digits and octrees. (x, y, z) can thus be seen as three positions in separate binary trees which we want to combine into an octree. To convert (x, y, z) to a position in an octree, the bits of (x, y, z) can simply be interleaved. The result will be a single number of octal digits, each of which represents the position within one octree node.","title":"Idea"},{"location":"svo/construction.html#examples","text":"This is how coordinates can be mapped to octree indices: \\begin{align} & (6, 8, 9) = (0101_2, 1000_2, 1001_2) \\\\ \\xrightarrow{\\text{interleave}} \\quad& (0,1,1),(1,1,1),(0,0,0),(1,0,1) \\\\ \\xrightarrow{\\text{concatenate}} \\quad& 011,111,000,101_2 = 3705_8 = 1989 \\end{align} Note that in the above example, x is used as the most significant bit of each octal digit, followed by y and z . This is how octree node indices can be mapped to coordinates: \\begin{align} &25 = 31_8 = 011,001_2 \\\\ \\xrightarrow{\\text{to vectors}} \\quad& (0, 1, 1), (0, 0, 1) \\\\ \\xrightarrow{\\text{deinterleave}} \\quad& (00_2, 10_2, 11_2) = (0, 2, 3) \\end{align}","title":"Examples"},{"location":"svo/construction.html#implementation_1","text":"The following C++17 implementation shows how three coordinates (x, y, z) can be efficiently interleaved using binary Magic Numbers. The implementation expands upon one of the Bit Twiddling Hacks by Sean Eron Anderson . // interleaves a given number with two zero-bits after each input bit // the first insertion occurs between the least significant bit and the next higher bit uint64_t ileave_two0(uint32_t input) { constexpr size_t numInputs = 3; constexpr uint64_t masks[] = { 0x9249'2492'4924'9249, 0x30C3'0C30'C30C'30C3, 0xF00F'00F0'0F00'F00F, 0x00FF'0000'FF00'00FF, 0xFFFF'0000'0000'FFFF }; uint64_t n = input; for (int i = 4; i != 1; --i) { const auto shift = (numInputs - 1) * (1 << i); n |= n << shift; n &= masks[i]; } return n; } uint64_t ileave3(uint32_t x, uint32_t y, uint32_t z) { return (ileave_two0(x) << 2) | (ileave_two0(y) << 1) | ileave_two0(z); } Note An implementation for a variable amount of inputs is equally possible, but would significantly increase the code complexity. Most notably, the masks lookup table would need to be generated computationally. C++ was chosen due to its constexpr compile-time context.","title":"Implementation"},{"location":"svo/construction.html#traversing-the-octree","text":"Once the octree node index is computed, traversing the octree becomes simple: For a given index n , we start at the most significant octal digit o and the root node. We follow the branch number o or construct it if it does not exist yet. Insert the voxel's color once a leaf node is found. Repeat until the least significant octal digit is processed. Note Once a nonexistent branch is found in step 2, all deeper branches will also be missing. In such a case, we can enter a different code path that handles this case.","title":"Traversing the Octree"},{"location":"svo/construction.html#node-implementation","text":"An SVO will need to store our voxel colors at some level. We can reduce memory consumption and cache misses by using a small voxel array at the second-to-final depth: // a regular node struct svo_node { svo_node *children[8]; }; // a node that stores colors instead struct svo_array_node { uint32_t colors[8]; } // a node that stores just one color, something that we want to avoid struct svo_leaf_node { uint32_t color; } This code will need to be adjusted so that the nodes are either polymorphic or type unions are used.","title":"Node Implementation"},{"location":"svo/svo.html","text":"Sparse Voxel Octree An Octree - Source: Wikipedia , WhiteTimberwolf A sparse voxel octree is a data structure which stores voxels in a tree with a branching factor of 8, with its branches being potentially absent. Missing branches typically represent empty volumes where no voxels exist. The greater these volumes are, the closer to a the root of the tree can the branches be pruned. This results in a very efficient representation of models with a significant portion of empty space. Unlike with a voxel list, all positioning is implicit and results from the tree structure, meaning that no space has to be used for the storage of coordinates during serialization. Thus, octrees combine the two greatest advantages of voxel lists and voxel arrays: like lists, they waste little space on encoding empty voxels like for arrays, voxel coordinates are implicit and little space is wasted Extreme Cases And Limits To illustrate the following extreme cases, voxel arrays and voxel lists are also compared. The space complexity of three extreme cases is compared between the three data structures, where v is the amount of voxels. Voxel Array Voxel List Sparse Voxel Octree Empty O(1) 1 O(1) O(1) Tightly Filled O(v) O(4v) O(\\frac{8}{7} v) Stretched O(\\infty) O(1) O(\\infty) Empty Octree Entirely empty models can be encoded using just the root note, which then encodes that no subtrees exist. Tightly Filled Octree Entirely filled models will have some overhead compared to an array of voxels. For every eight nodes, there is one parent node. We can calculate the maximum possible overhead by summing up this \\frac{1}{8} overhead infinitely: \\sum_{n=1}^\\infty{\\frac{1}{8}^n} = \\frac{1}{7} So at worst, our data will increase by \\frac{1}{7} , which is much better than a 100% increase such as for binary trees. Stretched Octree The stretched case is a case where a finite amount of voxels are placed infinitely far apart. For arrays, this produces infinite space requirements because all space between these points must be filled. For octrees, more layers are necessary to encode positions further from the origin. In neither case there is an upper bound to this. In practice, octrees perform significantly better at encoding sparse data than arrays. Construction How an octree can be constructed from a list voxels is thorougly explained in SVO Construction . Serialization To be used in a serial data format, octrees must first be serialized. Nodes will no longer be laid out \"randomly\" in memory but instead be arranged one after another. To fully encode an SVO, two steps must be performed: Linearize nodes by traversing the SVO's nodes in a deterministic, reversible order. Serialize each node to binary data. Traversal Order There are two well-known strategies for traversing trees completely: Depth-First Search (DFS) Breadth-First Search (BFS) Depth-First Tree, traversed depth-first - Source: Wikipedia , Alexander Drichel DFS can be performed using only a stack to keep track of the node number at each level. On the deepest level, the next node is chosen until the end is reached and the next parent node is chosen. This low memory cost (which is in fact O(\\log{n}) where n is the number of nodes) is highly advantageous when encoding enormous models. Breadth-First Tree, traversed breadth first - Source: Wikipedia , Alexander Drichel BFS comes with a higher cost since a typical algorithm appends all branches to a queue for every traversed node. This means that in the worst case, which is at the beginning of serialization eight nodes are appended on every level before any node is popped from the queue, resulting in a higher memory cost. Node Encoding Single-Bit Format 0 stands for air-subtree 1 stands for partially or entirely filled voxel-subtree 8 Bits per octree-node, thus this format is byte-aligned. 1.5-Bit Format 00 stands for air-subtree 01 stands for solid subtree 1 stands for partially filled subtree Variable amount of bits per octree-node, neither bit- nor byte-aligned. On the last level (node = voxel), the single-bit format is used because there are no subtrees. 2-Bit Format 00 stands for air-subtree 01 stands for solid subtree 10 stands for partially filled subtree 11 variable purpose 11 for Raw/Array Subtrees Useful to encode subtrees completely filled with high-entropy content. On the second-to-last level, 11 for raw-subtrees there is no difference between 10 and 11 , so reverting to the 1.5-bit format is viable. On the last level, the single-bit format should be used. As long as the 1.5-bit format is not used, this encoding is completely byte-aligned: * alignment to 16 -bit boundaries on most levels * alignment to 8 -bit boundaries on last level 11 for Pointers to Subtrees on the Same Level Useful for encoding multiple similar subtrees. Similarities between structures could be effectively exploited. Verifying whether subtrees are equal down to the base level has very high complexity: O(n^2 * 8^n) . The comparison depth could be reduced down to a limited number of levels or the level number could be encoded next to the pointer: {u32 indexOfOtherTree, u8 depth} . Instead of the pointer, a tree could instead encode all the places where it is additionally used. This would make decoding easier, since remembering trees on the same level is not necessary. Tetrahexacontrees This term comes from \"tetrahexaconta\" (Greek for 64) and \"tree\". It builds on the idea of octrees but expands the branching factor from 8 to 8 2 , or 64. A use of this concept can be seen in the VOLA file format. 64-bit architectures established themselves as the de-facto standard for desktop operating systems. Anecdotally, \"macOS Mojave would be the last version of macOS to run 32-bit apps\" - Apple . Thus, optimization of algorithms in the present day can be performed for 64-bit architectures without worrying about 32-bit users. Comparison to Octrees Tetrahexacontrees encode two octree layers of depth in a single layer. CPU-performance wise, they fill exactly one 64-bit register with one node, using the architecture's capacities optimally unlike octrees. However, they sacrifice potential compression efficiency. In the best case which is an entirely empty node, an octree requires only one byte of space to encode that each of the 8 child-nodes are empty. A hexacontree will however require eight times the space, meaning 64 bits that are all 0 . In the worst case, which is noise that requires all nodes to be present, a tetrahexacontree is slightly more efficient because it requires only 8 bytes for two octree layers instead of 8+1 such as an octree. In conclusion, tetrahexacontrees can come with a significant space cost, while making better use of modern architectures. Depends on how much space is pre-allocated before the insertion of any voxels. Other data structures consume no space for such a pre-allocation. \u21a9","title":"Sparse Voxel Octree"},{"location":"svo/svo.html#sparse-voxel-octree","text":"An Octree - Source: Wikipedia , WhiteTimberwolf A sparse voxel octree is a data structure which stores voxels in a tree with a branching factor of 8, with its branches being potentially absent. Missing branches typically represent empty volumes where no voxels exist. The greater these volumes are, the closer to a the root of the tree can the branches be pruned. This results in a very efficient representation of models with a significant portion of empty space. Unlike with a voxel list, all positioning is implicit and results from the tree structure, meaning that no space has to be used for the storage of coordinates during serialization. Thus, octrees combine the two greatest advantages of voxel lists and voxel arrays: like lists, they waste little space on encoding empty voxels like for arrays, voxel coordinates are implicit and little space is wasted","title":"Sparse Voxel Octree"},{"location":"svo/svo.html#extreme-cases-and-limits","text":"To illustrate the following extreme cases, voxel arrays and voxel lists are also compared. The space complexity of three extreme cases is compared between the three data structures, where v is the amount of voxels. Voxel Array Voxel List Sparse Voxel Octree Empty O(1) 1 O(1) O(1) Tightly Filled O(v) O(4v) O(\\frac{8}{7} v) Stretched O(\\infty) O(1) O(\\infty)","title":"Extreme Cases And Limits"},{"location":"svo/svo.html#empty-octree","text":"Entirely empty models can be encoded using just the root note, which then encodes that no subtrees exist.","title":"Empty Octree"},{"location":"svo/svo.html#tightly-filled-octree","text":"Entirely filled models will have some overhead compared to an array of voxels. For every eight nodes, there is one parent node. We can calculate the maximum possible overhead by summing up this \\frac{1}{8} overhead infinitely: \\sum_{n=1}^\\infty{\\frac{1}{8}^n} = \\frac{1}{7} So at worst, our data will increase by \\frac{1}{7} , which is much better than a 100% increase such as for binary trees.","title":"Tightly Filled Octree"},{"location":"svo/svo.html#stretched-octree","text":"The stretched case is a case where a finite amount of voxels are placed infinitely far apart. For arrays, this produces infinite space requirements because all space between these points must be filled. For octrees, more layers are necessary to encode positions further from the origin. In neither case there is an upper bound to this. In practice, octrees perform significantly better at encoding sparse data than arrays.","title":"Stretched Octree"},{"location":"svo/svo.html#construction","text":"How an octree can be constructed from a list voxels is thorougly explained in SVO Construction .","title":"Construction"},{"location":"svo/svo.html#serialization","text":"To be used in a serial data format, octrees must first be serialized. Nodes will no longer be laid out \"randomly\" in memory but instead be arranged one after another. To fully encode an SVO, two steps must be performed: Linearize nodes by traversing the SVO's nodes in a deterministic, reversible order. Serialize each node to binary data.","title":"Serialization"},{"location":"svo/svo.html#traversal-order","text":"There are two well-known strategies for traversing trees completely: Depth-First Search (DFS) Breadth-First Search (BFS)","title":"Traversal Order"},{"location":"svo/svo.html#depth-first","text":"Tree, traversed depth-first - Source: Wikipedia , Alexander Drichel DFS can be performed using only a stack to keep track of the node number at each level. On the deepest level, the next node is chosen until the end is reached and the next parent node is chosen. This low memory cost (which is in fact O(\\log{n}) where n is the number of nodes) is highly advantageous when encoding enormous models.","title":"Depth-First"},{"location":"svo/svo.html#breadth-first","text":"Tree, traversed breadth first - Source: Wikipedia , Alexander Drichel BFS comes with a higher cost since a typical algorithm appends all branches to a queue for every traversed node. This means that in the worst case, which is at the beginning of serialization eight nodes are appended on every level before any node is popped from the queue, resulting in a higher memory cost.","title":"Breadth-First"},{"location":"svo/svo.html#node-encoding","text":"","title":"Node Encoding"},{"location":"svo/svo.html#single-bit-format","text":"0 stands for air-subtree 1 stands for partially or entirely filled voxel-subtree 8 Bits per octree-node, thus this format is byte-aligned.","title":"Single-Bit Format"},{"location":"svo/svo.html#15-bit-format","text":"00 stands for air-subtree 01 stands for solid subtree 1 stands for partially filled subtree Variable amount of bits per octree-node, neither bit- nor byte-aligned. On the last level (node = voxel), the single-bit format is used because there are no subtrees.","title":"1.5-Bit Format"},{"location":"svo/svo.html#2-bit-format","text":"00 stands for air-subtree 01 stands for solid subtree 10 stands for partially filled subtree 11 variable purpose","title":"2-Bit Format"},{"location":"svo/svo.html#11-for-rawarray-subtrees","text":"Useful to encode subtrees completely filled with high-entropy content. On the second-to-last level, 11 for raw-subtrees there is no difference between 10 and 11 , so reverting to the 1.5-bit format is viable. On the last level, the single-bit format should be used. As long as the 1.5-bit format is not used, this encoding is completely byte-aligned: * alignment to 16 -bit boundaries on most levels * alignment to 8 -bit boundaries on last level","title":"11 for Raw/Array Subtrees"},{"location":"svo/svo.html#11-for-pointers-to-subtrees-on-the-same-level","text":"Useful for encoding multiple similar subtrees. Similarities between structures could be effectively exploited. Verifying whether subtrees are equal down to the base level has very high complexity: O(n^2 * 8^n) . The comparison depth could be reduced down to a limited number of levels or the level number could be encoded next to the pointer: {u32 indexOfOtherTree, u8 depth} . Instead of the pointer, a tree could instead encode all the places where it is additionally used. This would make decoding easier, since remembering trees on the same level is not necessary.","title":"11 for Pointers to Subtrees on the Same Level"},{"location":"svo/svo.html#tetrahexacontrees","text":"This term comes from \"tetrahexaconta\" (Greek for 64) and \"tree\". It builds on the idea of octrees but expands the branching factor from 8 to 8 2 , or 64. A use of this concept can be seen in the VOLA file format. 64-bit architectures established themselves as the de-facto standard for desktop operating systems. Anecdotally, \"macOS Mojave would be the last version of macOS to run 32-bit apps\" - Apple . Thus, optimization of algorithms in the present day can be performed for 64-bit architectures without worrying about 32-bit users.","title":"Tetrahexacontrees"},{"location":"svo/svo.html#comparison-to-octrees","text":"Tetrahexacontrees encode two octree layers of depth in a single layer. CPU-performance wise, they fill exactly one 64-bit register with one node, using the architecture's capacities optimally unlike octrees. However, they sacrifice potential compression efficiency. In the best case which is an entirely empty node, an octree requires only one byte of space to encode that each of the 8 child-nodes are empty. A hexacontree will however require eight times the space, meaning 64 bits that are all 0 . In the worst case, which is noise that requires all nodes to be present, a tetrahexacontree is slightly more efficient because it requires only 8 bytes for two octree layers instead of 8+1 such as an octree. In conclusion, tetrahexacontrees can come with a significant space cost, while making better use of modern architectures. Depends on how much space is pre-allocated before the insertion of any voxels. Other data structures consume no space for such a pre-allocation. \u21a9","title":"Comparison to Octrees"}]}