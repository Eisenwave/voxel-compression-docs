{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Compression of Voxel Models This is the documentation of my research project at TU Dresden. This documentation was written using MkDocs . Warning You can browse this offline by hosting it as a static web page on a local server. Many functions such as searching or syntax highlighting won't work when opening this project with a file:// scheme. To name an example, use python3 -m http.server 8000 in the root directory to host this page locally on port 8000.","title":"Compression of Voxel Models"},{"location":"index.html#compression-of-voxel-models","text":"This is the documentation of my research project at TU Dresden. This documentation was written using MkDocs . Warning You can browse this offline by hosting it as a static web page on a local server. Many functions such as searching or syntax highlighting won't work when opening this project with a file:// scheme. To name an example, use python3 -m http.server 8000 in the root directory to host this page locally on port 8000.","title":"Compression of Voxel Models"},{"location":"attribute_compression.html","text":"SVO Attribute Compression Geometry is the most important attribute, as it gives the model shape. However, it does not inherently make up the majority of a model's information. Whether a voxel exists or not is only a single-bit information, whereas the colors are often times a 24-bit information. Add an alpha channel to that and various other material properties and it is plain to see that effort has to be put into compressing these attributes as well. Image-Based Approach Storing a 24-bit RGB color for every voxel would be very expensive. What some formats such as PNG instead do is store a delta between neighboring colors. Instead of storing deltas we could also store whether neighboring colors are exactly identical, but such a naive approach would become very ineffective when introducing small amounts of noise into the colors. Primer on PNG Filtering c|b -+- a|x x is the color to encode and a, b, c are its neighbors. In the Filtering Section of the PNG specification we can see that the colors are converted to a delta-based representation relative to their neighbors. This step however does not reduce the size of the data as \"both the inputs and outputs fit into bytes\". It is merely a pre-processing step which increases redundancy in the image bytes and thus improves DEFLATE compression, the next step . Problems in Three Dimensions Regardless of whether we want to naively store exact matches between neighbors or a delta, we run into the same problems. We might not always have a neighbor. We need to cache vast amounts of data to reference neighbors. In image formats at most, a pixel may have a zero-alpha value but it still exists in the data. In our octree format voxels might simply not exist at all. There is a distinct difference between an invisible voxel and a missing voxel. However, we could still treat missing voxels as zero-colors. Hence, this is the smaller of the problems. The latter problem is of higher significance. Due to our geometry encoding scheme, we would need to cache a significant portion of our model when reading it. For instance, a voxel which lies at the origin could reference three other octants as neighbors and obtain its colors from them. Therefore, we must cache these octants during the reading process. Image pixels are typically stored in such a way that you only need to store the previous and the current line to obtain the negative neighbors of any pixel. Since we are forced to store neighbors for random access, we have two options: Store neighbors in an array, having O(1) random access but O(\\infty) spatial cost Store neighbors in an octree, having O(\\log{n}) random access and O(v+\\log{v}) spatial cost Conclusion Our geometry-data is not arranged in a way that allows for fast random access of previously read neighbors and a low spatial cost. Unfortunately, we can thus not trivially extend traditional image-based approaches into three dimensions. We must use an approach which is coupled to the octree structure instead. Octree-Coupled Approach Figure 1: A Duck Model Observe the above figure. We can see that not only are there few colors in total, but we can see distinct shapes with an equal or similar color. As described in Properties of Voxel Models , voxels which are located closely to each other also tend to have similar colors. Our goal is to use the existing octree structure and add information to it, so that we encode attribute information for more than one voxel at a time. We exploit the fact that as we split up the model into smaller and smaller subtrees, the range of colors within that subtrees will also get narrower. By range we refer to a subsection of RGB-space. For example, the entire model or its root node has a color range from (24, 19, 17) to (212, 162, 17) . We can obtain this range using the component-wise minimum and maximum of all colors. Figure 2: The Octants of a Duck Model When we split up the model into multiple octants, we see narrower ranges for most octants. For example, octants 0, 1, 2, 3, 5 and 7 contain only yellow, which is (199, 162, 0) .","title":"SVO Attribute Compression"},{"location":"attribute_compression.html#svo-attribute-compression","text":"Geometry is the most important attribute, as it gives the model shape. However, it does not inherently make up the majority of a model's information. Whether a voxel exists or not is only a single-bit information, whereas the colors are often times a 24-bit information. Add an alpha channel to that and various other material properties and it is plain to see that effort has to be put into compressing these attributes as well.","title":"SVO Attribute Compression"},{"location":"attribute_compression.html#image-based-approach","text":"Storing a 24-bit RGB color for every voxel would be very expensive. What some formats such as PNG instead do is store a delta between neighboring colors. Instead of storing deltas we could also store whether neighboring colors are exactly identical, but such a naive approach would become very ineffective when introducing small amounts of noise into the colors.","title":"Image-Based Approach"},{"location":"attribute_compression.html#octree-coupled-approach","text":"Figure 1: A Duck Model Observe the above figure. We can see that not only are there few colors in total, but we can see distinct shapes with an equal or similar color. As described in Properties of Voxel Models , voxels which are located closely to each other also tend to have similar colors. Our goal is to use the existing octree structure and add information to it, so that we encode attribute information for more than one voxel at a time. We exploit the fact that as we split up the model into smaller and smaller subtrees, the range of colors within that subtrees will also get narrower. By range we refer to a subsection of RGB-space. For example, the entire model or its root node has a color range from (24, 19, 17) to (212, 162, 17) . We can obtain this range using the component-wise minimum and maximum of all colors. Figure 2: The Octants of a Duck Model When we split up the model into multiple octants, we see narrower ranges for most octants. For example, octants 0, 1, 2, 3, 5 and 7 contain only yellow, which is (199, 162, 0) .","title":"Octree-Coupled Approach"},{"location":"cuboid_extraction.html","text":"Cuboid Extraction Motivation Voxel models of certain types have large volumes of voxels. These types include extruded heightmaps, medical scans, video game worlds and voxel art. Other types such as voxelized polygonal models may also be filled up instead of being kept hollow. The volumes may often be misaligned with the octree structure. Consider a single 2x2x2 cube in the center of an octree. All 8 subtrees of the octree would have to encode an individual voxel of this cube, which is far from optimal. In addition, decoding volumes which are completely filled simplifies the decoding process. These volumes could be extracted and encoded as cuboids like {triple<u8> pos, triple<u8> size} within a container that has dimensions up to 256^3. However we extract cuboids, those should be as large in volume as possible. This way, we cover the most voxels with our pairs of positions. The highest-volume container should be found, then extracted and the next-highest-volume container found, etc. We invest 6 bytes into the extraction, so our volume needs to be 48 to break even (e.g. 4x4x3 ). Absolutely Stupid Method extreme complexity but optimal results Since a cuboid is just a pair of positions, we can simply iterate over all pairs of positions. We then iterate over all voxels in the cuboid to test whether they exist. For a d*d*d model containing v voxels the complexity is thus O(d^3 * d^3 * d^3) or O(d^9) or O(v^3) . This is some clown-world-tier complexity and should not find its way into any serious implementation. Due to its simplicity, it could be used to verify the correctness of more complex approaches though. XYZ-Merge best possible complexity not optimal An XYZ-merge works by merging all neighboring voxels into lines on one axis first. Then neighboring lines are merged into planes on the second axis. Then neighboring planes are merged into cuboids on the last axis. The results are not optimal and may differ depending on the order of axes. At worst, we can't merge anything and thus iterate over every voxel in each of the steps once. The complexity is O(d^3 * 3) = O(d^3) or O(v) . Heightmap-Based Approaches All following approaches are based on the idea, that we can simplify this problem to a 2-dimensional one. One axis is being used as a height-axis, ideally the smallest one if the model is not cubical. We then use a sweeping-plane approach where at each coordinate, we draw a heightmap which extends into our chosen direction. Finding the largest volume in the model is reduced to finding the maximum of the largest volumes for all heightmaps. Constructing Heightmaps from Voxel-Models Here is an illustration of how this is done, in 2 dimensions, where \"up\" in text is the height axis: 0123456789 0123456789 7 ### -> 1110000000 6 #### ## # -> 2221011010 5 ## ### # # -> 3302120101 4 ##### # ## -> 4413201012 3 ## # # # -> 5504010100 2 ######## -> 6612121200 1 ######### -> 7726232310 0 ## ## #### -> 8807303420 In this illustration, # would be encoded as 1 and would be encoded as 0 Each slice from 0 to 7 is one histogram in 2 dimensions or a heightmap in 3 dimensions. We can construct these very efficiently by just taking the heightmap at one height above and incrementing each height, unless we find an empty voxel ( 0 ). Constructing Bitmaps from Heightmaps Finding the largest cuboid in a voxel-model has been reduced to finding the largest cuboid in all its heightmaps. The problem is once again reduced to finding the largest area of 1 s in a bitmap, which can be done in O(n*n) . This is done by looking at all different height-values of the heightmap. At every height, a bitmap is constructed. In our bitmap of equal dimensions, 1 represents that the height at the location is >= the height. Example: 389200 111000 323350 ------> 101110 500020 (h=3) 100000 211141 000010 Finding the largest area of 1 in an n*n rectangle has O(n^2) complexity or O(1) per pixel, when using a sweeping-line algorithm and searching for the greatest area in the resulting histograms: https://www.geeksforgeeks.org/maximum-size-rectangle-binary-sub-matrix-1s/ The volume of the greatest cuboid is then the current height multiplied with the size of the greatest area of 1 which we find. Expected values To understand the following approaches, one must realize that the highest cuboid is not necessarily the largest. For example, a very flat pyramid may have a shape which is only great in volume towards the base. For an n*n heightmap with n height, we can find the cuboid with the largest volume for all heights by finding the largest cuboid at each individual height. This forces us to check every single height. Naive Method high complexity optimal results The naive method simply to iterate over all heights. We then require O(d^2 * d^2) complexity where one d^2 represents the size of the base and the other d^2 represents the amount of pairs of heights. This would be O(v^(4/3)) , which is not as bad as the stupid approach but still polynomial. Modified Kadane's-Algorithm THIS SECTION IS WIP - complexity yet unknown - hopefully optimal results This can be done by using a sweeping-plane algorithm, where each plane is a heightmap which encodes how many voxels extrude upwards, starting from each one of its pixels. The problem is thus reduced to finding the greatest cuboid on a heightmap, which can be done somewhat efficiently using Kadane's algorithm, where any `0` is treated as negative infinity and the heights are cut-off at some maximum height dynamically during the search. For a `n*n` map, Kadane's algorithm has a complexity of `O(n^3)` or `O(n)` per pixel. Whether this is usable has to be investigated further. Golden-Section-Search (not sure if this actually works) best known complexity optimal We can achieve logarithmic complexity per voxel. The approach to this is very similar to the naive method, but based on a crucial observation. The maximum volumes at each minimum height form a unimodal function. Our search is still based on finding the greatest are of 1 in a bitmap, but we choose our heights in a smarter way instead of iterating over all heights. Consider a histogram such as: ^ 7| # 6|# # # 5|# # ### # # 4|# # ### ## ### ## # 3|# ## ### ### ### ####### ## 2|#### ### ### #### ### ####### ### 1|##### #### ### ##### ############### #### -+----------------------------------------------> |0123456789abcdefghijklmnopqrstuvwxyzABCDEFGH The greatest areas for each height are: 7: 07 (3:1, 3:7) 6: 07 (3:1, 3:7) found by extruding (3:1, 3:6) >>5: 15 (8:1, a:5) >>4: 15 (8:1, a:5) >>>>3: 21 (w:1, C:3) >>>>2: 21 (w:1, C:3) >>1: 15 (o:1, C:1) Note that the maximum volumes at each height only form a unimodal function if we extrude our found area as far up as possible. Searching for the maximum or minimum of a unimodal function can be done with logarithmic complexity. The final complexity would thus be O(n^2 * log_2 n) or O(log_2 n) per pixel.","title":"Cuboid Extraction"},{"location":"cuboid_extraction.html#cuboid-extraction","text":"","title":"Cuboid Extraction"},{"location":"cuboid_extraction.html#motivation","text":"Voxel models of certain types have large volumes of voxels. These types include extruded heightmaps, medical scans, video game worlds and voxel art. Other types such as voxelized polygonal models may also be filled up instead of being kept hollow. The volumes may often be misaligned with the octree structure. Consider a single 2x2x2 cube in the center of an octree. All 8 subtrees of the octree would have to encode an individual voxel of this cube, which is far from optimal. In addition, decoding volumes which are completely filled simplifies the decoding process. These volumes could be extracted and encoded as cuboids like {triple<u8> pos, triple<u8> size} within a container that has dimensions up to 256^3. However we extract cuboids, those should be as large in volume as possible. This way, we cover the most voxels with our pairs of positions. The highest-volume container should be found, then extracted and the next-highest-volume container found, etc. We invest 6 bytes into the extraction, so our volume needs to be 48 to break even (e.g. 4x4x3 ).","title":"Motivation"},{"location":"cuboid_extraction.html#absolutely-stupid-method","text":"extreme complexity but optimal results Since a cuboid is just a pair of positions, we can simply iterate over all pairs of positions. We then iterate over all voxels in the cuboid to test whether they exist. For a d*d*d model containing v voxels the complexity is thus O(d^3 * d^3 * d^3) or O(d^9) or O(v^3) . This is some clown-world-tier complexity and should not find its way into any serious implementation. Due to its simplicity, it could be used to verify the correctness of more complex approaches though.","title":"Absolutely Stupid Method"},{"location":"cuboid_extraction.html#xyz-merge","text":"best possible complexity not optimal An XYZ-merge works by merging all neighboring voxels into lines on one axis first. Then neighboring lines are merged into planes on the second axis. Then neighboring planes are merged into cuboids on the last axis. The results are not optimal and may differ depending on the order of axes. At worst, we can't merge anything and thus iterate over every voxel in each of the steps once. The complexity is O(d^3 * 3) = O(d^3) or O(v) .","title":"XYZ-Merge"},{"location":"cuboid_extraction.html#heightmap-based-approaches","text":"All following approaches are based on the idea, that we can simplify this problem to a 2-dimensional one. One axis is being used as a height-axis, ideally the smallest one if the model is not cubical. We then use a sweeping-plane approach where at each coordinate, we draw a heightmap which extends into our chosen direction. Finding the largest volume in the model is reduced to finding the maximum of the largest volumes for all heightmaps.","title":"Heightmap-Based Approaches"},{"location":"cuboid_extraction.html#naive-method","text":"high complexity optimal results The naive method simply to iterate over all heights. We then require O(d^2 * d^2) complexity where one d^2 represents the size of the base and the other d^2 represents the amount of pairs of heights. This would be O(v^(4/3)) , which is not as bad as the stupid approach but still polynomial.","title":"Naive Method"},{"location":"cuboid_extraction.html#modified-kadanes-algorithm","text":"THIS SECTION IS WIP - complexity yet unknown - hopefully optimal results This can be done by using a sweeping-plane algorithm, where each plane is a heightmap which encodes how many voxels extrude upwards, starting from each one of its pixels. The problem is thus reduced to finding the greatest cuboid on a heightmap, which can be done somewhat efficiently using Kadane's algorithm, where any `0` is treated as negative infinity and the heights are cut-off at some maximum height dynamically during the search. For a `n*n` map, Kadane's algorithm has a complexity of `O(n^3)` or `O(n)` per pixel. Whether this is usable has to be investigated further.","title":"Modified Kadane's-Algorithm"},{"location":"cuboid_extraction.html#golden-section-search-not-sure-if-this-actually-works","text":"best known complexity optimal We can achieve logarithmic complexity per voxel. The approach to this is very similar to the naive method, but based on a crucial observation. The maximum volumes at each minimum height form a unimodal function. Our search is still based on finding the greatest are of 1 in a bitmap, but we choose our heights in a smarter way instead of iterating over all heights. Consider a histogram such as: ^ 7| # 6|# # # 5|# # ### # # 4|# # ### ## ### ## # 3|# ## ### ### ### ####### ## 2|#### ### ### #### ### ####### ### 1|##### #### ### ##### ############### #### -+----------------------------------------------> |0123456789abcdefghijklmnopqrstuvwxyzABCDEFGH The greatest areas for each height are: 7: 07 (3:1, 3:7) 6: 07 (3:1, 3:7) found by extruding (3:1, 3:6) >>5: 15 (8:1, a:5) >>4: 15 (8:1, a:5) >>>>3: 21 (w:1, C:3) >>>>2: 21 (w:1, C:3) >>1: 15 (o:1, C:1) Note that the maximum volumes at each height only form a unimodal function if we extrude our found area as far up as possible. Searching for the maximum or minimum of a unimodal function can be done with logarithmic complexity. The final complexity would thus be O(n^2 * log_2 n) or O(log_2 n) per pixel.","title":"Golden-Section-Search (not sure if this actually works)"},{"location":"properties.html","text":"Properties of Voxel Models The cornerstone of compression is discovering and eliminating redundancies in data. We must first recognize these redundancies by observing the nature of voxel models. There are plenty of properties which we can exploit, as described in the following sections. Geometric/Spatial Locality Normalized 3D Perlin Noise with a threshold of 0.4 Voxels rarely come alone. All 3D models will typically take some distinguished shape. There will be large areas with filled geometry (voxels) and large empty areas, air , or void . In artistic circles these are often described as negative space . Uniform voxel noise with a probability of 0.1 that a voxel is set The only kind of model which has no spatial locality whatsoever would be uniformly distributed noise. (see above) These kinds of models are the absolute exception and are rarely if ever seen. Conclusion Compression schemes have to be able to describe large volumes of positive and negative space efficiently. Color/Attribute Locality \"Ragged Cluster\" model visualized in Magica Voxel Color and other attributes such as normals correlate with geometry. This means that the color distance between neighboring voxels is significantly lower than the distance of random points in RGB space. In fact, this correlation is dramatically high. For the above model, the average euclidean distance of any unique pair of neighboring voxel colors (0, 0, 0) \\le (r, g, b) \\le (255, 255, 255) is 8.56 . Normalized for positions in a unit cube instead this is 0.03357 . For uniform random colors, this distance would be equal to Robbin's Constant which is roughly equal to 0.66170 , almost 20 times higher. Conclusion Compression schemes should make use of geometric encoding and attach attributes on top of that. Alternatively voxel compression schemes should encode attributes in a fashion very similar to geometry. Color Sparsity While in principle, plenty of software supports 24-bit True Color RGB or even wider standards, only a small amount of colors are actually used. Especially in the field of Voxel Art , the 3D-equivalent to Pixel Art , small palettes are used. To name an example, Magica Voxel supports 255 unique colors but each individual color is a 24-bit True Color. Conclusion Compression schemes should be aware of potentially very low color counts and exploit these by building a palette. A palette will not always be beneficial since in principle, any amount of colors should be present. However, in many cases this will be beneficial.","title":"Properties of Voxel Models"},{"location":"properties.html#properties-of-voxel-models","text":"The cornerstone of compression is discovering and eliminating redundancies in data. We must first recognize these redundancies by observing the nature of voxel models. There are plenty of properties which we can exploit, as described in the following sections.","title":"Properties of Voxel Models"},{"location":"properties.html#geometricspatial-locality","text":"Normalized 3D Perlin Noise with a threshold of 0.4 Voxels rarely come alone. All 3D models will typically take some distinguished shape. There will be large areas with filled geometry (voxels) and large empty areas, air , or void . In artistic circles these are often described as negative space . Uniform voxel noise with a probability of 0.1 that a voxel is set The only kind of model which has no spatial locality whatsoever would be uniformly distributed noise. (see above) These kinds of models are the absolute exception and are rarely if ever seen.","title":"Geometric/Spatial Locality"},{"location":"properties.html#colorattribute-locality","text":"\"Ragged Cluster\" model visualized in Magica Voxel Color and other attributes such as normals correlate with geometry. This means that the color distance between neighboring voxels is significantly lower than the distance of random points in RGB space. In fact, this correlation is dramatically high. For the above model, the average euclidean distance of any unique pair of neighboring voxel colors (0, 0, 0) \\le (r, g, b) \\le (255, 255, 255) is 8.56 . Normalized for positions in a unit cube instead this is 0.03357 . For uniform random colors, this distance would be equal to Robbin's Constant which is roughly equal to 0.66170 , almost 20 times higher.","title":"Color/Attribute Locality"},{"location":"properties.html#color-sparsity","text":"While in principle, plenty of software supports 24-bit True Color RGB or even wider standards, only a small amount of colors are actually used. Especially in the field of Voxel Art , the 3D-equivalent to Pixel Art , small palettes are used. To name an example, Magica Voxel supports 255 unique colors but each individual color is a 24-bit True Color.","title":"Color Sparsity"},{"location":"statistical_tests.html","text":"Statistical Tests to Determine Voxel Model Properties The following list should give an overview over possible properties which voxel models are suspected to have. A description of an algorithm and/or pseudocude is used to provide a potential test. Spatial Locality of Different Methods of Iteration Over Voxel Models There are various different ways of iterating over a voxel model. We will consider only two or three, which are relevant to us. Nested Loop Iteration This is the traditional method of iterating over multi-dimensional arrays. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[x][y][z]; It is extremely efficient for traversing memory because it seemlessly iterates over memory locations, as long as the axes of iteration are in the right order. The distances between two positions are at best 1 and at worst SIZE_X + SIZEY . However, the spatial locality is much worse when looking at more than one position. For say, 10 positions the distance between the first and last will be 10, which is comparably far. Z-Order Iteration Z-Order iteration traverses space with much higher locality. It works by traversing all nodes of an octree depth-first. 3D-Vectors can be converted into \"octree positions\" by interleaving the bits of the coordinates into a single number. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[interleave_bits(x, y, z)]; ) Hilbert-Curve Iteration Hilbert-Curves have even higher locality than Z-Order iterations, but are considerably better in locality. See https://slideplayer.com/slide/3370293/ for construction. In short, space is filled in the following order, which is a Gray Code. [[0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 0]] The entry direction for one of these pieces is +Z and the exit-direction is -Y. This pattern is repeated recursively, but the smaller building blocks have to be mirrored and rotated to fit together seemlessly into a larger block. The tremendously useful property here is that the distance between two points in the iteration is at most 1 . Testing Spatial Locality Spatial locality can simply be tested by comparing the average distance between each pair of points, triple of points, etc. within an iteration. When more than two points are tested, the distances of each unique pair of points can be summed up or averaged. Hilber-Curve Iteration is expected to deliver the best results on most, if not all scales. Correlation of Color and Geometry Deltas It is expected that color correlates with positions. This means that positions which are close to each other should also have similar colors. To verify this property, each unique pair of points can be iterated over. The euclidean distance in geometry-space (scaled down to a unit-cube) as well as the euclidean distance in the RGB color space should be plotted. The correlation can then be calculated from all data entries. struct Entry { double geoDistance; double colDistance; }; struct ColoredPoint { vec3 geo; vec3 col; } std::vector<double[2]> entries; for (const std::pair<ColoredPoint, ColoredPoint> &pair : allPoints) { double geoDistance = pair.first.geo.distanceTo(pair.second.geo); double colDistance = pair.first.col.distanceTo(pair.second.col); entries.emplace_back(geoDistance, colDistance); }","title":"Statistical Tests to Determine Voxel Model Properties"},{"location":"statistical_tests.html#statistical-tests-to-determine-voxel-model-properties","text":"The following list should give an overview over possible properties which voxel models are suspected to have. A description of an algorithm and/or pseudocude is used to provide a potential test.","title":"Statistical Tests to Determine Voxel Model Properties"},{"location":"statistical_tests.html#spatial-locality-of-different-methods-of-iteration-over-voxel-models","text":"There are various different ways of iterating over a voxel model. We will consider only two or three, which are relevant to us.","title":"Spatial Locality of Different Methods of Iteration Over Voxel Models"},{"location":"statistical_tests.html#correlation-of-color-and-geometry-deltas","text":"It is expected that color correlates with positions. This means that positions which are close to each other should also have similar colors. To verify this property, each unique pair of points can be iterated over. The euclidean distance in geometry-space (scaled down to a unit-cube) as well as the euclidean distance in the RGB color space should be plotted. The correlation can then be calculated from all data entries. struct Entry { double geoDistance; double colDistance; }; struct ColoredPoint { vec3 geo; vec3 col; } std::vector<double[2]> entries; for (const std::pair<ColoredPoint, ColoredPoint> &pair : allPoints) { double geoDistance = pair.first.geo.distanceTo(pair.second.geo); double colDistance = pair.first.col.distanceTo(pair.second.col); entries.emplace_back(geoDistance, colDistance); }","title":"Correlation of Color and Geometry Deltas"},{"location":"uncompressed.html","text":"Uncompressed Format The uncompressed format used for reference in this project is a 32-bit list of voxels. In this case a voxel is a triple of coordinates and an ARGB integer, meaning that voxels can be partially transparent. Example Implementation Here is a simple example implementation of a 32-bit voxel list in C++. struct voxel { int32_t x; int32_t y; int32_t z; uint8_t a; uint8_t r; uint8_t g; uint8_t b; } std::vector<voxel> voxel_list; Justification - Voxel Arrays vs. Voxel Lists There are at least two popular methods of representing voxels in an uncompressed way: 3D-array of colors, aka. voxel array array of coordinate/color pairs, aka. voxel list The first method is often used in software on a small scale. Arrays allow for random access in O(1) . They are also used in other research, such as High Resolution Sparse Voxel DAGs . Despite its popularity, arrays are unsuitable for measuring compression ratios because the entropy of the voxel data poorly correlates with the size of this representation. For instance, two voxels at (1, 1, 1) and (1000, 1000, 1000) require 1 gigavoxel of space due to all the empty space between the two voxels. However, in the best case where all voxels are present, this method has only constant overhead: that which is necessary to store the dimensions of the array. The second representation -which is the one used here- will require space that linearly scales with the amount of non-empty voxels. Note that in the worst case, this could require four times the space of the first method due to the coordinates being stored explicitly. This kind of overhead is still preferable to the potential (near) complete waste of space of the first method. To summarize, here is a quick overview: Voxel Array Voxel List worst case overhead (space) O(\\infty) 1 O(4n) 2 best case overhead (space) \\Omega(1) \\Omega(4n) 2 random access (time) O(1) O(n) Serialization Serialization of this representation is trivial because the data structure in memory is similar of not identical to its serialized counterpart. Here, the VL32 file format is used. Unbounded because two voxels can be infinitely far apart, creating infinite wasted space / overhead \u21a9 The constant factor of 4 is irrelevant in this notation, but illustrates the extent of the overhead \u21a9 \u21a9","title":"Uncompressed Format"},{"location":"uncompressed.html#uncompressed-format","text":"The uncompressed format used for reference in this project is a 32-bit list of voxels. In this case a voxel is a triple of coordinates and an ARGB integer, meaning that voxels can be partially transparent.","title":"Uncompressed Format"},{"location":"uncompressed.html#example-implementation","text":"Here is a simple example implementation of a 32-bit voxel list in C++. struct voxel { int32_t x; int32_t y; int32_t z; uint8_t a; uint8_t r; uint8_t g; uint8_t b; } std::vector<voxel> voxel_list;","title":"Example Implementation"},{"location":"uncompressed.html#justification-voxel-arrays-vs-voxel-lists","text":"There are at least two popular methods of representing voxels in an uncompressed way: 3D-array of colors, aka. voxel array array of coordinate/color pairs, aka. voxel list The first method is often used in software on a small scale. Arrays allow for random access in O(1) . They are also used in other research, such as High Resolution Sparse Voxel DAGs . Despite its popularity, arrays are unsuitable for measuring compression ratios because the entropy of the voxel data poorly correlates with the size of this representation. For instance, two voxels at (1, 1, 1) and (1000, 1000, 1000) require 1 gigavoxel of space due to all the empty space between the two voxels. However, in the best case where all voxels are present, this method has only constant overhead: that which is necessary to store the dimensions of the array. The second representation -which is the one used here- will require space that linearly scales with the amount of non-empty voxels. Note that in the worst case, this could require four times the space of the first method due to the coordinates being stored explicitly. This kind of overhead is still preferable to the potential (near) complete waste of space of the first method. To summarize, here is a quick overview: Voxel Array Voxel List worst case overhead (space) O(\\infty) 1 O(4n) 2 best case overhead (space) \\Omega(1) \\Omega(4n) 2 random access (time) O(1) O(n)","title":"Justification - Voxel Arrays vs. Voxel Lists"},{"location":"uncompressed.html#serialization","text":"Serialization of this representation is trivial because the data structure in memory is similar of not identical to its serialized counterpart. Here, the VL32 file format is used. Unbounded because two voxels can be infinitely far apart, creating infinite wasted space / overhead \u21a9 The constant factor of 4 is irrelevant in this notation, but illustrates the extent of the overhead \u21a9 \u21a9","title":"Serialization"},{"location":"dag/dag.html","text":"Directed Acyclic Graph Figure 1: A Directed Acyclic Graph Directed Acyclic Graphs (DAGs) for voxel encoding build on the idea of octrees. However, they allow nodes to reference the branches of other nodes. How this may work can be seen in Figure 1 . The second branch of the root node stores a +4 . This +4 points four nodes ahead, on the same level in the graph and tells the decoder \"this node has the same content\" as the node four positions ahead. It is a four because there are three zero bits in the root node between this node and the one it points to.","title":"Directed Acyclic Graph"},{"location":"dag/dag.html#directed-acyclic-graph","text":"Figure 1: A Directed Acyclic Graph Directed Acyclic Graphs (DAGs) for voxel encoding build on the idea of octrees. However, they allow nodes to reference the branches of other nodes. How this may work can be seen in Figure 1 . The second branch of the root node stores a +4 . This +4 points four nodes ahead, on the same level in the graph and tells the decoder \"this node has the same content\" as the node four positions ahead. It is a four because there are three zero bits in the root node between this node and the one it points to.","title":"Directed Acyclic Graph"},{"location":"file_formats/structlang.html","text":"Structure Language (StructLang) StructLang is a data specification language used within the scope of this project. It uses a syntax similar to Rust and C to mathematically specify a syntax for binary data. Comments Comments begin with a // and continue until the end of the line. Alternatively, a comment block which begins with /* and ends with */ can be used. Settings Some global settings may be necessary to write a proper specification. Syntax set = \"set\" identifier \"=\" value; Examples set byte_bits = 32 set default_byte_order = big_endian set default_signed_representation = twos_complement List of Settings Identifier Type Description byte_bits unsigned integer number of bits in one byte default_byte_order modifier default byte order (endianness) of types default_signed_representation modifier default representation of signed integers Type Definitions Definitions define data types. Syntax def = \"def\" type \"=\" {modifier} base_type; type is the identifier of the type modifier a type modifier base_type the base type which this type is specializing Example def i32 = signed 32_bit twos_complement integer def u8 = unsigned 8_bit integer def string = null_terminated u8[] Arrays Arrays are blocks of one type which are stored using a single variable. Syntax array_type = type \"[\" size | \"\" \"]\"; Examples u8[4096] buffer // a constant-sized array u32 size u8[size] var_buffer // a variable-sized array u8[] endless_buffer // an array which extends until the end of the data Structures Defines a structure of other types. These types can also be structures. The first (uppermost) type in a struct is also the first element in the serialized data. Syntax struct = \"struct\" identifier \"{\" type identifier ... \"}\"; Example struct Color { u8 red u8 green u8 blue } Enumerations Defines a list of constants of some type. Syntax enum = \"enum\", identifier, \":\", type, \"{\", {identifier, \"=\", value}, \"}\"; Examples enum Size : string { SMALL = \"S\" MEDIUM = \"M\" LARGE = \"L\" EXTRA_LARGE = \"XL\" } enum ArgbColor : u32 { RED = 0xffff0000 GREEN = 0xff00ff00 BLUE = 0xff0000ff } Templated Structures Sometimes a structure depends on content found in a header or other structures. Templates can change how a structure is laid out using variables. Syntax struct = \"struct\" type \"<\" type {identifier \",\"} \">\" \"{\" ... \"}\"; Example struct varint<u8 bits> { if bits == 8 { u8 data } else if bits == 16 { u16 data } else if bits == 32 { u32 data } else { error \"Invalid bits variable\" } }","title":"Structure Language (StructLang)"},{"location":"file_formats/structlang.html#structure-language-structlang","text":"StructLang is a data specification language used within the scope of this project. It uses a syntax similar to Rust and C to mathematically specify a syntax for binary data.","title":"Structure Language (StructLang)"},{"location":"file_formats/structlang.html#comments","text":"Comments begin with a // and continue until the end of the line. Alternatively, a comment block which begins with /* and ends with */ can be used.","title":"Comments"},{"location":"file_formats/structlang.html#settings","text":"Some global settings may be necessary to write a proper specification.","title":"Settings"},{"location":"file_formats/structlang.html#type-definitions","text":"Definitions define data types.","title":"Type Definitions"},{"location":"file_formats/structlang.html#arrays","text":"Arrays are blocks of one type which are stored using a single variable.","title":"Arrays"},{"location":"file_formats/structlang.html#structures","text":"Defines a structure of other types. These types can also be structures. The first (uppermost) type in a struct is also the first element in the serialized data.","title":"Structures"},{"location":"file_formats/structlang.html#enumerations","text":"Defines a list of constants of some type.","title":"Enumerations"},{"location":"file_formats/structlang.html#templated-structures","text":"Sometimes a structure depends on content found in a header or other structures. Templates can change how a structure is laid out using variables.","title":"Templated Structures"},{"location":"file_formats/vl32.html","text":"32-Bit Voxel List (VL32) VL32 is a simple, binary, intermediate file format used in the code of this research project. Extension: .vl32 Media Type: model/x-vl32 Specification VL32 can be specified in only a few lines of StructLang: def u8 = unsigned 8_bit integer def i32 = big_endian twos_complement 32_bit integer struct main { voxel[] voxels } struct voxel { i32 x i32 y i32 z argb32 color } struct argb32 { u8 alpha u8 red u8 green u8 blue } Voxels with a color that has an alpha of zero are treated as void. Use Case VL32 is largely used for benchmarking compression efficiency. Any compression effort should yield significantly higher entropy than this format. One of the significant advantages is that there doesn't need to be any header information. When reading, voxels are simply loaded until the EOF is reached. Also there is no difference in data size between the file encoded on disk and its typical in-memory representation, such as a std::vector of voxels.","title":"32-Bit Voxel List (VL32)"},{"location":"file_formats/vl32.html#32-bit-voxel-list-vl32","text":"VL32 is a simple, binary, intermediate file format used in the code of this research project. Extension: .vl32 Media Type: model/x-vl32","title":"32-Bit Voxel List (VL32)"},{"location":"file_formats/vl32.html#specification","text":"VL32 can be specified in only a few lines of StructLang: def u8 = unsigned 8_bit integer def i32 = big_endian twos_complement 32_bit integer struct main { voxel[] voxels } struct voxel { i32 x i32 y i32 z argb32 color } struct argb32 { u8 alpha u8 red u8 green u8 blue } Voxels with a color that has an alpha of zero are treated as void.","title":"Specification"},{"location":"file_formats/vl32.html#use-case","text":"VL32 is largely used for benchmarking compression efficiency. Any compression effort should yield significantly higher entropy than this format. One of the significant advantages is that there doesn't need to be any header information. When reading, voxels are simply loaded until the EOF is reached. Also there is no difference in data size between the file encoded on disk and its typical in-memory representation, such as a std::vector of voxels.","title":"Use Case"},{"location":"file_formats/vlascii.html","text":"ASCII Voxel List (VLASCII) VLASCII is a simple, text-based, intermediate file format used in the code of this research project. Extension: .vlascii Media Type: model/x-vlascii Specification Here the specification, in EBNF . vlascii = { line }; (* lines can be empty *) line = [comment | voxel], {\" \"}, nl; (* trailing space allowed *) comment = \"#\", { ?any character? } - nl; voxel = xyz, space, color, space; xyz = integer, space, integer, space, integer; color = (h, h, h, h, h, h) | (h, h, h); h = ?hexadecimal digit?; integer = [\"-\"], ?decimal digit?, { ?decimal digit? }; nl = ?newline character?; space = \" \", { \" \" }; Example # red voxel at 0, 0, 0 0 0 0 ff0000 # white voxel at 0, 1, 0 0 1 0 fff # black voxel at 0, 0, 1 0 0 1 000","title":"ASCII Voxel List (VLASCII)"},{"location":"file_formats/vlascii.html#ascii-voxel-list-vlascii","text":"VLASCII is a simple, text-based, intermediate file format used in the code of this research project. Extension: .vlascii Media Type: model/x-vlascii","title":"ASCII Voxel List (VLASCII)"},{"location":"file_formats/vlascii.html#specification","text":"Here the specification, in EBNF . vlascii = { line }; (* lines can be empty *) line = [comment | voxel], {\" \"}, nl; (* trailing space allowed *) comment = \"#\", { ?any character? } - nl; voxel = xyz, space, color, space; xyz = integer, space, integer, space, integer; color = (h, h, h, h, h, h) | (h, h, h); h = ?hexadecimal digit?; integer = [\"-\"], ?decimal digit?, { ?decimal digit? }; nl = ?newline character?; space = \" \", { \" \" };","title":"Specification"},{"location":"file_formats/vlascii.html#example","text":"# red voxel at 0, 0, 0 0 0 0 ff0000 # white voxel at 0, 1, 0 0 1 0 fff # black voxel at 0, 0, 1 0 0 1 000","title":"Example"},{"location":"flvc/flvc.html","text":"Free Lossless Voxel Compression (FLVC) FLVC is the file format produced based on the results of the presented research. Extension: .flvc Media Type: model/x-flvc Magic Bytes: \"\\xff\\x11\\x33\\xccflvc\" = ff 11 33 cc 66 6c 76 63 Specification StructLang Type Definitions def u8 = unsigned integer<8> def u16 = big_endian unsigned integer<16> def u32 = big_endian unsigned integer<32> def u64 = big_endian unsigned integer<64> def i8 = twos_complement integer<8> def i16 = big_endian twos_complement integer<16> def i32 = big_endian twos_complement integer<32> def i64 = big_endian twos_complement integer<64> def ascii = unsigned hi_pad integer<7> Enumerations And Constants enum attribute_modifier : u16 { // this attribute has no spatial locality // should be used for random unique ids etc. NON_LOCAL = 1 // only applicable to the \"color\" attribute // whatever color model is used, alpha will be appended to it last // ARGB is the default, in which alpha is first ALPHA_LAST = 2 } enum attribute_type : u8 { BOOL = 0x00 INT_8 = 0x11 INT_16 = 0x12 INT_32 = 0x13 INT_64 = 0x14 UINT_8 = 0x21 UINT_16 = 0x22 UINT_32 = 0x23 UINT_64 = 0x24 FLOAT_32 = 0x41 FLOAT_64 = 0x42 } enum builtin_identifiers : string16 { // attributes will be used as the color of the voxel COLOR = \"color\" // attributes will be used as the normal of the voxel NORMAL = \"normal\" } Helper Structs struct vec3<T> { T x T y T z } struct string16 { u16 size ascii[size] content } Note that vec3 is a template. e.g. vec3<u32> would be a vec3 of u32 . File Structure struct main { u64 magic = 0xff11_33cc_666c_7663 u8 version_major = 0 u8 version_minor = 1 header header content content } struct header { u16 attribute_count attribute_definition[attribute_count] attributes // Global offset which is applied to all voxels which we read. vec3<i32> offset // The size of the SVO. vec3<u32> size } struct attribute_definition { // bitmap storing all modifiers u16 modifier_map // type of the attribute attribute_type atype // Must be <= 3. // If not zero, this indicates that the type is a fixed-size array-type or vector-type. // If zero, the type is a variable sized-array. u8 cardinality // unique identifier of the attribute // certain values such as \"color\" are builtin and reserved // (see enum builtin_identifiers) string16 identifier } header.size is not strictly necessary for decoding, but it can be helpful when converting directly to a 3D array or other format which requires a size upon construction. The attribute definition allows us to practically store any data we want inside of the format. For example, store an RGB24 value: modifier_map = SERIAL atype = UINT_8 cardinality = 3 identifier = \"color\" struct content { u64 node_count extern svo_data svo_data } The actual svo_data is too complex to be expressed in StructLang.","title":"Free Lossless Voxel Compression (FLVC)"},{"location":"flvc/flvc.html#free-lossless-voxel-compression-flvc","text":"FLVC is the file format produced based on the results of the presented research. Extension: .flvc Media Type: model/x-flvc Magic Bytes: \"\\xff\\x11\\x33\\xccflvc\" = ff 11 33 cc 66 6c 76 63","title":"Free Lossless Voxel Compression (FLVC)"},{"location":"flvc/flvc.html#specification","text":"","title":"Specification"},{"location":"related/literature.html","text":"References Literature Efficient Sparse Voxel Octrees Authors: Samuli Laine, Tero Karras Publisher: NVIDIA Research Publication Date: 2010-02-01 Published in: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) Links: NVIDIA Research , PDF Last Viewed: 2020-05-04 Geometry and Attribute Compression for Voxel Scenes Authors: Bas Dado, Timothy R. Kol, Pablo Bauszat, Jean-Marc Thiery, Elmar Eisemann Publisher: Delft University of Technology Publication Date: 2015-12-16 Also published in: EUROGRAPHICS 2016, Volume 35 (2016), Number 2 Links: TUDelft , PDF Last Viewed: 2020-05-04 High Resolution Sparse Voxel DAGs Authors: Viktor Ka\u0308mpe, Erik Sintorn, Ulf Assarsson Publisher: Chalmers University of Technology Publication Date: 2013-07 Published in: ACM Transactions on Graphics , Vol 32, No. 4 Links: ACM Digital Library , PDF Last Viewed: 2020-05-04 VOLA: A Compact Volumetric Format for 3D Mapping and Embedded Systems Authors: Jonathan Byrne, Le\u0301onie Buckley, Sam Caulfield, David Moloney Publisher: Advanced Architecture Group, Intel, Ireland Publication Date: 2018-01 Conference: 4th International Conference on Geographical Information Systems Theory, Applications and Management Published in: Proceedings of the 4th International Conference on Geographical Information Systems Theory, Applications and Management - Volume 1: GISTAM Links: Researchgate , PDF Last Viewed: 2020-05-04 Symmetry-aware Sparse Voxel DAGs (SSVDAGs) for compression-domain tracing of high-resolution geometric scenes Authors: Alberto Jaspe Villanueva, Fabio Marton, Enrico Gobbetti, CRS4 Publication Date: 2017-05-12 Published In: Journal of Computer Graphics Techniques (JCGT), vol. 6, no. 2 Links: Computer Graphics Techniques , Full-Text PDF , Low-Resolution PDF , Video Demo A Computer Oriented Geodetic Data Base And a New Technique in File Sequencing Author: G.M. Morton Publication Date: 1996-03-01 Published In: Journal of Computer Graphics Techniques (JCGT), vol. 6, no. 2 Links: PDF \u00dcber die stetige Abbildung einer Linie auf ein Fl\u00e4chenst\u00fcck {abc} Author: David Hilbert Publication Date: 1891-03-04 Published In: Mathematische Annalen, 38th volume, 3rd booklet Links: DigiZeitschriften , PDF Specifications Qubicle File Specification Articles Authors: Minddesk Software GmbH Publication Dates: 2015-10-02, 2016-01-11 Published at: getqubicle.com Links: QEF Spec. , QB Spec. , QBT Spec. Last Viewed: 2020-05-04 Binvox Voxel File Format Specification Author: Patrick Min Publication Date: N/A Last Modification Date: 2015-12-17 Published at: patrickmin.com Links: Website , Parent Page Last Viewed: 2020-06-03 SVX Format Specification Author: Alan Hudson (?) Publication Date: N/A Last Modification Date: N/A Published at: Absolutely Fabulous 3D Printing Links: Website Last Viewed: 2020-06-04 SLAB6 Project Page (KVX, KV6 Documentation) Author: Ken Silverman Publication Date: 2000 or earlier (?) Last Modification Date: 2011-03-22 Published at: Ken Silverman's Projects Page Links: Website , SLAB6 Download Last Viewed: 2020-06-07 Zoxel File Format Specification Author: Graham King Publication Date: 2013-05-16 Last Modification Date: 2013-11-29 Published at: Zoxel Repository Links: Wiki Page Last Viewed: 2020-06-08 Schematic File Format Authors: Minecraft Wiki Publication Date: N/A Last Modification Date: 2020-05-10 Published at: Minecraft Wiki Links: Wiki Page Last Viewed: 2020-06-08 Structure Block File Format Authors: Minecraft Wiki Publication Date: N/A Last Modification Date: 2020-05-25 Published at: Minecraft Wiki Links: Wiki Page Last Viewed: 2020-06-08 Sproxel User Manual Author: androo.gardner@gmail.com (?) Publication Date: N/A Last Modification Date N/A Published at: Sproxel at Google Code Links: Wiki Page Last Viewed: 2020-06-08 Web Compressing Voxel Worlds Author: Steven Pigeon Publication Date: 2011 or prior Published at: Harder, Better, Faster, Stronger Blog Links: HBFS Page Last Viewed: 2020-05-30","title":"References"},{"location":"related/literature.html#references","text":"","title":"References"},{"location":"related/literature.html#literature","text":"","title":"Literature"},{"location":"related/literature.html#specifications","text":"","title":"Specifications"},{"location":"related/literature.html#web","text":"","title":"Web"},{"location":"related/overview.html","text":"Overview over Related Work","title":"Overview over Related Work"},{"location":"related/overview.html#overview-over-related-work","text":"","title":"Overview over Related Work"},{"location":"related/voxel_formats.html","text":"List of Voxel File Formats Binvox Stat Value Pattern *.binvox Media-Type model/x-binvox (unofficial) Magic #binvox 1 (of which 1 is version) Software Binvox Structure binary with text header Volumes single1 Voxel-Encoding voxel array Compression run-length encoding Color Support none Palette none KVX Stat Value Pattern *.kvx Media-Type model/x-kvx (unofficial) Magic none Software Voxlap Structure binary Volumes single Voxel-Encoding map of voxel columns per mipmap level Compression none Color Support RGB666 Palette global, 256 colors KV6 Stat Value Pattern *.kv6 Media-Type model/x-kv6 (unofficial) Magic Kvxl Software SLAB6 Structure binary Volumes single Voxel-Encoding map of voxel columns Compression none Color Support RGB666 in palette, RGB24 otherwise Palette optional, global, 256 colors PNG Stack Stat Value Pattern *.png Media-Type image/png Magic \\x89PNG Software various Structure binary Volumes single Voxel-Encoding stack of images Compression PNG Color Support PNG Palette PNG Minecraft Schematic Stat Value Pattern *.schematic Media-Type application/x-schematic+nbt (unofficial) Magic \\x10 (Compound Tag) Software various Minecraft-related Structure binary, based on NBT Volumes single Voxel-Encoding voxel array Compression none Color Support MC block-based Palette implicit, global, MC blocks Minecraft Structure Stat Value Pattern *.mcstructure Media-Type application/x-minecraft-structure+nbt Magic \\x10 (Compound Tag) Software Minecraft Structure binary, based on NBT Volumes single Voxel-Encoding voxel list Compression none Color Support MC block-based Palette global, MC blocks Qubicle Exchange Format Stat Value Pattern *.qef Media-Type text/x-qef+plain (unofficial) Magic Qubicle Exchange Format ... (copyright header) Software Qubicle Structure text, line-based Volumes single Voxel-Encoding voxel list Compression none Color Support floating-point RGB Palette global Qubicle Binary Stat Value Pattern *.qb Media-Type model/x-qb (unofficial) Magic none Software Qubicle Structure binary Volumes multiple, named Voxel-Encoding voxel array Compression optional run-length encoding Color Support RGB24 Palette none Qubicle Binary Tree Stat Value Pattern *.qb Media-Type model/x-qb (unofficial) Magic QB 2 Software Qubicle Structure binary Volumes multiple, named, hierarchical Voxel-Encoding voxel array Compression zlib Color Support RGB24, RGBA32 with palette Palette optional, global Simple Voxels Stat Value Pattern *.svx Media-Type application/x-svx+zip (unofficial) Magic PK ... Software Shapeways Structure zip-archive with manifest.xml and images Volumes single Voxel-Encoding stack of images Compression depends on image format Color Support depends on image format Palette no global, only within image Sproxel CSV Stat Value Pattern *.csv Media-Type text/x-sproxel+csv (unofficial) Magic VOX Software Sproxel Structure CSV-based Volumes single Voxel-Encoding voxel array Compression none Color Support RGBA32 Palette none Sproxel Enhanced PNG Stat Value Pattern *.csv Media-Type image/x-sproxel+png (unofficial) Magic \\x89 PNG Software Sproxel Structure PNG-based Volumes single Voxel-Encoding stack of slices within single PNG Compression PNG Color Support PNG Palette PNG Voxel Model Stat Value Pattern *.vox Media-Type model/x-vox (unofficial) Magic VOX Software MagicaVoxel Structure binary with RIFF-style chunks Volumes multiple, since 0.99.5 with names, hierarchical, links Voxel-Encoding 8-bit voxel lists Compression none Color Support RGB24 Palette global, 256 colors of which one is reserved Zoxel Stat Value Pattern *.zox Media-Type text/x-zoxel+json (unofficial) Magic none Software Zoxel Structure text, JSON-based Volumes single Voxel-Encoding voxel list Compression none Color Support RGBA32 Palette none","title":"List of Voxel File Formats"},{"location":"related/voxel_formats.html#list-of-voxel-file-formats","text":"","title":"List of Voxel File Formats"},{"location":"rle/rle.html","text":"Run-Length Encoding Run-Length Encoding (RLE) is a form of lossless data compression which stores elements of said data using a single value and a count or \"run-length\". Viability for Voxel Compression RLE is viable in those cases, where there are long runs of identical or very similar data. Due to voxel arrays often containing huge amounts of empty space, they also contain long runs of 0x0 RGB values (or whatever other value represents empty voxels) which could be run-length-compressed. This mitigates their greatest downside compared to voxel lists , their empty-space-overhead. In-Band- vs Out-Of-Band- Signaling The main distinction in RLE methods can be made between In-Band Signaling And Out-Of-Band Signaling . In-Band Signaling This method uses the alphabet of the data which it attempts to compress. For instance, if the data consists of only alphabetic ASCII characters, then digits could be used to encode the counts. Or for ASCII characters which are stored in 8-bit integers, the uppermost, unused bit could be used to signal that the remaining seven bits are the count. In any case, this method is best when the addition of the count does not conflict with the existing data. Otherwise, an escape sequence is necessary. For instance, to encode any 8-bit integer sequence, the value 0xff could be used to \"escape\" the data and be followed up by the count and the actual byte to be encoded, including 0xff . \\text{aaabbbcfdeef} \\rightarrow \\text{3a3bcfd2ef} Out-Of-Band Signaling This method encodes all of the data in pairs of count and data instead of leaving single characters intact. Its main advantage is the simplicity of parsing and an identical effect for all types of data. While a particular escape sequence might be a poor choice for some specific data set, this method does not require an escape sequence and thus doesn't suffer from the problem. To avoid bloating the data in size, further measures must be taken such as having a sequence which can signal a sequence of different characters as well as a sequence of identical characters. For instance, negative counts could be used to signal multiple different characters. \\text{aaabbbcfdeef} \\rightarrow \\text{3a3b1c1f1d2e1f} Summary In-Band signaling should be used in cases where certain values in the data are unused, allowing for an escape sequence with no conflicts with other data. If there are not just a handful of values but an entire bit per byte which is unused (such as in ASCII ), then this method becomes especially viable. Otherwise, OOB signaling is preferable, as it gives much more flexibility to the implementing developer and doesn't produce any conflicts with the data to be compressed. Existing Implementations Binvox The Binvox file format provides simple compression for geometry-only voxel data. It uses out-of-band signaling After a text header, the binary voxel data can be specified as follows: struct binvox_data { marker[] } struct marker { u8 count u8 bit_value } Criticism Binvox run-length encodes only streaks of 0 -bits or 1 -bits. But to store their values, it uses an entire byte which wastes 7 bits. Almost half (7 out of 16) bits for each marker are thus wasted. Also the worst case is a recurring pattern of 010101... . For such a worst case, Binvox increases the required storage space by a factor of 16! Qubicle Binary The Qubicle Binary (QB) file format has an option for compressing models using RLE. It is still in use, although it has been superseded by the Qubicle Binary Tree (QBT) file format which uses zlib instead of custom RLE. Models are made of matrices , which are arrays, usually sized 128 3 or smaller 1 . When compressing matrices , each slice (xy-plane) is being run-length-encoded. The RLE implementation uses in-band signaling . The CODEFLAG = 2 escape sequence signals a following pair of count and data, whereas the NEXTSLICEFLAG = 6 signals the end of the current slice . Criticism This implementation is flawed, in that it fails to exploit an obvious non-conflicting escape sequence: A color with an alpha of zero is invisible, regardless of its other components. In the QB format, the escape sequences correspond to pitch black colors with an alpha of 2 or 6 respectively, which is almost invisible. Alpha channels can also be used to store visibility maps instead, where such values would be far more common. Such a problem could have been easily mitigated by using different values for the escape sequences or by not storing colors in RGBA or BGRA format. An example of a better constant would be 1 31 , which is interpreted as an invisible color but with a red value of 128. Our Experiments There are countless ways to implement RLE. We implemented a few experimental methods ourselves to see how much one could improve upon the original designs. Compact Binvox struct marker { bit value i7 count } Instead of wasting 7 bits, we simply integrate the bit-value into the uppermost bit of the count. If we read the marker as a signed two's complement integer, we can easily obtain the bit using marker < 0 and the count using marker & 0x7f . Complete Binvox struct marker { u8 count u8 value } Instead of wasting 7 bits, we allow for an entire byte to be repeated count times. 0x00 and 0xff Escape Sequences This method uses in-band signaling. We encode our bits as usual, but when we encounter an escape sequence, the following byte is used as our count. We have two escape sequences: 0x00 indicates that the following byte encodes the number of zero-bits 0xff indicates that the following byte encodes the number of one-bits The obvious advantage of this method is that our escape sequences don't conflict with high-entropy data. We preserve any bytes which have both 0 and 1 in them and only affect fully empty/filled bytes, which occur in a low-entropy context anyways. Zlib TODO complete this For most of its lifetime, Qubicle did not support matrices greater than 128 in each dimension. However, the file format technically allows for greater sizes due to a 32-bit integer being used for each dimension. \u21a9","title":"Run-Length Encoding"},{"location":"rle/rle.html#run-length-encoding","text":"Run-Length Encoding (RLE) is a form of lossless data compression which stores elements of said data using a single value and a count or \"run-length\".","title":"Run-Length Encoding"},{"location":"rle/rle.html#viability-for-voxel-compression","text":"RLE is viable in those cases, where there are long runs of identical or very similar data. Due to voxel arrays often containing huge amounts of empty space, they also contain long runs of 0x0 RGB values (or whatever other value represents empty voxels) which could be run-length-compressed. This mitigates their greatest downside compared to voxel lists , their empty-space-overhead.","title":"Viability for Voxel Compression"},{"location":"rle/rle.html#in-band-vs-out-of-band-signaling","text":"The main distinction in RLE methods can be made between In-Band Signaling And Out-Of-Band Signaling .","title":"In-Band- vs Out-Of-Band- Signaling"},{"location":"rle/rle.html#existing-implementations","text":"","title":"Existing Implementations"},{"location":"rle/rle.html#our-experiments","text":"There are countless ways to implement RLE. We implemented a few experimental methods ourselves to see how much one could improve upon the original designs.","title":"Our Experiments"},{"location":"rle/space_filling_curves.html","text":"Space-Filling Curves A space-filling curve is a curve which's range contains the entirety of a hypercube When filling space with a curve, we are generally applying a bijective function: c: \\mathbb{N} \\rightarrow \\mathbb{Z}^N,\\; N \\in \\mathbb{N} This maps discrete points of the curve onto points in (hyper)space. Note that often times it may be easier to iterate over all points in space and assign an index to each instead. Since our mapping is bijective, this is also a viable strategy for filling space, as long as we are working within finite boundaries. In such a case, we are applying the inverse function: c^{-1}: \\mathbb{Z}^N \\rightarrow \\mathbb{N},\\; N \\in \\mathbb{N} Motivation In the previous RLE methods, we have filled space using nested iteration. Using alternative space-filling curves improves spatial locality over nested iterations. This is expected to improve the compression ratio of RLE. Comparison of Space-Filling Curves We will be discussing three approaches, namely nested iteration , Z-Order Curves , and Hilbert Curves for use in RLE. First, we introduce, define and present an implementation of all three methods. Then, we compare them. One of the points of comparison is how frequently a jump is found in the curve. The set of jumps J(c) for a curve c is defined as: J(c) = \\{(i,j) \\in \\mathbb{N}\\times\\mathbb{N} \\;\\big|\\; \\lVert c(j) - c(i)\\rVert \\gt 1\\} The only curves without jumps are curves of which all points are direct neighbors. Note There are many more possible space-filling curves. Just by permuting coordinates we could obtain six variations of each of our curves. The three chosen examples were selected because they have significant advantages and disadvantages over one-another and thus act as a good proxy for comparison of all space-filling curves. Nested Iteration Figure 1: Nested Iteration in Two Dimensions Let l_x, l_y, l_z \\in \\mathbb{N} be the dimensions of the volume to fill. Our curve can be defined as: c(i) = \\begin{pmatrix} i \\bmod (l_x \\cdot l_y) \\cr \\lfloor\\frac{i}{l_x}\\rfloor \\bmod l_y \\cr \\lfloor\\frac{i}{l_x \\cdot l_y}\\rfloor \\end{pmatrix} It is however much simpler to perform the inverse mapping: c^{-1}(x, y, z) = x + (y \\cdot l_x) + (z \\cdot l_x \\cdot l_y) For a cube with dimensions which are powers of two, this is equivalent to concatenating the bits of x , y and z of any point. Nested iteration fills space by iterating over all coordinates, with x running the fastest, followed by progressively slower-running coordinates. The reverse-approach can be performed without any multiplication at all, using the following code: voxel container[limit_x * limit_y * limit_z]; size_t index = 0; for (unsigned z = 0; z < limit_z; ++z) for (unsigned y = 0; y < limit_y; ++y) for (unsigned x = 0; x < limit_x; ++x, ++index) container[index] = voxel_at(x, y, z); Notice how our container can have any shape, it is not limited to a hypercube. A jump occurs once every limit_x coordinates, where x jumps from limit_x - 1 to 0 . Z-Order Curves Figure 2: Z-Order Curve in Two Dimensions Z-Order curves have already been presented as a possible solution in 1996 by G.H. Morton . They have the significant advantage of a higher spatial locality. Z-Order Curves can be constructed iteratively by repeating the z-pattern each 2 N iterations, recursively. For three dimension, they can be defined as follows: \\begin{align} c(i) &= \\text{deinterleave3}(i) \\\\ c^{-1}(x, y, z) &= \\text{interleave3}(x, y, z) \\end{align} The operations interleave3 and deinterleave3 are the basis for Octree Node Indices . They (de)interleave the bits of the three coordinates, producing a single index which consists of a series of octal digits. See the linked section for an efficient implementation and thorough explanation. The space-filling itself can be implemented very similarly to nested iteration. We can implemented Z-Order Curves as follows: voxel container[limit * limit * limit]; for (unsigned z = 0; z < limit; ++z) for (unsigned y = 0; y < limit; ++y) for (unsigned x = 0; x < limit; ++x) container[interleave3(x, y, z)] = voxel_at(x, y, z); Note that our container now needs to be a cube and also must have dimensions which are a power of two. Interleaving bits is still the most expensive arithmetic operation performed here. A typical implementation will interleave each coordinate with zeros first, then combine these partial results using a bitwise OR. Only x changes every iteration, so we can cache the results for y and z . We can perform fewer operations in total using the following code: voxel container[limit_x * limit_y * limit_z]; size_t index = 0; for (unsigned z = 0; z < limit_z; ++z) { // assuming this is implemented as a special case which handles zero-inputs unsigned zi = interleave3(z, 0, 0); for (unsigned y = 0; y < limit_y; ++y) { unsigned yi = interleave3(0, y, 0); for (unsigned x = 0; x < limit_x; ++x, ++index) { unsigned xi = interleave3(0, 0, x); container[zi | yi | xi] = voxel_at(x, y, z); } } } Hilbert Curves Figure 3: Hilbert Curve in Two Dimensions Hilbert Curves also improve spatial locality similar to Z-Order curves. They are very similar to Z-Order Curves in the aspect that they also have a pattern for each 4 pixels (or 8 voxels) which is repeated recursively to construct the curve. However, Hilbert curves also require these units to be rotated depending on their position in the grid at a higher level. Despite that, we can construct Hilbert curves from Z-Order Curves . An efficient implementation of this was provided by Icabod . Figure 4: A Hilbert Curve in Three Dimension - Michael Trott, in The Mathematica GuideBook for Programming The implementation builds on our approach for Z-Order Curves. It can also be optimized by caching portions of our Morton (Z-Order) index, but the final conversion to our Hilbert index must happen in its entirety every loop. voxel container[limit * limit * limit]; for (unsigned z = 0; z < limit; ++z) { for (unsigned y = 0; y < limit; ++y) { for (unsigned x = 0; x < limit; ++x) { unsigned morton_index = interleave3(x, y, z); unsigned hilbert_index = morton_to_hilbert3d(morton_index); container[hilbert_index] = voxel_at(x, y, z); } } } Comparisons Nested Iteration Z-Order Curve Hilbert Curve Complexity per Voxel O(1) O(\\log{b}) O(b) Container Restrictions cube with dims. 2 n cube with dims. 2 n Jumps each l_x iterations each 2 iterations never Implementation Effort low medium high Z-Order Curves have logarithmic complexity. However, hardware may support bit-(de)interleaving via a dedicated instruction which can be implemented very easily by rewiring bits. This can effectively turn the complexity to O(1) , should such hardware support exist. Also note that while Z-Order curves have very frequent jumps, the most frequents ones (each 2 iterations) are short, 2D-diagonal jumps covering a distance of \\sqrt{2} . Each 4 iterations, there is a longer 3D-diagonal jump of \\sqrt{3} . Each 8 iterations, there is an even longer jump, and so forth. Unlike the simple interleave3 operation for Z-Order curves, we can not easily hardware-optimize morton_to_hilbert3d . Each computed octal digit affects the transformation applied to less significant digits. This recursive dependency leads to a complexity of O(b) Impact on Run-Length Encoding The impact on RLE can be very positive or very negative depending on the used method. In the following table, we compare how our geometry compression methods are affected by the different curves: Method\\Size For Nested Iteration Z-Order Curve Hilbert Curve Binvox 177 KB 258 KB 184 KB Compact Binvox 89 KB 134 KB 98 KB Complete Binvox 254 KB 123 KB 109 KB In-Band 185 KB 93 KB 77 KB The surprising effect is that for our bitwise formats Binvox and Compact Binvox , the effect is negative. For byte-based formats like Complete Binvox and In-Band , the effect is positive. Negative Impact on Bitwise Formats The reason why bitwise formats are negatively impacted by higher spatial locality is that they rarely profit from its advantages but are very negatively impacted by its disadvantages. The main disadvantage which is a potentially higher transition rate is explained as follows: For bitwise, out-of-band RLE formats, it is possible to determine number of encoded markers using only the number of transitions t and the number of bits in the stream b (assuming, there is no size limit for the count stored in a marker). A transition occurs when a one-bit is followed by a zero-bit or a zero-bit is followed by a one-bit. When we run-length-encode a bitstream, we only need to encode a new marker for a transition. If all bits were equal, we would only need to encode a single marker storing the size of the bitstream and the value of said bit. Let t be the number of transitions and b the total number of bits in a stream. The transition rate is t_r = \\frac{t}{b} and the average run length r_\\oslash = t_r^{-1} = \\frac{b}{t} . We see the following results for our curves when iterating over our Perlin128 model: Stat\\Method Nested Iteration Z-Order Curve Hilbert Curve t (lower is better) 88936 125046 88410 t_r (lower is better) 0.042 0.0601 0.042 r_\\oslash (higher is better) 23.58 16.64 23.72 The transition rate is very negatively impacted by Z-Order Curves. This happens because the very frequent jumps which occur in Z-Order Curves will produce significant amounts of transitions from inside a shape (1) to outside a shape(0) at its boundaries. Note that Hilbert Curves have a lower transition rate but still negatively impact our bitwise formats. This only happens because with Hilbert Curves, we run out of space in our one-markers (8 bits for Binvox , 7 bits for Compact Binvox ) more frequently due to how efficient this reordering is. So ironically, better is worse in this case. Positive Impact on Bytewise Formats In the previous section, I mentioned that bitwise formats rarely profit from the advantages of spatial locality. Bytewise formats do profit and perform much better as a result. The primary effect of higher spatial locality is a \"clumping\" of transitions. While the number of transitions t may not be affected, sections of our model with more transitions will be placed closer together and sections with fewer transitions will also be placed together. This is reflected by another stat, the transition follow-up rate t_f , defined as follows: \\begin{align} \\text{is_transition}(i) &= (\\text{voxel_exists}(c(i)) \\ne \\text{voxel_exists}(c(i - 1))) \\\\ \\text{is_follow_up_transition}(i) &= \\text{is_transition}(i) \\land \\text{is_transition}(i-1) \\\\ t_f &= \\frac{\\lvert\\{0 \\le i \\lt b | \\text{is_follow_up_transition}(i)\\}\\rvert}{t} \\end{align} In other words: the probability that a transition is followed-up by another transition. Here the results for our Perlin128 model: Stat\\Method Nested Iteration Z-Order Curve Hilbert Curve t_f (higher is better) 0.01402 0.4346 0.2885 Bytewise formats do profit from a higher t_f , for a constant t . They can simply encode a byte with a run-length of one which stores multiple transitions. This leaves other areas which have very few transitions and can be encoded with longer runs. Bitwise formats can not do this and need a separate marker for every single transition. Note It is not required for a RLE format to encode 8-bit values to take advantage of a higher t_f . Any number of bits greater than one is sufficient. Summary We compared nested iteration , Z-Order Curves and Hilbert Curves for use in RLE. The impact of different space-filling curves was dramatic. Bytewise formats such as Complete Binvox and In-Band performed worse with just nested iteration but saw reductions in data of nearly 60% when using the latter methods. Surprisingly, the previously better-performing bitwise formats did not see any benefit. In fact, they became more redundant when using the latter space-filling curves. This phenomenon was investigated and explained by demonstrating that only the number of transitions affects the number of markers and thus the data size for bitwise formats. In total, we were able to achieve an improvement using Hilbert Curves and In-Band over the previously best method, Compact Binvox with Nested Iteration . Unfortunately, the computational effort of Hilbert Curves makes it questionable whether this method should be used.","title":"Space-Filling Curves"},{"location":"rle/space_filling_curves.html#space-filling-curves","text":"A space-filling curve is a curve which's range contains the entirety of a hypercube When filling space with a curve, we are generally applying a bijective function: c: \\mathbb{N} \\rightarrow \\mathbb{Z}^N,\\; N \\in \\mathbb{N} This maps discrete points of the curve onto points in (hyper)space. Note that often times it may be easier to iterate over all points in space and assign an index to each instead. Since our mapping is bijective, this is also a viable strategy for filling space, as long as we are working within finite boundaries. In such a case, we are applying the inverse function: c^{-1}: \\mathbb{Z}^N \\rightarrow \\mathbb{N},\\; N \\in \\mathbb{N}","title":"Space-Filling Curves"},{"location":"rle/space_filling_curves.html#motivation","text":"In the previous RLE methods, we have filled space using nested iteration. Using alternative space-filling curves improves spatial locality over nested iterations. This is expected to improve the compression ratio of RLE.","title":"Motivation"},{"location":"rle/space_filling_curves.html#comparison-of-space-filling-curves","text":"We will be discussing three approaches, namely nested iteration , Z-Order Curves , and Hilbert Curves for use in RLE. First, we introduce, define and present an implementation of all three methods. Then, we compare them. One of the points of comparison is how frequently a jump is found in the curve. The set of jumps J(c) for a curve c is defined as: J(c) = \\{(i,j) \\in \\mathbb{N}\\times\\mathbb{N} \\;\\big|\\; \\lVert c(j) - c(i)\\rVert \\gt 1\\} The only curves without jumps are curves of which all points are direct neighbors. Note There are many more possible space-filling curves. Just by permuting coordinates we could obtain six variations of each of our curves. The three chosen examples were selected because they have significant advantages and disadvantages over one-another and thus act as a good proxy for comparison of all space-filling curves.","title":"Comparison of Space-Filling Curves"},{"location":"rle/space_filling_curves.html#impact-on-run-length-encoding","text":"The impact on RLE can be very positive or very negative depending on the used method. In the following table, we compare how our geometry compression methods are affected by the different curves: Method\\Size For Nested Iteration Z-Order Curve Hilbert Curve Binvox 177 KB 258 KB 184 KB Compact Binvox 89 KB 134 KB 98 KB Complete Binvox 254 KB 123 KB 109 KB In-Band 185 KB 93 KB 77 KB The surprising effect is that for our bitwise formats Binvox and Compact Binvox , the effect is negative. For byte-based formats like Complete Binvox and In-Band , the effect is positive.","title":"Impact on Run-Length Encoding"},{"location":"svo/construction.html","text":"SVO Construction When constructing an SVO from a voxel list , the complexity of this process depends on the data fed to the constructing algorithm. Within the scope of this project, the uncompressed format is a list of voxels , but there are further subtle differences. Summary of Construction The following process must be repeated for all voxels v := (p := (x, y, z), c) \\in (\\mathbb{Z}^3, \\mathbb{N}) in the list. Test signed input position p against current SVO dimensions d . If the position is outside of our boundaries, enlarge the SVO to fit p . Subtract p_{min} of the SVO from p to obtain p_{\\text{normalized}} . Convert p_{\\text{normalized}} to the octree node index n . Use n to traverse the SVO and insert the voxel at the correct location. Optional: If only one octant is used, cut branches belonging to other octants recursively. Note To handle signed values, the octree must be extended into both positive and negative octants. Coordinate System There are two coordinate systems with which we must concern ourselves with: world coordinate system (signed) SVO coordinate system (unsigned) The conversion between these two coordinate systems occurs in step 3. The problem which we face is that our SVO is meant to split the world coordinate system into eight equal octants, recursively. The first split occurs at the origin however, the origin (0, 0, 0) must be located in one of these octants. To solve this, we put the origin into the first octant; then all positions with no negative coordinates will lie in just one octant. This allows us to perform the optimisation from step 6 for only unsigned coordinates. It also helps us optimize our boundary test . As a result, for example, an SVO that can contain 4x4x4 voxels will have space from (-2, -2, -2) to (1, 1, 1) . Special Case Where Voxel Coordinates Are Positive If the voxels are sorted with the first voxel being the most negative corner of the model, we have a global p_{min} (see step 3.). All voxels can then be translated by -p_{min} , yielding only positions that belong in the first octant. If x, y, z are already guaranteed to be positive, this condition is obviously also met. In such cases. step 1. and 2. are simplified and step 6. is eliminated. Efficient Boundary Test To check whether a point lies within our SVO, max(abs(x), abs(y), abs(z)) > d would suffice. However, this test is overly pessimistic because we have more negative space instead of positive space. Also, assuming no compiler optimisations, we have to perform six conditional operations: each call to abs() requires one conditional operation a three-argument max() would require two more one more conditional operation is necessary for the > d comparison Assuming unsorted inputs, these six conditional jumps may wreak havoc on the performance of the branch predictor . To remove the pessimism from our test, we define a new function to be used in stead of abs : abs_{\\text{SVO}}(n) = \\begin{cases} -n - 1,& \\text{if } n < 0\\\\ n, & \\text{otherwise} \\end{cases} Implementation uint32_t abs_svo(int32_t n) { return n < 0 ? (-n -1) : n; } bool comp_against_svo_bounds(int32_t x, int32_t y, int32_t z, uint32_t d) { return (abs_svo(x) | abs_svo(y) | abs_svo(z)) >= d; } Such an implementation eliminates five out of six conditional operations on modern compilers, leaving only the final >= comparison. See this Compiler Explorer page for an example. Compiler Optimization of abs_svo Using abs_{\\text{SVO}} actually works in ours and the compiler's favor. This is due to the fact that negating a number in two's complement requires a bitwise negation and an increment. Due to our decrement of the negated number, we eliminate this need. abs_svo(int): mov eax, edi # copy function parameter into result register sar eax, 31 # fill the register with 1s if the number is negative, else with 0s xor eax, edi # xor result register with parameter, performing a conditional bitwise NOT retn # return from the function Manual Optimization of Comparison with d This only works because d is an SVO dimension and thus always guaranteed to be a power of two. The most significant bit of lower numbers is lower than the single bit of a greater power of two. To name an example, 128 will have the 128-bit set, whereas all lower numbers will consist only of less significant bits. Hence, they can be safely combined with an | operation before making the comparison. Summary The overly pessimistic initial comparison could be fixed with -surprisingly- no performance impact. Out of the six necessary conditional operations, we could optimize five away. During a microbenchmark of the original max(abs(x), abs(y), abs(z)) > d comparison vs. our optimized method, no performance difference could be found . However, keep in mind that abs() functions are often compiled to use a conditional move instruction which can be expensive on older architectures. So depending on the architecture, such a benefit could be seen. Octree Growth If we do find that a point which is to be inserted does not fit within the current octree, we must enlarge it. Single-Octant Growth Figure 1: Simple (Single-Octant) Octree Growth If only one octant is used, e.g. all positions are unsigned, then we can enlarge the octree into just one direction. The current root node goes into the lowest corner (with index 0) of the new, higher-level root node. Unilateral Octree Growth Figure 2: Unilateral Octree Growth If we use signed positions, we must grow our octree unilaterally. This means that each node receives a new parent. The four new parents are then moved into the root node at the location of their children. Here is an implementation in pseudo-C++: for (size_t i = 0; i < 8; ++i) { if (root.has(i)) { auto parent = make_new_branch(); parent[~i & 0b111] = root.extract(i); root[i] = parent; } } Within each new parent, the current nodes end up positioned in the opposite corner of where they were before. In one index from 0 to 7, each bit represents a three-dimensional coordinate. So index 4 = 0b010 represents (0, 1, 0) . By flipping all bits of the index we can quickly calculate the position inside the new parent. Note that for squashed octrees , this beautifully simple case no longer applies. We still create exactly eight new parents, but each parent will receive up to 4 of the 16 first-level branches. This and other problems make unilateral growth for squashed octrees a lengthy and complicated process. Position Normalization Once the octree has grown to a size at which it can contain our new position p = (x, y, z) , we must normalize our position. In this case normalization means that we simply subtract (x_{\\text{min}}, y_{\\text{min}}, z_{\\text{min}}) from p to obtain p_{\\text{normalized}} . This is necessary because internally, octrees don't have any concept of \"negative\" or \"positive\" positions, just indices within nodes which are all unsigned. The minimum coordinate for all dimensions is -2^d , where d is the unilateral depth of the octree. Once we subtract this minimum from our position, the position will be unsigned and ready for calculation of the octree node index. Octree Node Index After obtaining an unsigned position p_{\\text{normalized}} = (x, y, z) \\in \\mathbb{N}^3 within the octree, we must find out where to store this position in the data structure. Find the correct insertion point equires recursively testing whether each coordinate is in the lower or the upper half of current subtree. As long as the tree's dimensions are a power of 2, this can be reduced to checking whether a bit is set. For example, 128 is in the upper half of the 256-tree, because the most 128-bit is set, which is not the case for 127. We do not want to make this test at every level; It would be more convenient to pre-calculate a complete path through the octree that leads straight to the insertion point. Approach in One Dimension Figure: Binary Numbers Form a Binary Tree Implicitly As seen in the above Figure, the lower bit indicates whether the position is left or right in the lower subtree and the higher bit indicates whether the position is left or right in the upper subtree. To navigate the above binary tree, we can use the following pseudo-code: void insert(size_t index, rgb32_t color) { auto &branch = root[(index >> 1) & 1]; // use upper bit to get branch auto &leaf = branch[(index >> 0) & 1]; // use lower bit to get leaf leaf.color = color; } Approach in Three Dimensions The same pattern occurs for octal digits and octrees. (x, y, z) can thus be seen as three positions in separate binary trees which we want to combine into an octree. To convert (x, y, z) to a position in an octree, the bits of (x, y, z) can simply be interleaved. The result will be a single number of octal digits, each of which represents the position within one octree node. Just like we can use the bits of a binary number to navigate the above binary tree, we can use the digits of the octal number to navigate the octree at every level. void insert(size_t index, rgb32_t color) { auto &branch = root[(index >> 3) & 0b111]; // use upper digit to get branch // ... repeat this process for however many levels of branches there are auto &leaf = branch[(index >> 0) & 0b111]; // use lower digit to get leaf leaf.color = color; } Examples This is how coordinates can be mapped to octree indices: \\begin{align} & (6, 8, 9) = (\\color{red}{0101_2}, \\color{green}{1000_2}, \\color{blue}{1001_2}) \\\\ \\xrightarrow{\\text{interleave}} \\quad& (\\color{red}{0},\\color{green}{1},\\color{blue}{1}), (\\color{red}{1},\\color{green}{1},\\color{blue}{1}), (\\color{red}{0},\\color{green}{0},\\color{blue}{0}), (\\color{red}{1},\\color{green}{0},\\color{blue}{1}) \\\\ \\xrightarrow{\\text{concatenate}} \\quad& \\color{red}{0}\\color{green}{1}\\color{blue}{1}, \\color{red}{1}\\color{green}{1}\\color{blue}{1}, \\color{red}{0}\\color{green}{0}\\color{blue}{0}, \\color{red}{1}\\color{green}{0}\\color{blue}{1}_2 = 3705_8 = 1989 \\end{align} Note that in the above example, x is used as the most significant bit of each octal digit, followed by y and z . This is how octree node indices can be mapped to coordinates: \\begin{align} &25 = 31_8 = \\color{red}{0}\\color{green}{1}\\color{blue}{1},\\color{red}{0}\\color{green}{0}\\color{blue}{1}_2 \\\\ \\xrightarrow{\\text{to vectors}} \\quad& (\\color{red}{0}, \\color{green}{1}, \\color{blue}{1}), (\\color{red}{0}, \\color{green}{0}, \\color{blue}{1}) \\\\ \\xrightarrow{\\text{deinterleave}} \\quad& (\\color{red}{00_2}, \\color{green}{10_2}, \\color{blue}{11_2}) = (0, 2, 3) \\end{align} Implementation The following C++17 implementation shows how three coordinates (x, y, z) can be efficiently interleaved using binary Magic Numbers. The implementation expands upon one of the Bit Twiddling Hacks by Sean Eron Anderson . // interleaves a given number with two zero-bits after each input bit // the first insertion occurs between the least significant bit and the next higher bit uint64_t ileave_two0(uint32_t input) { constexpr size_t numInputs = 3; constexpr uint64_t masks[] = { 0x9249'2492'4924'9249, 0x30C3'0C30'C30C'30C3, 0xF00F'00F0'0F00'F00F, 0x00FF'0000'FF00'00FF, 0xFFFF'0000'0000'FFFF }; uint64_t n = input; for (int i = 4; i != 1; --i) { const auto shift = (numInputs - 1) * (1 << i); n |= n << shift; n &= masks[i]; } return n; } uint64_t ileave3(uint32_t x, uint32_t y, uint32_t z) { return (ileave_two0(x) << 2) | (ileave_two0(y) << 1) | ileave_two0(z); } Note An implementation for a variable amount of inputs is equally possible, but would significantly increase the code complexity. Most notably, the masks lookup table would need to be generated computationally. C++ was chosen due to its constexpr compile-time context. Traversing the Octree Once the octree node index is computed, traversing the octree becomes simple: For a given index n , we start at the most significant octal digit o and the root node. We follow the branch number o or construct it if it does not exist yet. Insert the voxel's color once a leaf node is found. Repeat until the least significant octal digit is processed. Note Once a nonexistent branch is found in step 2, all deeper branches will also be missing. In such a case, we can enter a different code path that handles this case. Node Implementation An SVO will need to store our voxel colors at some level. We can reduce memory consumption and cache misses by using a small voxel array at the second-to-final depth: // a regular node struct svo_node { svo_node *children[8]; }; // a node that stores colors instead struct svo_array_node { uint32_t colors[8]; } // a node that stores just one color, something that we want to avoid struct svo_leaf_node { uint32_t color; } This code will need to be adjusted so that the nodes are either polymorphic or type unions are used.","title":"SVO Construction"},{"location":"svo/construction.html#svo-construction","text":"When constructing an SVO from a voxel list , the complexity of this process depends on the data fed to the constructing algorithm. Within the scope of this project, the uncompressed format is a list of voxels , but there are further subtle differences.","title":"SVO Construction"},{"location":"svo/construction.html#efficient-boundary-test","text":"To check whether a point lies within our SVO, max(abs(x), abs(y), abs(z)) > d would suffice. However, this test is overly pessimistic because we have more negative space instead of positive space. Also, assuming no compiler optimisations, we have to perform six conditional operations: each call to abs() requires one conditional operation a three-argument max() would require two more one more conditional operation is necessary for the > d comparison Assuming unsorted inputs, these six conditional jumps may wreak havoc on the performance of the branch predictor . To remove the pessimism from our test, we define a new function to be used in stead of abs : abs_{\\text{SVO}}(n) = \\begin{cases} -n - 1,& \\text{if } n < 0\\\\ n, & \\text{otherwise} \\end{cases}","title":"Efficient Boundary Test"},{"location":"svo/construction.html#octree-growth","text":"If we do find that a point which is to be inserted does not fit within the current octree, we must enlarge it.","title":"Octree Growth"},{"location":"svo/construction.html#position-normalization","text":"Once the octree has grown to a size at which it can contain our new position p = (x, y, z) , we must normalize our position. In this case normalization means that we simply subtract (x_{\\text{min}}, y_{\\text{min}}, z_{\\text{min}}) from p to obtain p_{\\text{normalized}} . This is necessary because internally, octrees don't have any concept of \"negative\" or \"positive\" positions, just indices within nodes which are all unsigned. The minimum coordinate for all dimensions is -2^d , where d is the unilateral depth of the octree. Once we subtract this minimum from our position, the position will be unsigned and ready for calculation of the octree node index.","title":"Position Normalization"},{"location":"svo/construction.html#octree-node-index","text":"After obtaining an unsigned position p_{\\text{normalized}} = (x, y, z) \\in \\mathbb{N}^3 within the octree, we must find out where to store this position in the data structure. Find the correct insertion point equires recursively testing whether each coordinate is in the lower or the upper half of current subtree. As long as the tree's dimensions are a power of 2, this can be reduced to checking whether a bit is set. For example, 128 is in the upper half of the 256-tree, because the most 128-bit is set, which is not the case for 127. We do not want to make this test at every level; It would be more convenient to pre-calculate a complete path through the octree that leads straight to the insertion point.","title":"Octree Node Index"},{"location":"svo/construction.html#traversing-the-octree","text":"Once the octree node index is computed, traversing the octree becomes simple: For a given index n , we start at the most significant octal digit o and the root node. We follow the branch number o or construct it if it does not exist yet. Insert the voxel's color once a leaf node is found. Repeat until the least significant octal digit is processed. Note Once a nonexistent branch is found in step 2, all deeper branches will also be missing. In such a case, we can enter a different code path that handles this case.","title":"Traversing the Octree"},{"location":"svo/optimization.html","text":"SVO Optimization Sparse Voxel Octrees are often sufficiently compact data structures for computer graphics applications. However, they still contain a large amount of redundancy and have plenty of potential for optimization. We can differentiate between two types of optimizations: top-down optimizations optimize nodes starting from the root node and continue downwards. bottom-up optimizations optimize nodes starting from the leafs and continue upwards. Top-down optimizations alter the geometric boundaries of the octree but have little effect on the amount of nodes. This is due to the fact that in any tree, there are more nodes towards the bottom. Their primary purpose is accelerating access to the deeper layers. Bottom-up optimizations have no impact on the boundaries of the octree as this solely depends on the maximum depth. Their primary purpose is decreasing the amount of nodes or reducing nodes in size. Single-Octant Optimization Figure 1: Octree Optimization, where b is a sub-branch (visualized using a Quadtree) Once an octree has been fully constructed, unused octants can be optimized or \"cut away\" recursively. This can be especially helpful for octrees where all voxels reside very far from the origin. For instance, we could be encoding voxels with coordinates ranging from 100,000 to 100,050. Many almost completely empty octree layers would need to be traversed to get to where such locations are stored. Trimming away such single-octant layers accelerates encoding and decoding. This is our first and only top-down optimization . Algorithm s \\gets (0,0,0) If the root node r has exactly one branch b : s \\gets s + 2^{d-2} r \\gets b repeat 2. 2^d is the negated minimum point of our current octree, as described in Position Normalization . After this process has been completed, we simply store s alongside the octree. When decoding, s is added back onto all found positions. Complete Branch Optimization Figure 2: A Complete (Sub-)Tree Observe the Figure 2 above. All nodes are completely filled with 1 , representing that their subtree or color is present. This demonstrates one of the significant weak points of octrees: They are very good at trimming away air recursively, but have a very high cost when encoding a completely filled container. In fact, we would be much better off encoding such containers as arrays than using octrees, as octrees only add redundancy and no benefit in this case. To optimize such cases, we must eliminate nodes which are recursively filled in, or complete . A voxel model that demonstrates this well is chessmaster3 : Figure 3: chessmaster3 Model, visualized in Magica Voxel A very large portion of this model is completely filled in. In fact, the cuboid base of this model alone is 1088x1088 large and many voxels tall. When encoding this model, we see the following results: Method Geometry Bytes SVX 1031 KiB Octree 25044 KiB (~24x) Tetrahexacontree 22704 KiB (~22x) Octree Optimized 1340 KiB (~1.3x) Thct. Optimized 4619 KiB (~4.5x) So how could we accomplish a seemingly miraculous drop from 24x worse to nearly identical for octrees? By simply using the degenerate case of a zero-node to encode a complete subtree. Figure 4: The Tree from Figure 2, after optimization. Compare the above figure to Figure 2 . We are eliminating one layer of nodes and going from the root directly to the color information. Of course, the above data only includes geometry bytes, not color bytes. By eliminating such layers, we can save ourselves 8 nodes on the second level from the bottom, 64 nodes on the third, and so on. Geometrically, it does not even require a lot of space to be completely filled. We merely need a 4x4x4 volume of voxels to be complete in order to eliminate 8 nodes. Tetrahexacontrees do not perform nearly as well though. They require a 16x16x16 volume to be complete and only then is an optimization possible. The more squashed an octree becomes, the fewer opportunities there are to optimize it.","title":"SVO Optimization"},{"location":"svo/optimization.html#svo-optimization","text":"Sparse Voxel Octrees are often sufficiently compact data structures for computer graphics applications. However, they still contain a large amount of redundancy and have plenty of potential for optimization. We can differentiate between two types of optimizations: top-down optimizations optimize nodes starting from the root node and continue downwards. bottom-up optimizations optimize nodes starting from the leafs and continue upwards. Top-down optimizations alter the geometric boundaries of the octree but have little effect on the amount of nodes. This is due to the fact that in any tree, there are more nodes towards the bottom. Their primary purpose is accelerating access to the deeper layers. Bottom-up optimizations have no impact on the boundaries of the octree as this solely depends on the maximum depth. Their primary purpose is decreasing the amount of nodes or reducing nodes in size.","title":"SVO Optimization"},{"location":"svo/optimization.html#single-octant-optimization","text":"Figure 1: Octree Optimization, where b is a sub-branch (visualized using a Quadtree) Once an octree has been fully constructed, unused octants can be optimized or \"cut away\" recursively. This can be especially helpful for octrees where all voxels reside very far from the origin. For instance, we could be encoding voxels with coordinates ranging from 100,000 to 100,050. Many almost completely empty octree layers would need to be traversed to get to where such locations are stored. Trimming away such single-octant layers accelerates encoding and decoding. This is our first and only top-down optimization .","title":"Single-Octant Optimization"},{"location":"svo/optimization.html#complete-branch-optimization","text":"Figure 2: A Complete (Sub-)Tree Observe the Figure 2 above. All nodes are completely filled with 1 , representing that their subtree or color is present. This demonstrates one of the significant weak points of octrees: They are very good at trimming away air recursively, but have a very high cost when encoding a completely filled container. In fact, we would be much better off encoding such containers as arrays than using octrees, as octrees only add redundancy and no benefit in this case. To optimize such cases, we must eliminate nodes which are recursively filled in, or complete . A voxel model that demonstrates this well is chessmaster3 : Figure 3: chessmaster3 Model, visualized in Magica Voxel A very large portion of this model is completely filled in. In fact, the cuboid base of this model alone is 1088x1088 large and many voxels tall. When encoding this model, we see the following results: Method Geometry Bytes SVX 1031 KiB Octree 25044 KiB (~24x) Tetrahexacontree 22704 KiB (~22x) Octree Optimized 1340 KiB (~1.3x) Thct. Optimized 4619 KiB (~4.5x) So how could we accomplish a seemingly miraculous drop from 24x worse to nearly identical for octrees? By simply using the degenerate case of a zero-node to encode a complete subtree. Figure 4: The Tree from Figure 2, after optimization. Compare the above figure to Figure 2 . We are eliminating one layer of nodes and going from the root directly to the color information. Of course, the above data only includes geometry bytes, not color bytes. By eliminating such layers, we can save ourselves 8 nodes on the second level from the bottom, 64 nodes on the third, and so on. Geometrically, it does not even require a lot of space to be completely filled. We merely need a 4x4x4 volume of voxels to be complete in order to eliminate 8 nodes. Tetrahexacontrees do not perform nearly as well though. They require a 16x16x16 volume to be complete and only then is an optimization possible. The more squashed an octree becomes, the fewer opportunities there are to optimize it.","title":"Complete Branch Optimization"},{"location":"svo/svo.html","text":"Sparse Voxel Octree An Octree - Source: Wikipedia , WhiteTimberwolf A sparse voxel octree is a data structure which stores voxels in a tree with a branching factor of 8, with its branches being potentially absent. Missing branches typically represent empty volumes where no voxels exist. The greater empty volumes are, the closer to the root can their corresponding subtrees be pruned. This results in a very efficient representation of models with a significant portion of empty space. Unlike with a voxel list, all positioning is implicit and results from the tree structure, meaning that no space has to be used for the storage of coordinates during serialization. Thus, octrees combine the two greatest advantages of voxel lists and voxel arrays: like lists, they waste little space on encoding empty voxels like for arrays, voxel coordinates are implicit and little space is wasted Extreme Cases And Limits To illustrate the following extreme cases, voxel arrays and voxel lists are also compared. The space complexity of three extreme cases is compared between the three data structures, where v is the amount of voxels. Voxel Array Voxel List Sparse Voxel Octree Empty O(1) 1 O(1) O(1) Tightly Filled O(v) O(4v) O(\\frac{8}{7} v) Stretched O(\\infty) O(1) O(\\infty) Empty Octree Entirely empty models can be encoded using just the root note, which then encodes that no subtrees exist. Tightly Filled Octree Entirely filled models will have some overhead compared to an array of voxels. For every eight nodes, there is one parent node. We can calculate the maximum possible overhead by summing up this \\frac{1}{8} overhead infinitely: \\sum_{n=1}^\\infty{\\frac{1}{8}^n} = \\frac{1}{7} So at worst, our data will increase by \\frac{1}{7} , which is much better than a 100% increase such as for binary trees. Stretched Octree The stretched case is a case where a finite amount of voxels are placed infinitely far apart. For arrays, this produces infinite space requirements because all space between these points must be filled. For octrees, more layers are necessary to encode positions further from the origin. In neither case there is an upper bound to this. In practice, octrees perform significantly better at encoding sparse data than arrays. Construction and Optimization How an octree can be constructed from a list voxels is thorougly explained in SVO Construction . After the octree has been constructed, it will often be necessary to optimize its structure. See SVO Optimization . Serialization Figure 0: A Sparse Voxel Octree, encoded in memory To be used in a serial data format, octrees must first be serialized. Nodes will no longer be laid out freely in memory but instead be arranged one after another. To fully encode an SVO, two steps must be performed: Linearize nodes by traversing the SVO's nodes in a deterministic, reversible order. Serialize each node to binary data. Traversal Order There are two well-known strategies for traversing trees completely: Depth-First Search (DFS) Breadth-First Search (BFS) We improve upon Depth-First Search using our own novel method, Accelerated Depth-First Search (ADFS). The main points of comparison are as follows: Method Space Data Structure Bulk-Read Possible DFS O(\\log{v}) Stack of Nodes never BFS O(v) Queue for entire layer ADFS O(\\log{v}) Stack of Node Lists for direct children Depth-First Figure 1: Tree, traversed depth-first DFS can be performed using only a stack to keep track of the node number at each level. On the deepest level, the next node is chosen until the end is reached and the next parent node is chosen. This low memory cost (which is in fact O(\\log{n}) where n is the number of nodes) is highly advantageous when encoding enormous models. Breadth-First Figure 2: Tree, traversed breadth-first BFS comes with a higher cost since a typical algorithm appends all branches to a queue for every traversed node. This means that in the worst case, which is at the beginning of serialization eight nodes are appended on every level before any node is popped from the queue, resulting in a higher memory cost. Accelerated Depth-First Figure 3: Tree, traversed depth-first In Figure 3 , the labels symbolize order of visitation / order of storage . Accelerated Depth-First works identically to DFS, however all direct children of the current node are stored first. So for example, we store all direct children (2, 3, 4) of the root node (1), but then continue onward to 2 as though we were performing regular DFS. When we are decoding a format in which a node contains the connections to its child nodes, we can count the number of connections and read multiple nodes simultaneously. This is the main benefit of this method. Regular DFS requires us to inspect one connection at a time, then go one node deeper into the tree if it is set. A bulk-read is never possible. An obvious prerequisite is that the nodes are encoded in a fixed-length format, otherwise we can't safely perform such a bulk-read. We can still use just a stack as a data structure, but we need to store a list at every depth with the cached nodes. This approach was specially invented for this research project. Any previous use of it is unknown to me. Why To Serialize Octrees Depth-First and not Breadth-First Figure 4: A serialized octree, depth-first The scheme more practical for encoding octrees is depth-first. This is due to the fact that only a stack is necessary to keep track of the current position. The size or depth of the octree would need to double in all dimensions to necessitate a stack greater by one element. Overall, this is a very low memory profile. For breadth first, we would always load information about the entire next deeper layer into our queue, then move on. To be fair, this does allow us to discard the previous layer entirely once we move deeper, but the memory cost is still unnecessarily high. Node Encoding In the above graphs, the 1-bit encoding was demonstrated due to its simplicity. However, there is a variety of different encodings to choose from. Single-Bit Format 0 stands for air-subtree 1 stands for partially or entirely filled voxel-subtree 8 Bits per octree-node, thus this format is byte-aligned. 2-Bit Format 00 stands for air-subtree 01 stands for solid subtree 10 stands for partially filled subtree 11 variable purpose 1.5-Bit Format 00 stands for air-subtree 01 stands for solid subtree 1 stands for partially filled subtree Variable amount of bits per octree-node, neither bit- nor byte-aligned. On the last level (node = voxel), the single-bit format is used because there are no subtrees. 11 for Raw/Array Subtrees Useful to encode subtrees completely filled with high-entropy content. On the second-to-last level, 11 for raw-subtrees there is no difference between 10 and 11 , so reverting to the 1.5-bit format is viable. On the last level, the single-bit format should be used. As long as the 1.5-bit format is not used, this encoding is completely byte-aligned: * alignment to 16 -bit boundaries on most levels * alignment to 8 -bit boundaries on last level 11 for Pointers to Subtrees on the Same Level Useful for encoding multiple similar subtrees. Similarities between structures could be effectively exploited. Verifying whether subtrees are equal down to the base level has very high complexity: O(n^2 * 8^n) . The comparison depth could be reduced down to a limited number of levels or the level number could be encoded next to the pointer: {u32 indexOfOtherTree, u8 depth} . Instead of the pointer, a tree could instead encode all the places where it is additionally used. This would make decoding easier, since remembering trees on the same level is not necessary. Degenerate Cases If you paid close attention to Figure 1 and Figure 3 , you will have noticed that they contain a 00000000 node. Such nodes can in principle exist, but are a waste of space. After all, they could be trimmed away one layer above by simply encoding a 0 -bit. This nonsensical nature is why they are considered to be a degenerate case . Such cases can however be useful. They offer a natural escape sequence from the regular encoding of an SVO. They could offer special functionality as seen in 3.2.3 to the single-bit format, which does not have any unused values. Squashed Octrees Figure 5: A squashed Octree (compare to Figure 0) A squashed octree is an octree where two or more layers of the tree have been combined into a single layer. By squashing an octree once, we receive a tetrahexacontree. This term comes from \"tetrahexaconta\" (Greek for 64) and \"tree\". It builds on the idea of octrees but expands the branching factor from 8 to 8 2 , or 64. In almost all regards, a squashed octree is implemented identically to a regular octree. However, we divide space into a 4x4x4 cube instead of a 2x2x2 cube with each layer. Motivation When serializing or deserializing an octree, we must do so node by node. This involves generating a bitmask (see above sections on node encoding). For a tetrahexacontree and under use of the 1-bit format, we fill exactly one CPU register on a 64-bit architecture with our nodes. With a regular octree, we would waste all but eight bits. 64-bit architectures established themselves as the de-facto standard for desktop operating systems. Anecdotally, \"macOS Mojave would be the last version of macOS to run 32-bit apps\" - Apple . Thus, optimization of algorithms in the present day can be performed for 64-bit architectures without worrying about 32-bit users. A use of this concept can be seen in the VOLA file format. VOLA uses a 1-bit format for its nodes while squashing two layers into one. So VOLA uses a tetrahexacontree. Unfortunately the paper fails to mention how performance and compression efficiency can be gained or lost this way. Therefore, we run our own tests in the following subsections. Performance Benefits Squashed SVOs lead to very significant performance benefits. For instance, when storing our Ragged Cluster model voxel-by-voxel in our SVO, this took: for a regular SVO: 1700-1800 ms for a squashed SVO: 1048-1288 ms It would be a realistic estimate to say that a 100% speedup is possible. Spatial Costs The costs of one squash are almost neglegible. For instance, our Ragged Cluster model requires: for a regular SVO: 50,467,464 node bits in single-bit format for a squashed SVO: 50,566,592 node bits in single-bit format That is a mere 0.196% increase in bits. However, while by a slim margin, a tetrahexacontree will almost always perform slightly worse: Best Case for Regular Octrees In the best case which is an entirely empty node, an octree requires only one byte of space to encode that each of the 8 child-nodes are empty. A tetrahexacontree will however require eight times the space, meaning 64 bits that are all 0 . However, octrees are very good at trimming away large empty volumes. For our Ragged Cluser , the average sub-branch count was 6.901 , meaning that in each node we would most likely see 7 out of 8 bits set. So this best case is rarely encountered. Best Case for Squashed Octrees The only case where a squashed octree is more efficient than a regular octree is the case where all sub-branches exist. This would be one root-node and 8 branches for a regular octree. Thanks to the squash, this this would only be a single node for a tetrahexacontree, but eight times as large. For our Ragged Cluser , the average squashed sub-branch count was 35.78 . So we are far from encountering this completely-filled case. Squashing More than One Layer In principle we squash even more layers, to receive a tree with a branching factor of 512 and higher. However, we would not receive architectural benefits anymore and would lose out on even more compression efficiency. Conclusion Tetrahexacontrees provide nearly identical spatial costs while providing a very significant performance improvement. This result does have broad implications for the use of octrees in computer graphics in general. Many ray casting algorithms would likely benefits from higher branching factors. In our case, we will follow the example of the VOLA file format and use a higher branching factor in our encoding scheme. Depends on how much space is pre-allocated before the insertion of any voxels. Other data structures consume no space for such a pre-allocation. \u21a9","title":"Sparse Voxel Octree"},{"location":"svo/svo.html#sparse-voxel-octree","text":"An Octree - Source: Wikipedia , WhiteTimberwolf A sparse voxel octree is a data structure which stores voxels in a tree with a branching factor of 8, with its branches being potentially absent. Missing branches typically represent empty volumes where no voxels exist. The greater empty volumes are, the closer to the root can their corresponding subtrees be pruned. This results in a very efficient representation of models with a significant portion of empty space. Unlike with a voxel list, all positioning is implicit and results from the tree structure, meaning that no space has to be used for the storage of coordinates during serialization. Thus, octrees combine the two greatest advantages of voxel lists and voxel arrays: like lists, they waste little space on encoding empty voxels like for arrays, voxel coordinates are implicit and little space is wasted","title":"Sparse Voxel Octree"},{"location":"svo/svo.html#extreme-cases-and-limits","text":"To illustrate the following extreme cases, voxel arrays and voxel lists are also compared. The space complexity of three extreme cases is compared between the three data structures, where v is the amount of voxels. Voxel Array Voxel List Sparse Voxel Octree Empty O(1) 1 O(1) O(1) Tightly Filled O(v) O(4v) O(\\frac{8}{7} v) Stretched O(\\infty) O(1) O(\\infty)","title":"Extreme Cases And Limits"},{"location":"svo/svo.html#construction-and-optimization","text":"How an octree can be constructed from a list voxels is thorougly explained in SVO Construction . After the octree has been constructed, it will often be necessary to optimize its structure. See SVO Optimization .","title":"Construction and Optimization"},{"location":"svo/svo.html#serialization","text":"Figure 0: A Sparse Voxel Octree, encoded in memory To be used in a serial data format, octrees must first be serialized. Nodes will no longer be laid out freely in memory but instead be arranged one after another. To fully encode an SVO, two steps must be performed: Linearize nodes by traversing the SVO's nodes in a deterministic, reversible order. Serialize each node to binary data.","title":"Serialization"},{"location":"svo/svo.html#squashed-octrees","text":"Figure 5: A squashed Octree (compare to Figure 0) A squashed octree is an octree where two or more layers of the tree have been combined into a single layer. By squashing an octree once, we receive a tetrahexacontree. This term comes from \"tetrahexaconta\" (Greek for 64) and \"tree\". It builds on the idea of octrees but expands the branching factor from 8 to 8 2 , or 64. In almost all regards, a squashed octree is implemented identically to a regular octree. However, we divide space into a 4x4x4 cube instead of a 2x2x2 cube with each layer.","title":"Squashed Octrees"}]}