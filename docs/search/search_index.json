{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Compression of Voxel Models This is the documentation of my research project at TU Dresden. This documentation was written using MkDocs . Warning You can browse this offline by hosting it as a static web page on a local server. Many functions such as searching or syntax highlighting won't work when opening this project with a file:// scheme. To name an example, use python3 -m http.server 8000 in the root directory to host this page locally on port 8000.","title":"Compression of Voxel Models"},{"location":"index.html#compression-of-voxel-models","text":"This is the documentation of my research project at TU Dresden. This documentation was written using MkDocs . Warning You can browse this offline by hosting it as a static web page on a local server. Many functions such as searching or syntax highlighting won't work when opening this project with a file:// scheme. To name an example, use python3 -m http.server 8000 in the root directory to host this page locally on port 8000.","title":"Compression of Voxel Models"},{"location":"attribute_compression.html","text":"Attribute Compression","title":"Attribute Compression"},{"location":"attribute_compression.html#attribute-compression","text":"","title":"Attribute Compression"},{"location":"cuboid_extraction.html","text":"Cuboid Extraction Motivation Voxel models of certain types have large volumes of voxels. These types include extruded heightmaps, medical scans, video game worlds and voxel art. Other types such as voxelized polygonal models may also be filled up instead of being kept hollow. The volumes may often be misaligned with the octree structure. Consider a single 2x2x2 cube in the center of an octree. All 8 subtrees of the octree would have to encode an individual voxel of this cube, which is far from optimal. In addition, decoding volumes which are completely filled simplifies the decoding process. These volumes could be extracted and encoded as cuboids like {triple<u8> pos, triple<u8> size} within a container that has dimensions up to 256^3. However we extract cuboids, those should be as large in volume as possible. This way, we cover the most voxels with our pairs of positions. The highest-volume container should be found, then extracted and the next-highest-volume container found, etc. We invest 6 bytes into the extraction, so our volume needs to be 48 to break even (e.g. 4x4x3 ). Absolutely Stupid Method extreme complexity but optimal results Since a cuboid is just a pair of positions, we can simply iterate over all pairs of positions. We then iterate over all voxels in the cuboid to test whether they exist. For a d*d*d model containing v voxels the complexity is thus O(d^3 * d^3 * d^3) or O(d^9) or O(v^3) . This is some clown-world-tier complexity and should not find its way into any serious implementation. Due to its simplicity, it could be used to verify the correctness of more complex approaches though. XYZ-Merge best possible complexity not optimal An XYZ-merge works by merging all neighboring voxels into lines on one axis first. Then neighboring lines are merged into planes on the second axis. Then neighboring planes are merged into cuboids on the last axis. The results are not optimal and may differ depending on the order of axes. At worst, we can't merge anything and thus iterate over every voxel in each of the steps once. The complexity is O(d^3 * 3) = O(d^3) or O(v) . Heightmap-Based Approaches All following approaches are based on the idea, that we can simplify this problem to a 2-dimensional one. One axis is being used as a height-axis, ideally the smallest one if the model is not cubical. We then use a sweeping-plane approach where at each coordinate, we draw a heightmap which extends into our chosen direction. Finding the largest volume in the model is reduced to finding the maximum of the largest volumes for all heightmaps. Constructing Heightmaps from Voxel-Models Here is an illustration of how this is done, in 2 dimensions, where \"up\" in text is the height axis: 0123456789 0123456789 7 ### -> 1110000000 6 #### ## # -> 2221011010 5 ## ### # # -> 3302120101 4 ##### # ## -> 4413201012 3 ## # # # -> 5504010100 2 ######## -> 6612121200 1 ######### -> 7726232310 0 ## ## #### -> 8807303420 In this illustration, # would be encoded as 1 and would be encoded as 0 Each slice from 0 to 7 is one histogram in 2 dimensions or a heightmap in 3 dimensions. We can construct these very efficiently by just taking the heightmap at one height above and incrementing each height, unless we find an empty voxel ( 0 ). Constructing Bitmaps from Heightmaps Finding the largest cuboid in a voxel-model has been reduced to finding the largest cuboid in all its heightmaps. The problem is once again reduced to finding the largest area of 1 s in a bitmap, which can be done in O(n*n) . This is done by looking at all different height-values of the heightmap. At every height, a bitmap is constructed. In our bitmap of equal dimensions, 1 represents that the height at the location is >= the height. Example: 389200 111000 323350 ------> 101110 500020 (h=3) 100000 211141 000010 Finding the largest area of 1 in an n*n rectangle has O(n^2) complexity or O(1) per pixel, when using a sweeping-line algorithm and searching for the greatest area in the resulting histograms: https://www.geeksforgeeks.org/maximum-size-rectangle-binary-sub-matrix-1s/ The volume of the greatest cuboid is then the current height multiplied with the size of the greatest area of 1 which we find. Expected values To understand the following approaches, one must realize that the highest cuboid is not necessarily the largest. For example, a very flat pyramid may have a shape which is only great in volume towards the base. For an n*n heightmap with n height, we can find the cuboid with the largest volume for all heights by finding the largest cuboid at each individual height. This forces us to check every single height. Naive Method high complexity optimal results The naive method simply to iterate over all heights. We then require O(d^2 * d^2) complexity where one d^2 represents the size of the base and the other d^2 represents the amount of pairs of heights. This would be O(v^(4/3)) , which is not as bad as the stupid approach but still polynomial. Modified Kadane's-Algorithm THIS SECTION IS WIP - complexity yet unknown - hopefully optimal results This can be done by using a sweeping-plane algorithm, where each plane is a heightmap which encodes how many voxels extrude upwards, starting from each one of its pixels. The problem is thus reduced to finding the greatest cuboid on a heightmap, which can be done somewhat efficiently using Kadane's algorithm, where any `0` is treated as negative infinity and the heights are cut-off at some maximum height dynamically during the search. For a `n*n` map, Kadane's algorithm has a complexity of `O(n^3)` or `O(n)` per pixel. Whether this is usable has to be investigated further. Golden-Section-Search (not sure if this actually works) best known complexity optimal We can achieve logarithmic complexity per voxel. The approach to this is very similar to the naive method, but based on a crucial observation. The maximum volumes at each minimum height form a unimodal function. Our search is still based on finding the greatest are of 1 in a bitmap, but we choose our heights in a smarter way instead of iterating over all heights. Consider a histogram such as: ^ 7| # 6|# # # 5|# # ### # # 4|# # ### ## ### ## # 3|# ## ### ### ### ####### ## 2|#### ### ### #### ### ####### ### 1|##### #### ### ##### ############### #### -+----------------------------------------------> |0123456789abcdefghijklmnopqrstuvwxyzABCDEFGH The greatest areas for each height are: 7: 07 (3:1, 3:7) 6: 07 (3:1, 3:7) found by extruding (3:1, 3:6) >>5: 15 (8:1, a:5) >>4: 15 (8:1, a:5) >>>>3: 21 (w:1, C:3) >>>>2: 21 (w:1, C:3) >>1: 15 (o:1, C:1) Note that the maximum volumes at each height only form a unimodal function if we extrude our found area as far up as possible. Searching for the maximum or minimum of a unimodal function can be done with logarithmic complexity. The final complexity would thus be O(n^2 * log_2 n) or O(log_2 n) per pixel.","title":"Cuboid Extraction"},{"location":"cuboid_extraction.html#cuboid-extraction","text":"","title":"Cuboid Extraction"},{"location":"cuboid_extraction.html#motivation","text":"Voxel models of certain types have large volumes of voxels. These types include extruded heightmaps, medical scans, video game worlds and voxel art. Other types such as voxelized polygonal models may also be filled up instead of being kept hollow. The volumes may often be misaligned with the octree structure. Consider a single 2x2x2 cube in the center of an octree. All 8 subtrees of the octree would have to encode an individual voxel of this cube, which is far from optimal. In addition, decoding volumes which are completely filled simplifies the decoding process. These volumes could be extracted and encoded as cuboids like {triple<u8> pos, triple<u8> size} within a container that has dimensions up to 256^3. However we extract cuboids, those should be as large in volume as possible. This way, we cover the most voxels with our pairs of positions. The highest-volume container should be found, then extracted and the next-highest-volume container found, etc. We invest 6 bytes into the extraction, so our volume needs to be 48 to break even (e.g. 4x4x3 ).","title":"Motivation"},{"location":"cuboid_extraction.html#absolutely-stupid-method","text":"extreme complexity but optimal results Since a cuboid is just a pair of positions, we can simply iterate over all pairs of positions. We then iterate over all voxels in the cuboid to test whether they exist. For a d*d*d model containing v voxels the complexity is thus O(d^3 * d^3 * d^3) or O(d^9) or O(v^3) . This is some clown-world-tier complexity and should not find its way into any serious implementation. Due to its simplicity, it could be used to verify the correctness of more complex approaches though.","title":"Absolutely Stupid Method"},{"location":"cuboid_extraction.html#xyz-merge","text":"best possible complexity not optimal An XYZ-merge works by merging all neighboring voxels into lines on one axis first. Then neighboring lines are merged into planes on the second axis. Then neighboring planes are merged into cuboids on the last axis. The results are not optimal and may differ depending on the order of axes. At worst, we can't merge anything and thus iterate over every voxel in each of the steps once. The complexity is O(d^3 * 3) = O(d^3) or O(v) .","title":"XYZ-Merge"},{"location":"cuboid_extraction.html#heightmap-based-approaches","text":"All following approaches are based on the idea, that we can simplify this problem to a 2-dimensional one. One axis is being used as a height-axis, ideally the smallest one if the model is not cubical. We then use a sweeping-plane approach where at each coordinate, we draw a heightmap which extends into our chosen direction. Finding the largest volume in the model is reduced to finding the maximum of the largest volumes for all heightmaps.","title":"Heightmap-Based Approaches"},{"location":"cuboid_extraction.html#constructing-heightmaps-from-voxel-models","text":"Here is an illustration of how this is done, in 2 dimensions, where \"up\" in text is the height axis: 0123456789 0123456789 7 ### -> 1110000000 6 #### ## # -> 2221011010 5 ## ### # # -> 3302120101 4 ##### # ## -> 4413201012 3 ## # # # -> 5504010100 2 ######## -> 6612121200 1 ######### -> 7726232310 0 ## ## #### -> 8807303420 In this illustration, # would be encoded as 1 and would be encoded as 0 Each slice from 0 to 7 is one histogram in 2 dimensions or a heightmap in 3 dimensions. We can construct these very efficiently by just taking the heightmap at one height above and incrementing each height, unless we find an empty voxel ( 0 ).","title":"Constructing Heightmaps from Voxel-Models"},{"location":"cuboid_extraction.html#constructing-bitmaps-from-heightmaps","text":"Finding the largest cuboid in a voxel-model has been reduced to finding the largest cuboid in all its heightmaps. The problem is once again reduced to finding the largest area of 1 s in a bitmap, which can be done in O(n*n) . This is done by looking at all different height-values of the heightmap. At every height, a bitmap is constructed. In our bitmap of equal dimensions, 1 represents that the height at the location is >= the height. Example: 389200 111000 323350 ------> 101110 500020 (h=3) 100000 211141 000010 Finding the largest area of 1 in an n*n rectangle has O(n^2) complexity or O(1) per pixel, when using a sweeping-line algorithm and searching for the greatest area in the resulting histograms: https://www.geeksforgeeks.org/maximum-size-rectangle-binary-sub-matrix-1s/ The volume of the greatest cuboid is then the current height multiplied with the size of the greatest area of 1 which we find.","title":"Constructing Bitmaps from Heightmaps"},{"location":"cuboid_extraction.html#expected-values","text":"To understand the following approaches, one must realize that the highest cuboid is not necessarily the largest. For example, a very flat pyramid may have a shape which is only great in volume towards the base. For an n*n heightmap with n height, we can find the cuboid with the largest volume for all heights by finding the largest cuboid at each individual height. This forces us to check every single height.","title":"Expected values"},{"location":"cuboid_extraction.html#naive-method","text":"high complexity optimal results The naive method simply to iterate over all heights. We then require O(d^2 * d^2) complexity where one d^2 represents the size of the base and the other d^2 represents the amount of pairs of heights. This would be O(v^(4/3)) , which is not as bad as the stupid approach but still polynomial.","title":"Naive Method"},{"location":"cuboid_extraction.html#modified-kadanes-algorithm","text":"THIS SECTION IS WIP - complexity yet unknown - hopefully optimal results This can be done by using a sweeping-plane algorithm, where each plane is a heightmap which encodes how many voxels extrude upwards, starting from each one of its pixels. The problem is thus reduced to finding the greatest cuboid on a heightmap, which can be done somewhat efficiently using Kadane's algorithm, where any `0` is treated as negative infinity and the heights are cut-off at some maximum height dynamically during the search. For a `n*n` map, Kadane's algorithm has a complexity of `O(n^3)` or `O(n)` per pixel. Whether this is usable has to be investigated further.","title":"Modified Kadane's-Algorithm"},{"location":"cuboid_extraction.html#golden-section-search-not-sure-if-this-actually-works","text":"best known complexity optimal We can achieve logarithmic complexity per voxel. The approach to this is very similar to the naive method, but based on a crucial observation. The maximum volumes at each minimum height form a unimodal function. Our search is still based on finding the greatest are of 1 in a bitmap, but we choose our heights in a smarter way instead of iterating over all heights. Consider a histogram such as: ^ 7| # 6|# # # 5|# # ### # # 4|# # ### ## ### ## # 3|# ## ### ### ### ####### ## 2|#### ### ### #### ### ####### ### 1|##### #### ### ##### ############### #### -+----------------------------------------------> |0123456789abcdefghijklmnopqrstuvwxyzABCDEFGH The greatest areas for each height are: 7: 07 (3:1, 3:7) 6: 07 (3:1, 3:7) found by extruding (3:1, 3:6) >>5: 15 (8:1, a:5) >>4: 15 (8:1, a:5) >>>>3: 21 (w:1, C:3) >>>>2: 21 (w:1, C:3) >>1: 15 (o:1, C:1) Note that the maximum volumes at each height only form a unimodal function if we extrude our found area as far up as possible. Searching for the maximum or minimum of a unimodal function can be done with logarithmic complexity. The final complexity would thus be O(n^2 * log_2 n) or O(log_2 n) per pixel.","title":"Golden-Section-Search (not sure if this actually works)"},{"location":"properties.html","text":"Properties of Voxel Models The cornerstone of compression is discovering and eliminating redundancies in data. We must first recognize these redundancies by observing the nature of voxel models. There are plenty of properties which we can exploit, as described in the following sections. Geometric/Spatial Locality Normalized 3D Perlin Noise with a threshold of 0.4 Voxels rarely come alone. All 3D models will typically take some distinguished shape. There will be large areas with filled geometry (voxels) and large empty areas, air , or void . In artistic circles these are often described as negative space . Uniform voxel noise with a probability of 0.1 that a voxel is set The only kind of model which has no spatial locality whatsoever would be uniformly distributed noise. (see above) These kinds of models are the absolute exception and are rarely if ever seen. Conclusion Compression schemes have to be able to describe large volumes of positive and negative space efficiently. Color/Attribute Locality \"Ragged Cluster\" model visualized in Magica Voxel Color and other attributes such as normals correlate with geometry. This means that the color distance between neighboring voxels is significantly lower than the distance of random points in RGB space. In fact, this correlation is dramatically high. For the above model, the average euclidean distance of any unique pair of neighboring voxel colors (0, 0, 0) \\le (r, g, b) \\le (255, 255, 255) is 8.56 . Normalized for positions in a unit cube instead this is 0.03357 . For uniform random colors, this distance would be equal to Robbin's Constant which is roughly equal to 0.66170 , almost 20 times higher. Conclusion Compression schemes should make use of geometric encoding and attach attributes on top of that. Alternatively voxel compression schemes should encode attributes in a fashion very similar to geometry. Color Sparsity While in principle, plenty of software supports 24-bit True Color RGB or even wider standards, only a small amount of colors are actually used. Especially in the field of Voxel Art , the 3D-equivalent to Pixel Art , small palettes are used. To name an example, Magica Voxel supports 255 unique colors but each individual color is a 24-bit True Color. Conclusion Compression schemes should be aware of potentially very low color counts and exploit these by building a palette. A palette will not always be beneficial since in principle, any amount of colors should be present. However, in many cases this will be beneficial.","title":"Properties of Voxel Models"},{"location":"properties.html#properties-of-voxel-models","text":"The cornerstone of compression is discovering and eliminating redundancies in data. We must first recognize these redundancies by observing the nature of voxel models. There are plenty of properties which we can exploit, as described in the following sections.","title":"Properties of Voxel Models"},{"location":"properties.html#geometricspatial-locality","text":"Normalized 3D Perlin Noise with a threshold of 0.4 Voxels rarely come alone. All 3D models will typically take some distinguished shape. There will be large areas with filled geometry (voxels) and large empty areas, air , or void . In artistic circles these are often described as negative space . Uniform voxel noise with a probability of 0.1 that a voxel is set The only kind of model which has no spatial locality whatsoever would be uniformly distributed noise. (see above) These kinds of models are the absolute exception and are rarely if ever seen.","title":"Geometric/Spatial Locality"},{"location":"properties.html#conclusion","text":"Compression schemes have to be able to describe large volumes of positive and negative space efficiently.","title":"Conclusion"},{"location":"properties.html#colorattribute-locality","text":"\"Ragged Cluster\" model visualized in Magica Voxel Color and other attributes such as normals correlate with geometry. This means that the color distance between neighboring voxels is significantly lower than the distance of random points in RGB space. In fact, this correlation is dramatically high. For the above model, the average euclidean distance of any unique pair of neighboring voxel colors (0, 0, 0) \\le (r, g, b) \\le (255, 255, 255) is 8.56 . Normalized for positions in a unit cube instead this is 0.03357 . For uniform random colors, this distance would be equal to Robbin's Constant which is roughly equal to 0.66170 , almost 20 times higher.","title":"Color/Attribute Locality"},{"location":"properties.html#conclusion_1","text":"Compression schemes should make use of geometric encoding and attach attributes on top of that. Alternatively voxel compression schemes should encode attributes in a fashion very similar to geometry.","title":"Conclusion"},{"location":"properties.html#color-sparsity","text":"While in principle, plenty of software supports 24-bit True Color RGB or even wider standards, only a small amount of colors are actually used. Especially in the field of Voxel Art , the 3D-equivalent to Pixel Art , small palettes are used. To name an example, Magica Voxel supports 255 unique colors but each individual color is a 24-bit True Color.","title":"Color Sparsity"},{"location":"properties.html#conclusion_2","text":"Compression schemes should be aware of potentially very low color counts and exploit these by building a palette. A palette will not always be beneficial since in principle, any amount of colors should be present. However, in many cases this will be beneficial.","title":"Conclusion"},{"location":"statistical_tests.html","text":"Statistical Tests to Determine Voxel Model Properties The following list should give an overview over possible properties which voxel models are suspected to have. A description of an algorithm and/or pseudocude is used to provide a potential test. Spatial Locality of Different Methods of Iteration Over Voxel Models There are various different ways of iterating over a voxel model. We will consider only two or three, which are relevant to us. Nested Loop Iteration This is the traditional method of iterating over multi-dimensional arrays. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[x][y][z]; It is extremely efficient for traversing memory because it seemlessly iterates over memory locations, as long as the axes of iteration are in the right order. The distances between two positions are at best 1 and at worst SIZE_X + SIZEY . However, the spatial locality is much worse when looking at more than one position. For say, 10 positions the distance between the first and last will be 10, which is comparably far. Z-Order Iteration Z-Order iteration traverses space with much higher locality. It works by traversing all nodes of an octree depth-first. 3D-Vectors can be converted into \"octree positions\" by interleaving the bits of the coordinates into a single number. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[interleave_bits(x, y, z)]; ) Hilbert-Curve Iteration Hilbert-Curves have even higher locality than Z-Order iterations, but are considerably better in locality. See https://slideplayer.com/slide/3370293/ for construction. In short, space is filled in the following order, which is a Gray Code. [[0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 0]] The entry direction for one of these pieces is +Z and the exit-direction is -Y. This pattern is repeated recursively, but the smaller building blocks have to be mirrored and rotated to fit together seemlessly into a larger block. The tremendously useful property here is that the distance between two points in the iteration is at most 1 . Testing Spatial Locality Spatial locality can simply be tested by comparing the average distance between each pair of points, triple of points, etc. within an iteration. When more than two points are tested, the distances of each unique pair of points can be summed up or averaged. Hilber-Curve Iteration is expected to deliver the best results on most, if not all scales. Correlation of Color and Geometry Deltas It is expected that color correlates with positions. This means that positions which are close to each other should also have similar colors. To verify this property, each unique pair of points can be iterated over. The euclidean distance in geometry-space (scaled down to a unit-cube) as well as the euclidean distance in the RGB color space should be plotted. The correlation can then be calculated from all data entries. struct Entry { double geoDistance; double colDistance; }; struct ColoredPoint { vec3 geo; vec3 col; } std::vector<double[2]> entries; for (const std::pair<ColoredPoint, ColoredPoint> &pair : allPoints) { double geoDistance = pair.first.geo.distanceTo(pair.second.geo); double colDistance = pair.first.col.distanceTo(pair.second.col); entries.emplace_back(geoDistance, colDistance); }","title":"Statistical Tests to Determine Voxel Model Properties"},{"location":"statistical_tests.html#statistical-tests-to-determine-voxel-model-properties","text":"The following list should give an overview over possible properties which voxel models are suspected to have. A description of an algorithm and/or pseudocude is used to provide a potential test.","title":"Statistical Tests to Determine Voxel Model Properties"},{"location":"statistical_tests.html#spatial-locality-of-different-methods-of-iteration-over-voxel-models","text":"There are various different ways of iterating over a voxel model. We will consider only two or three, which are relevant to us.","title":"Spatial Locality of Different Methods of Iteration Over Voxel Models"},{"location":"statistical_tests.html#nested-loop-iteration","text":"This is the traditional method of iterating over multi-dimensional arrays. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[x][y][z]; It is extremely efficient for traversing memory because it seemlessly iterates over memory locations, as long as the axes of iteration are in the right order. The distances between two positions are at best 1 and at worst SIZE_X + SIZEY . However, the spatial locality is much worse when looking at more than one position. For say, 10 positions the distance between the first and last will be 10, which is comparably far.","title":"Nested Loop Iteration"},{"location":"statistical_tests.html#z-order-iteration","text":"Z-Order iteration traverses space with much higher locality. It works by traversing all nodes of an octree depth-first. 3D-Vectors can be converted into \"octree positions\" by interleaving the bits of the coordinates into a single number. char data[SIZE_X][SIZE_Y][SIZE_Z]; for (size_t x = 0; x < SIZE_X; ++x) for (size_t y = 0; y < SIZE_Y; ++y) for (size_t z = 0; z < SIZE_Z; ++z) data[interleave_bits(x, y, z)]; )","title":"Z-Order Iteration"},{"location":"statistical_tests.html#hilbert-curve-iteration","text":"Hilbert-Curves have even higher locality than Z-Order iterations, but are considerably better in locality. See https://slideplayer.com/slide/3370293/ for construction. In short, space is filled in the following order, which is a Gray Code. [[0, 0, 0], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 1, 1], [1, 0, 1], [1, 0, 0]] The entry direction for one of these pieces is +Z and the exit-direction is -Y. This pattern is repeated recursively, but the smaller building blocks have to be mirrored and rotated to fit together seemlessly into a larger block. The tremendously useful property here is that the distance between two points in the iteration is at most 1 .","title":"Hilbert-Curve Iteration"},{"location":"statistical_tests.html#testing-spatial-locality","text":"Spatial locality can simply be tested by comparing the average distance between each pair of points, triple of points, etc. within an iteration. When more than two points are tested, the distances of each unique pair of points can be summed up or averaged. Hilber-Curve Iteration is expected to deliver the best results on most, if not all scales.","title":"Testing Spatial Locality"},{"location":"statistical_tests.html#correlation-of-color-and-geometry-deltas","text":"It is expected that color correlates with positions. This means that positions which are close to each other should also have similar colors. To verify this property, each unique pair of points can be iterated over. The euclidean distance in geometry-space (scaled down to a unit-cube) as well as the euclidean distance in the RGB color space should be plotted. The correlation can then be calculated from all data entries. struct Entry { double geoDistance; double colDistance; }; struct ColoredPoint { vec3 geo; vec3 col; } std::vector<double[2]> entries; for (const std::pair<ColoredPoint, ColoredPoint> &pair : allPoints) { double geoDistance = pair.first.geo.distanceTo(pair.second.geo); double colDistance = pair.first.col.distanceTo(pair.second.col); entries.emplace_back(geoDistance, colDistance); }","title":"Correlation of Color and Geometry Deltas"},{"location":"uncompressed.html","text":"Uncompressed Format The uncompressed format used for reference in this project is a 32-bit list of voxels. In this case a voxel is a triple of coordinates and an ARGB integer, meaning that voxels can be partially transparent. Example Implementation Here is a simple example implementation of a 32-bit voxel list in C++. struct voxel { int32_t x; int32_t y; int32_t z; uint8_t a; uint8_t r; uint8_t g; uint8_t b; } std::vector<voxel> voxel_list; Justification - Voxel Arrays vs. Voxel Lists There are at least two popular methods of representing voxels in an uncompressed way: 3D-array of colors, aka. voxel array array of coordinate/color pairs, aka. voxel list The first method is often used in software on a small scale. Arrays allow for random access in O(1) . They are also used in other research, such as High Resolution Sparse Voxel DAGs . Despite its popularity, arrays are unsuitable for measuring compression ratios because the entropy of the voxel data poorly correlates with the size of this representation. For instance, two voxels at (1, 1, 1) and (1000, 1000, 1000) require 1 gigavoxel of space due to all the empty space between the two voxels. However, in the best case where all voxels are present, this method has only constant overhead: that which is necessary to store the dimensions of the array. The second representation -which is the one used here- will require space that linearly scales with the amount of non-empty voxels. Note that in the worst case, this could require four times the space of the first method due to the coordinates being stored explicitly. This kind of overhead is still preferable to the potential (near) complete waste of space of the first method. To summarize, here is a quick overview: Voxel Array Voxel List worst case overhead (space) O(\\infty) 1 O(4n) 2 best case overhead (space) \\Omega(1) \\Omega(4n) 2 random access (time) O(1) O(n) Serialization Serialization of this representation is trivial because the data structure in memory is similar of not identical to its serialized counterpart. Here, the VL32 file format is used. Unbounded because two voxels can be infinitely far apart, creating infinite wasted space / overhead \u21a9 The constant factor of 4 is irrelevant in this notation, but illustrates the extent of the overhead \u21a9 \u21a9","title":"Uncompressed Format"},{"location":"uncompressed.html#uncompressed-format","text":"The uncompressed format used for reference in this project is a 32-bit list of voxels. In this case a voxel is a triple of coordinates and an ARGB integer, meaning that voxels can be partially transparent.","title":"Uncompressed Format"},{"location":"uncompressed.html#example-implementation","text":"Here is a simple example implementation of a 32-bit voxel list in C++. struct voxel { int32_t x; int32_t y; int32_t z; uint8_t a; uint8_t r; uint8_t g; uint8_t b; } std::vector<voxel> voxel_list;","title":"Example Implementation"},{"location":"uncompressed.html#justification-voxel-arrays-vs-voxel-lists","text":"There are at least two popular methods of representing voxels in an uncompressed way: 3D-array of colors, aka. voxel array array of coordinate/color pairs, aka. voxel list The first method is often used in software on a small scale. Arrays allow for random access in O(1) . They are also used in other research, such as High Resolution Sparse Voxel DAGs . Despite its popularity, arrays are unsuitable for measuring compression ratios because the entropy of the voxel data poorly correlates with the size of this representation. For instance, two voxels at (1, 1, 1) and (1000, 1000, 1000) require 1 gigavoxel of space due to all the empty space between the two voxels. However, in the best case where all voxels are present, this method has only constant overhead: that which is necessary to store the dimensions of the array. The second representation -which is the one used here- will require space that linearly scales with the amount of non-empty voxels. Note that in the worst case, this could require four times the space of the first method due to the coordinates being stored explicitly. This kind of overhead is still preferable to the potential (near) complete waste of space of the first method. To summarize, here is a quick overview: Voxel Array Voxel List worst case overhead (space) O(\\infty) 1 O(4n) 2 best case overhead (space) \\Omega(1) \\Omega(4n) 2 random access (time) O(1) O(n)","title":"Justification - Voxel Arrays vs. Voxel Lists"},{"location":"uncompressed.html#serialization","text":"Serialization of this representation is trivial because the data structure in memory is similar of not identical to its serialized counterpart. Here, the VL32 file format is used. Unbounded because two voxels can be infinitely far apart, creating infinite wasted space / overhead \u21a9 The constant factor of 4 is irrelevant in this notation, but illustrates the extent of the overhead \u21a9 \u21a9","title":"Serialization"},{"location":"dag/dag.html","text":"Directed Acyclic Graph Figure 1: A Directed Acyclic Graph Directed Acyclic Graphs (DAGs) for voxel encoding build on the idea of octrees. However, they allow nodes to reference the branches of other nodes. How this may work can be seen in Figure 1 . The second branch of the root node stores a +4 . This +4 points four nodes ahead, on the same level in the graph and tells the decoder \"this node has the same content\" as the node four positions ahead. It is a four because there are three zero bits in the root node between this node and the one it points to.","title":"Directed Acyclic Graph"},{"location":"dag/dag.html#directed-acyclic-graph","text":"Figure 1: A Directed Acyclic Graph Directed Acyclic Graphs (DAGs) for voxel encoding build on the idea of octrees. However, they allow nodes to reference the branches of other nodes. How this may work can be seen in Figure 1 . The second branch of the root node stores a +4 . This +4 points four nodes ahead, on the same level in the graph and tells the decoder \"this node has the same content\" as the node four positions ahead. It is a four because there are three zero bits in the root node between this node and the one it points to.","title":"Directed Acyclic Graph"},{"location":"file_formats/structlang.html","text":"Structure Language (StructLang) StructLang is a data specification language used within the scope of this project. It uses a syntax similar to Rust and C to mathematically specify a syntax for binary data. Comments Comments begin with a // and continue until the end of the line. Alternatively, a comment block which begins with /* and ends with */ can be used. Settings Some global settings may be necessary to write a proper specification. Syntax set = \"set\" identifier \"=\" value; Examples set byte_bits = 32 set default_byte_order = big_endian set default_signed_representation = twos_complement List of Settings Identifier Type Description byte_bits unsigned integer number of bits in one byte default_byte_order modifier default byte order (endianness) of types default_signed_representation modifier default representation of signed integers Type Definitions Definitions define data types. Syntax def = \"def\" type \"=\" {modifier} base_type; type is the identifier of the type modifier a type modifier base_type the base type which this type is specializing Example def i32 = signed 32_bit twos_complement integer def u8 = unsigned 8_bit integer def string = null_terminated u8[] Arrays Arrays are blocks of one type which are stored using a single variable. Syntax array_type = type \"[\" size | \"\" \"]\"; Examples u8[4096] buffer // a constant-sized array u32 size u8[size] var_buffer // a variable-sized array u8[] endless_buffer // an array which extends until the end of the data Structures Defines a structure of other types. These types can also be structures. The first (uppermost) type in a struct is also the first element in the serialized data. Syntax struct = \"struct\" identifier \"{\" type identifier ... \"}\"; Example struct Color { u8 red u8 green u8 blue } Enumerations Defines a list of constants of some type. Syntax enum = \"enum\", identifier, \":\", type, \"{\", {identifier, \"=\", value}, \"}\"; Examples enum Size : string { SMALL = \"S\" MEDIUM = \"M\" LARGE = \"L\" EXTRA_LARGE = \"XL\" } enum ArgbColor : u32 { RED = 0xffff0000 GREEN = 0xff00ff00 BLUE = 0xff0000ff } Templated Structures Sometimes a structure depends on content found in a header or other structures. Templates can change how a structure is laid out using variables. Syntax struct = \"struct\" type \"<\" type {identifier \",\"} \">\" \"{\" ... \"}\"; Example struct varint<u8 bits> { if bits == 8 { u8 data } else if bits == 16 { u16 data } else if bits == 32 { u32 data } else { error \"Invalid bits variable\" } }","title":"Structure Language (StructLang)"},{"location":"file_formats/structlang.html#structure-language-structlang","text":"StructLang is a data specification language used within the scope of this project. It uses a syntax similar to Rust and C to mathematically specify a syntax for binary data.","title":"Structure Language (StructLang)"},{"location":"file_formats/structlang.html#comments","text":"Comments begin with a // and continue until the end of the line. Alternatively, a comment block which begins with /* and ends with */ can be used.","title":"Comments"},{"location":"file_formats/structlang.html#settings","text":"Some global settings may be necessary to write a proper specification.","title":"Settings"},{"location":"file_formats/structlang.html#syntax","text":"set = \"set\" identifier \"=\" value;","title":"Syntax"},{"location":"file_formats/structlang.html#examples","text":"set byte_bits = 32 set default_byte_order = big_endian set default_signed_representation = twos_complement","title":"Examples"},{"location":"file_formats/structlang.html#list-of-settings","text":"Identifier Type Description byte_bits unsigned integer number of bits in one byte default_byte_order modifier default byte order (endianness) of types default_signed_representation modifier default representation of signed integers","title":"List of Settings"},{"location":"file_formats/structlang.html#type-definitions","text":"Definitions define data types.","title":"Type Definitions"},{"location":"file_formats/structlang.html#syntax_1","text":"def = \"def\" type \"=\" {modifier} base_type; type is the identifier of the type modifier a type modifier base_type the base type which this type is specializing","title":"Syntax"},{"location":"file_formats/structlang.html#example","text":"def i32 = signed 32_bit twos_complement integer def u8 = unsigned 8_bit integer def string = null_terminated u8[]","title":"Example"},{"location":"file_formats/structlang.html#arrays","text":"Arrays are blocks of one type which are stored using a single variable.","title":"Arrays"},{"location":"file_formats/structlang.html#syntax_2","text":"array_type = type \"[\" size | \"\" \"]\";","title":"Syntax"},{"location":"file_formats/structlang.html#examples_1","text":"u8[4096] buffer // a constant-sized array u32 size u8[size] var_buffer // a variable-sized array u8[] endless_buffer // an array which extends until the end of the data","title":"Examples"},{"location":"file_formats/structlang.html#structures","text":"Defines a structure of other types. These types can also be structures. The first (uppermost) type in a struct is also the first element in the serialized data.","title":"Structures"},{"location":"file_formats/structlang.html#syntax_3","text":"struct = \"struct\" identifier \"{\" type identifier ... \"}\";","title":"Syntax"},{"location":"file_formats/structlang.html#example_1","text":"struct Color { u8 red u8 green u8 blue }","title":"Example"},{"location":"file_formats/structlang.html#enumerations","text":"Defines a list of constants of some type.","title":"Enumerations"},{"location":"file_formats/structlang.html#syntax_4","text":"enum = \"enum\", identifier, \":\", type, \"{\", {identifier, \"=\", value}, \"}\";","title":"Syntax"},{"location":"file_formats/structlang.html#examples_2","text":"enum Size : string { SMALL = \"S\" MEDIUM = \"M\" LARGE = \"L\" EXTRA_LARGE = \"XL\" } enum ArgbColor : u32 { RED = 0xffff0000 GREEN = 0xff00ff00 BLUE = 0xff0000ff }","title":"Examples"},{"location":"file_formats/structlang.html#templated-structures","text":"Sometimes a structure depends on content found in a header or other structures. Templates can change how a structure is laid out using variables.","title":"Templated Structures"},{"location":"file_formats/structlang.html#syntax_5","text":"struct = \"struct\" type \"<\" type {identifier \",\"} \">\" \"{\" ... \"}\";","title":"Syntax"},{"location":"file_formats/structlang.html#example_2","text":"struct varint<u8 bits> { if bits == 8 { u8 data } else if bits == 16 { u16 data } else if bits == 32 { u32 data } else { error \"Invalid bits variable\" } }","title":"Example"},{"location":"file_formats/vl32.html","text":"32-Bit Voxel List (VL32) VL32 is a simple, binary, intermediate file format used in the code of this research project. Extension: .vl32 Media Type: model/x-vl32 Specification VL32 can be specified in only a few lines of StructLang: def u8 = unsigned 8_bit integer def i32 = big_endian twos_complement 32_bit integer struct main { voxel[] voxels } struct voxel { i32 x i32 y i32 z argb32 color } struct argb32 { u8 alpha u8 red u8 green u8 blue } Voxels with a color that has an alpha of zero are treated as void. Use Case VL32 is largely used for benchmarking compression efficiency. Any compression effort should yield significantly higher entropy than this format. One of the significant advantages is that there doesn't need to be any header information. When reading, voxels are simply loaded until the EOF is reached. Also there is no difference in data size between the file encoded on disk and its typical in-memory representation, such as a std::vector of voxels.","title":"32-Bit Voxel List (VL32)"},{"location":"file_formats/vl32.html#32-bit-voxel-list-vl32","text":"VL32 is a simple, binary, intermediate file format used in the code of this research project. Extension: .vl32 Media Type: model/x-vl32","title":"32-Bit Voxel List (VL32)"},{"location":"file_formats/vl32.html#specification","text":"VL32 can be specified in only a few lines of StructLang: def u8 = unsigned 8_bit integer def i32 = big_endian twos_complement 32_bit integer struct main { voxel[] voxels } struct voxel { i32 x i32 y i32 z argb32 color } struct argb32 { u8 alpha u8 red u8 green u8 blue } Voxels with a color that has an alpha of zero are treated as void.","title":"Specification"},{"location":"file_formats/vl32.html#use-case","text":"VL32 is largely used for benchmarking compression efficiency. Any compression effort should yield significantly higher entropy than this format. One of the significant advantages is that there doesn't need to be any header information. When reading, voxels are simply loaded until the EOF is reached. Also there is no difference in data size between the file encoded on disk and its typical in-memory representation, such as a std::vector of voxels.","title":"Use Case"},{"location":"file_formats/vlascii.html","text":"ASCII Voxel List (VLASCII) VLASCII is a simple, text-based, intermediate file format used in the code of this research project. Extension: .vlascii Media Type: model/x-vlascii Specification Here the specification, in EBNF . vlascii = { line }; (* lines can be empty *) line = [comment | voxel], {\" \"}, nl; (* trailing space allowed *) comment = \"#\", { ?any character? } - nl; voxel = xyz, space, color, space; xyz = integer, space, integer, space, integer; color = (h, h, h, h, h, h) | (h, h, h); h = ?hexadecimal digit?; integer = [\"-\"], ?decimal digit?, { ?decimal digit? }; nl = ?newline character?; space = \" \", { \" \" }; Example # red voxel at 0, 0, 0 0 0 0 ff0000 # white voxel at 0, 1, 0 0 1 0 fff # black voxel at 0, 0, 1 0 0 1 000","title":"ASCII Voxel List (VLASCII)"},{"location":"file_formats/vlascii.html#ascii-voxel-list-vlascii","text":"VLASCII is a simple, text-based, intermediate file format used in the code of this research project. Extension: .vlascii Media Type: model/x-vlascii","title":"ASCII Voxel List (VLASCII)"},{"location":"file_formats/vlascii.html#specification","text":"Here the specification, in EBNF . vlascii = { line }; (* lines can be empty *) line = [comment | voxel], {\" \"}, nl; (* trailing space allowed *) comment = \"#\", { ?any character? } - nl; voxel = xyz, space, color, space; xyz = integer, space, integer, space, integer; color = (h, h, h, h, h, h) | (h, h, h); h = ?hexadecimal digit?; integer = [\"-\"], ?decimal digit?, { ?decimal digit? }; nl = ?newline character?; space = \" \", { \" \" };","title":"Specification"},{"location":"file_formats/vlascii.html#example","text":"# red voxel at 0, 0, 0 0 0 0 ff0000 # white voxel at 0, 1, 0 0 1 0 fff # black voxel at 0, 0, 1 0 0 1 000","title":"Example"},{"location":"flvc/flvc.html","text":"Free Lossless Voxel Compression (FLVC) FLVC is the file format produced based on the results of the presented research. Extension: .flvc Media Type: model/x-flvc Magic Bytes: \"\\xff\\x11\\x33\\xccflvc\" = ff 11 33 cc 66 6c 76 63 Specification StructLang Type Definitions def u8 = unsigned integer<8> def u16 = big_endian unsigned integer<16> def u32 = big_endian unsigned integer<32> def u64 = big_endian unsigned integer<64> def i8 = twos_complement integer<8> def i16 = big_endian twos_complement integer<16> def i32 = big_endian twos_complement integer<32> def i64 = big_endian twos_complement integer<64> def ascii = unsigned hi_pad integer<7> Enumerations And Constants enum attribute_modifier : u16 { // this attribute has no spatial locality // should be used for random unique ids etc. NON_LOCAL = 1 // only applicable to the \"color\" attribute // whatever color model is used, alpha will be appended to it last // ARGB is the default, in which alpha is first ALPHA_LAST = 2 } enum attribute_type : u8 { BOOL = 0x00 INT_8 = 0x11 INT_16 = 0x12 INT_32 = 0x13 INT_64 = 0x14 UINT_8 = 0x21 UINT_16 = 0x22 UINT_32 = 0x23 UINT_64 = 0x24 FLOAT_32 = 0x41 FLOAT_64 = 0x42 } enum builtin_identifiers : string16 { // attributes will be used as the color of the voxel COLOR = \"color\" // attributes will be used as the normal of the voxel NORMAL = \"normal\" } Helper Structs struct vec3<T> { T x T y T z } struct string16 { u16 size ascii[size] content } Note that vec3 is a template. e.g. vec3<u32> would be a vec3 of u32 . File Structure struct main { u64 magic = 0xff11_33cc_666c_7663 u8 version_major = 0 u8 version_minor = 1 header header content content } struct header { u16 attribute_count attribute_definition[attribute_count] attributes // Global offset which is applied to all voxels which we read. vec3<i32> offset // The size of the SVO. vec3<u32> size } struct attribute_definition { // bitmap storing all modifiers u16 modifier_map // type of the attribute attribute_type atype // Must be <= 3. // If not zero, this indicates that the type is a fixed-size array-type or vector-type. // If zero, the type is a variable sized-array. u8 cardinality // unique identifier of the attribute // certain values such as \"color\" are builtin and reserved // (see enum builtin_identifiers) string16 identifier } header.size is not strictly necessary for decoding, but it can be helpful when converting directly to a 3D array or other format which requires a size upon construction. The attribute definition allows us to practically store any data we want inside of the format. For example, store an RGB24 value: modifier_map = SERIAL atype = UINT_8 cardinality = 3 identifier = \"color\" struct content { u64 node_count extern svo_data svo_data } The actual svo_data is too complex to be expressed in StructLang.","title":"Free Lossless Voxel Compression (FLVC)"},{"location":"flvc/flvc.html#free-lossless-voxel-compression-flvc","text":"FLVC is the file format produced based on the results of the presented research. Extension: .flvc Media Type: model/x-flvc Magic Bytes: \"\\xff\\x11\\x33\\xccflvc\" = ff 11 33 cc 66 6c 76 63","title":"Free Lossless Voxel Compression (FLVC)"},{"location":"flvc/flvc.html#specification","text":"","title":"Specification"},{"location":"flvc/flvc.html#structlang-type-definitions","text":"def u8 = unsigned integer<8> def u16 = big_endian unsigned integer<16> def u32 = big_endian unsigned integer<32> def u64 = big_endian unsigned integer<64> def i8 = twos_complement integer<8> def i16 = big_endian twos_complement integer<16> def i32 = big_endian twos_complement integer<32> def i64 = big_endian twos_complement integer<64> def ascii = unsigned hi_pad integer<7>","title":"StructLang Type Definitions"},{"location":"flvc/flvc.html#enumerations-and-constants","text":"enum attribute_modifier : u16 { // this attribute has no spatial locality // should be used for random unique ids etc. NON_LOCAL = 1 // only applicable to the \"color\" attribute // whatever color model is used, alpha will be appended to it last // ARGB is the default, in which alpha is first ALPHA_LAST = 2 } enum attribute_type : u8 { BOOL = 0x00 INT_8 = 0x11 INT_16 = 0x12 INT_32 = 0x13 INT_64 = 0x14 UINT_8 = 0x21 UINT_16 = 0x22 UINT_32 = 0x23 UINT_64 = 0x24 FLOAT_32 = 0x41 FLOAT_64 = 0x42 } enum builtin_identifiers : string16 { // attributes will be used as the color of the voxel COLOR = \"color\" // attributes will be used as the normal of the voxel NORMAL = \"normal\" }","title":"Enumerations And Constants"},{"location":"flvc/flvc.html#helper-structs","text":"struct vec3<T> { T x T y T z } struct string16 { u16 size ascii[size] content } Note that vec3 is a template. e.g. vec3<u32> would be a vec3 of u32 .","title":"Helper Structs"},{"location":"flvc/flvc.html#file-structure","text":"struct main { u64 magic = 0xff11_33cc_666c_7663 u8 version_major = 0 u8 version_minor = 1 header header content content } struct header { u16 attribute_count attribute_definition[attribute_count] attributes // Global offset which is applied to all voxels which we read. vec3<i32> offset // The size of the SVO. vec3<u32> size } struct attribute_definition { // bitmap storing all modifiers u16 modifier_map // type of the attribute attribute_type atype // Must be <= 3. // If not zero, this indicates that the type is a fixed-size array-type or vector-type. // If zero, the type is a variable sized-array. u8 cardinality // unique identifier of the attribute // certain values such as \"color\" are builtin and reserved // (see enum builtin_identifiers) string16 identifier } header.size is not strictly necessary for decoding, but it can be helpful when converting directly to a 3D array or other format which requires a size upon construction. The attribute definition allows us to practically store any data we want inside of the format. For example, store an RGB24 value: modifier_map = SERIAL atype = UINT_8 cardinality = 3 identifier = \"color\" struct content { u64 node_count extern svo_data svo_data } The actual svo_data is too complex to be expressed in StructLang.","title":"File Structure"},{"location":"related/literature.html","text":"Literature References Efficient Sparse Voxel Octrees Authors: Samuli Laine, Tero Karras Publisher: NVIDIA Research Publication Date: 2010-02-01 Published in: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) Links: NVIDIA Research , PDF Last Viewed: 2020-05-04 Geometry and Attribute Compression for Voxel Scenes Authors: Bas Dado, Timothy R. Kol, Pablo Bauszat, Jean-Marc Thiery, Elmar Eisemann Publisher: Delft University of Technology Publication Date: 2015-12-16 Also published in: EUROGRAPHICS 2016, Volume 35 (2016), Number 2 Links: TUDelft , PDF Last Viewed: 2020-05-04 High Resolution Sparse Voxel DAGs Authors: Viktor Ka\u0308mpe, Erik Sintorn, Ulf Assarsson Publisher: Chalmers University of Technology Publication Date: 2013-07 Published in: ACM Transactions on Graphics , Vol 32, No. 4 Links: ACM Digital Library , PDF Last Viewed: 2020-05-04 VOLA: A Compact Volumetric Format for 3D Mapping and Embedded Systems Authors: Jonathan Byrne, Le\u0301onie Buckley, Sam Caulfield, David Moloney Publisher: Advanced Architecture Group, Intel, Ireland Publication Date: 2018-01 Conference: 4th International Conference on Geographical Information Systems Theory, Applications and Management Published in: Proceedings of the 4th International Conference on Geographical Information Systems Theory, Applications and Management - Volume 1: GISTAM Links: Researchgate , PDF Last Viewed: 2020-05-04 Qubicle File Specification Articles Authors: Minddesk Software GmbH Publication Dates: 2015-10-02, 2016-01-11 Published at: getqubicle.com Links: QEF Spec. , QB Spec. , QBT Spec. Last Viewed: 2020-05-04 Binvox Voxel File Format Specification Author: Patrick Min Last Modification Date: 2015-12-17 Published at: patrickmin.com Links: Website , Parent Page Last Viewed: 2020-06-03 Compressing Voxel Worlds Author: Steven Pigeon Publication Date: 2011 or prior Published at: Harder, Better, Faster, Stronger Blog Links: HBFS Page Last Viewed: 2020-05-30 Symmetry-aware Sparse Voxel DAGs (SSVDAGs) for compression-domain tracing of high-resolution geometric scenes Authors: Alberto Jaspe Villanueva, Fabio Marton, Enrico Gobbetti, CRS4 Publication Date: 2017-05-12 Published In: Journal of Computer Graphics Techniques (JCGT), vol. 6, no. 2 Links: Computer Graphics Techniques , Full-Text PDF , Low-Resolution PDF , Video Demo","title":"Literature References"},{"location":"related/literature.html#literature-references","text":"","title":"Literature References"},{"location":"related/literature.html#efficient-sparse-voxel-octrees","text":"Authors: Samuli Laine, Tero Karras Publisher: NVIDIA Research Publication Date: 2010-02-01 Published in: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D) Links: NVIDIA Research , PDF Last Viewed: 2020-05-04","title":"Efficient Sparse Voxel Octrees"},{"location":"related/literature.html#geometry-and-attribute-compression-for-voxel-scenes","text":"Authors: Bas Dado, Timothy R. Kol, Pablo Bauszat, Jean-Marc Thiery, Elmar Eisemann Publisher: Delft University of Technology Publication Date: 2015-12-16 Also published in: EUROGRAPHICS 2016, Volume 35 (2016), Number 2 Links: TUDelft , PDF Last Viewed: 2020-05-04","title":"Geometry and Attribute Compression for Voxel Scenes"},{"location":"related/literature.html#high-resolution-sparse-voxel-dags","text":"Authors: Viktor Ka\u0308mpe, Erik Sintorn, Ulf Assarsson Publisher: Chalmers University of Technology Publication Date: 2013-07 Published in: ACM Transactions on Graphics , Vol 32, No. 4 Links: ACM Digital Library , PDF Last Viewed: 2020-05-04","title":"High Resolution Sparse Voxel DAGs"},{"location":"related/literature.html#vola-a-compact-volumetric-format-for-3d-mapping-and-embedded-systems","text":"Authors: Jonathan Byrne, Le\u0301onie Buckley, Sam Caulfield, David Moloney Publisher: Advanced Architecture Group, Intel, Ireland Publication Date: 2018-01 Conference: 4th International Conference on Geographical Information Systems Theory, Applications and Management Published in: Proceedings of the 4th International Conference on Geographical Information Systems Theory, Applications and Management - Volume 1: GISTAM Links: Researchgate , PDF Last Viewed: 2020-05-04","title":"VOLA: A Compact Volumetric Format for 3D Mapping and Embedded Systems"},{"location":"related/literature.html#qubicle-file-specification-articles","text":"Authors: Minddesk Software GmbH Publication Dates: 2015-10-02, 2016-01-11 Published at: getqubicle.com Links: QEF Spec. , QB Spec. , QBT Spec. Last Viewed: 2020-05-04","title":"Qubicle File Specification Articles"},{"location":"related/literature.html#binvox-voxel-file-format-specification","text":"Author: Patrick Min Last Modification Date: 2015-12-17 Published at: patrickmin.com Links: Website , Parent Page Last Viewed: 2020-06-03","title":"Binvox Voxel File Format Specification"},{"location":"related/literature.html#compressing-voxel-worlds","text":"Author: Steven Pigeon Publication Date: 2011 or prior Published at: Harder, Better, Faster, Stronger Blog Links: HBFS Page Last Viewed: 2020-05-30","title":"Compressing Voxel Worlds"},{"location":"related/literature.html#symmetry-aware-sparse-voxel-dags-ssvdags-for-compression-domain-tracing-of-high-resolution-geometric-scenes","text":"Authors: Alberto Jaspe Villanueva, Fabio Marton, Enrico Gobbetti, CRS4 Publication Date: 2017-05-12 Published In: Journal of Computer Graphics Techniques (JCGT), vol. 6, no. 2 Links: Computer Graphics Techniques , Full-Text PDF , Low-Resolution PDF , Video Demo","title":"Symmetry-aware Sparse Voxel DAGs (SSVDAGs) for compression-domain tracing of high-resolution geometric scenes"},{"location":"related/overview.html","text":"Overview over Related Work","title":"Overview over Related Work"},{"location":"related/overview.html#overview-over-related-work","text":"","title":"Overview over Related Work"},{"location":"rle/rle.html","text":"Run-Length Encoding Run-Length Encoding (RLE) is a form of lossless data compression which stores elements of said data using a single value and a count or \"run-length\". Viability for Voxel Compression RLE is viable in those cases, where there are long runs of identical or very similar data. Due to voxel arrays often containing huge amounts of empty space, they also contain long runs of 0x0 RGB values (or whatever other value represents empty voxels) which could be run-length-compressed. This mitigates their greatest downside compared to voxel lists , their empty-space-overhead. In-Band- vs Out-Of-Band- Signaling The main distinction in RLE methods can be made between In-Band Signaling And Out-Of-Band Signaling . In-Band Signaling This method uses the alphabet of the data which it attempts to compress. For instance, if the data consists of only alphabetic ASCII characters, then digits could be used to encode the counts. Or for ASCII characters which are stored in 8-bit integers, the uppermost, unused bit could be used to signal that the remaining seven bits are the count. In any case, this method is best when the addition of the count does not conflict with the existing data. Otherwise, an escape sequence is necessary. For instance, to encode any 8-bit integer sequence, the value 0xff could be used to \"escape\" the data and be followed up by the count and the actual byte to be encoded, including 0xff . \\text{aaabbbcfdeef} \\rightarrow \\text{3a3bcfd2ef} Out-Of-Band Signaling This method encodes all of the data in pairs of count and data instead of leaving single characters intact. Its main advantage is the simplicity of parsing and an identical effect for all types of data. While a particular escape sequence might be a poor choice for some specific data set, this method does not require an escape sequence and thus doesn't suffer from the problem. To avoid bloating the data in size, further measures must be taken such as having a sequence which can signal a sequence of different characters as well as a sequence of identical characters. For instance, negative counts could be used to signal multiple different characters. \\text{aaabbbcfdeef} \\rightarrow \\text{3a3b1c1f1d2e1f} Summary In-Band signaling should be used in cases where certain values in the data are unused, allowing for an escape sequence with no conflicts with other data. If there are not just a handful of values but an entire bit per byte which is unused (such as in ASCII ), then this method becomes especially viable. Otherwise, OOB signaling is preferable, as it gives much more flexibility to the implementing developer and doesn't produce any conflicts with the data to be compressed. Existing Implementations Binvox The Binvox file format provides simple compression for geometry-only voxel data. It uses out-of-band signaling After a text header, the binary voxel data can be specified as follows: struct binvox_data { marker[] } struct marker { u8 count u8 bit_value } Criticism Binvox run-length encodes only streaks of 0 -bits or 1 -bits. But to store their values, it uses an entire byte which wastes 7 bits. Almost half (7 out of 16) bits for each marker are thus wasted. Also the worst case is a recurring pattern of 010101... . For such a worst case, Binvox increases the required storage space by a factor of 16! Qubicle Binary The Qubicle Binary (QB) file format has an option for compressing models using RLE. It is still in use, although it has been superseded by the Qubicle Binary Tree (QBT) file format which uses zlib instead of custom RLE. Models are made of matrices , which are arrays, usually sized 128 3 or smaller 1 . When compressing matrices , each slice (xy-plane) is being run-length-encoded. The RLE implementation uses in-band signaling . The CODEFLAG = 2 escape sequence signals a following pair of count and data, whereas the NEXTSLICEFLAG = 6 signals the end of the current slice . Criticism This implementation is flawed, in that it fails to exploit an obvious non-conflicting escape sequence: A color with an alpha of zero is invisible, regardless of its other components. In the QB format, the escape sequences correspond to pitch black colors with an alpha of 2 or 6 respectively, which is almost invisible. Alpha channels can also be used to store visibility maps instead, where such values would be far more common. Such a problem could have been easily mitigated by using different values for the escape sequences or by not storing colors in RGBA or BGRA format. An example of a better constant would be 1 31 , which is interpreted as an invisible color but with a red value of 128. Our Experiments There are countless ways to implement RLE. We implemented a few experimental methods ourselves to see how much one could improve upon the original designs. Compact Binvox struct marker { bit value i7 count } Instead of wasting 7 bits, we simply integrate the bit-value into the uppermost bit of the count. If we read the marker as a signed two's complement integer, we can easily obtain the bit using marker < 0 and the count using marker & 0x7f . Complete Binvox struct marker { u8 count u8 value } Instead of wasting 7 bits, we allow for an entire byte to be repeated count times. 0x00 and 0xff Escape Sequences This method uses in-band signaling. We encode our bits as usual, but when we encounter an escape sequence, the following byte is used as our count. We have two escape sequences: 0x00 indicates that the following byte encodes the number of zero-bits 0xff indicates that the following byte encodes the number of one-bits The obvious advantage of this method is that our escape sequences don't conflict with high-entropy data. We preserve any bytes which have both 0 and 1 in them and only affect fully empty/filled bytes, which occur in a low-entropy context anyways. Zlib TODO complete this For most of its lifetime, Qubicle did not support matrices greater than 128 in each dimension. However, the file format technically allows for greater sizes due to a 32-bit integer being used for each dimension. \u21a9","title":"Run-Length Encoding"},{"location":"rle/rle.html#run-length-encoding","text":"Run-Length Encoding (RLE) is a form of lossless data compression which stores elements of said data using a single value and a count or \"run-length\".","title":"Run-Length Encoding"},{"location":"rle/rle.html#viability-for-voxel-compression","text":"RLE is viable in those cases, where there are long runs of identical or very similar data. Due to voxel arrays often containing huge amounts of empty space, they also contain long runs of 0x0 RGB values (or whatever other value represents empty voxels) which could be run-length-compressed. This mitigates their greatest downside compared to voxel lists , their empty-space-overhead.","title":"Viability for Voxel Compression"},{"location":"rle/rle.html#in-band-vs-out-of-band-signaling","text":"The main distinction in RLE methods can be made between In-Band Signaling And Out-Of-Band Signaling .","title":"In-Band- vs Out-Of-Band- Signaling"},{"location":"rle/rle.html#in-band-signaling","text":"This method uses the alphabet of the data which it attempts to compress. For instance, if the data consists of only alphabetic ASCII characters, then digits could be used to encode the counts. Or for ASCII characters which are stored in 8-bit integers, the uppermost, unused bit could be used to signal that the remaining seven bits are the count. In any case, this method is best when the addition of the count does not conflict with the existing data. Otherwise, an escape sequence is necessary. For instance, to encode any 8-bit integer sequence, the value 0xff could be used to \"escape\" the data and be followed up by the count and the actual byte to be encoded, including 0xff . \\text{aaabbbcfdeef} \\rightarrow \\text{3a3bcfd2ef}","title":"In-Band Signaling"},{"location":"rle/rle.html#out-of-band-signaling","text":"This method encodes all of the data in pairs of count and data instead of leaving single characters intact. Its main advantage is the simplicity of parsing and an identical effect for all types of data. While a particular escape sequence might be a poor choice for some specific data set, this method does not require an escape sequence and thus doesn't suffer from the problem. To avoid bloating the data in size, further measures must be taken such as having a sequence which can signal a sequence of different characters as well as a sequence of identical characters. For instance, negative counts could be used to signal multiple different characters. \\text{aaabbbcfdeef} \\rightarrow \\text{3a3b1c1f1d2e1f}","title":"Out-Of-Band Signaling"},{"location":"rle/rle.html#summary","text":"In-Band signaling should be used in cases where certain values in the data are unused, allowing for an escape sequence with no conflicts with other data. If there are not just a handful of values but an entire bit per byte which is unused (such as in ASCII ), then this method becomes especially viable. Otherwise, OOB signaling is preferable, as it gives much more flexibility to the implementing developer and doesn't produce any conflicts with the data to be compressed.","title":"Summary"},{"location":"rle/rle.html#existing-implementations","text":"","title":"Existing Implementations"},{"location":"rle/rle.html#binvox","text":"The Binvox file format provides simple compression for geometry-only voxel data. It uses out-of-band signaling After a text header, the binary voxel data can be specified as follows: struct binvox_data { marker[] } struct marker { u8 count u8 bit_value }","title":"Binvox"},{"location":"rle/rle.html#criticism","text":"Binvox run-length encodes only streaks of 0 -bits or 1 -bits. But to store their values, it uses an entire byte which wastes 7 bits. Almost half (7 out of 16) bits for each marker are thus wasted. Also the worst case is a recurring pattern of 010101... . For such a worst case, Binvox increases the required storage space by a factor of 16!","title":"Criticism"},{"location":"rle/rle.html#qubicle-binary","text":"The Qubicle Binary (QB) file format has an option for compressing models using RLE. It is still in use, although it has been superseded by the Qubicle Binary Tree (QBT) file format which uses zlib instead of custom RLE. Models are made of matrices , which are arrays, usually sized 128 3 or smaller 1 . When compressing matrices , each slice (xy-plane) is being run-length-encoded. The RLE implementation uses in-band signaling . The CODEFLAG = 2 escape sequence signals a following pair of count and data, whereas the NEXTSLICEFLAG = 6 signals the end of the current slice .","title":"Qubicle Binary"},{"location":"rle/rle.html#criticism_1","text":"This implementation is flawed, in that it fails to exploit an obvious non-conflicting escape sequence: A color with an alpha of zero is invisible, regardless of its other components. In the QB format, the escape sequences correspond to pitch black colors with an alpha of 2 or 6 respectively, which is almost invisible. Alpha channels can also be used to store visibility maps instead, where such values would be far more common. Such a problem could have been easily mitigated by using different values for the escape sequences or by not storing colors in RGBA or BGRA format. An example of a better constant would be 1 31 , which is interpreted as an invisible color but with a red value of 128.","title":"Criticism"},{"location":"rle/rle.html#our-experiments","text":"There are countless ways to implement RLE. We implemented a few experimental methods ourselves to see how much one could improve upon the original designs.","title":"Our Experiments"},{"location":"rle/rle.html#compact-binvox","text":"struct marker { bit value i7 count } Instead of wasting 7 bits, we simply integrate the bit-value into the uppermost bit of the count. If we read the marker as a signed two's complement integer, we can easily obtain the bit using marker < 0 and the count using marker & 0x7f .","title":"Compact Binvox"},{"location":"rle/rle.html#complete-binvox","text":"struct marker { u8 count u8 value } Instead of wasting 7 bits, we allow for an entire byte to be repeated count times.","title":"Complete Binvox"},{"location":"rle/rle.html#0x00-and-0xff-escape-sequences","text":"This method uses in-band signaling. We encode our bits as usual, but when we encounter an escape sequence, the following byte is used as our count. We have two escape sequences: 0x00 indicates that the following byte encodes the number of zero-bits 0xff indicates that the following byte encodes the number of one-bits The obvious advantage of this method is that our escape sequences don't conflict with high-entropy data. We preserve any bytes which have both 0 and 1 in them and only affect fully empty/filled bytes, which occur in a low-entropy context anyways.","title":"0x00 and 0xff Escape Sequences"},{"location":"rle/rle.html#zlib","text":"TODO complete this For most of its lifetime, Qubicle did not support matrices greater than 128 in each dimension. However, the file format technically allows for greater sizes due to a 32-bit integer being used for each dimension. \u21a9","title":"Zlib"},{"location":"svo/construction.html","text":"SVO Construction When constructing an SVO from a voxel list , the complexity of this process depends on the data fed to the constructing algorithm. Within the scope of this project, the uncompressed format is a list of voxels , but there are further subtle differences. Summary of Construction The following process must be repeated for all voxels v := (p := (x, y, z), c) \\in (\\mathbb{Z}^3, \\mathbb{N}) in the list. Test signed input position p against current SVO dimensions d . If the position is outside of our boundaries, enlarge the SVO to fit p . Subtract p_{min} of the SVO from p to obtain p_{\\text{normalized}} . Convert p_{\\text{normalized}} to the octree node index n . Use n to traverse the SVO and insert the voxel at the correct location. Optional: If only one octant is used, cut branches belonging to other octants recursively. Note To handle signed values, the octree must be extended into both positive and negative octants. Coordinate System There are two coordinate systems with which we must concern ourselves with: world coordinate system (signed) SVO coordinate system (unsigned) The conversion between these two coordinate systems occurs in step 3. The problem which we face is that our SVO is meant to split the world coordinate system into eight equal octants, recursively. The first split occurs at the origin however, the origin (0, 0, 0) must be located in one of these octants. To solve this, we put the origin into the first octant; then all positions with no negative coordinates will lie in just one octant. This allows us to perform the optimisation from step 6 for only unsigned coordinates. It also helps us optimize our boundary test . As a result, for example, an SVO that can contain 4x4x4 voxels will have space from (-2, -2, -2) to (1, 1, 1) . Special Case Where Voxel Coordinates Are Positive If the voxels are sorted with the first voxel being the most negative corner of the model, we have a global p_{min} (see step 3.). All voxels can then be translated by -p_{min} , yielding only positions that belong in the first octant. If x, y, z are already guaranteed to be positive, this condition is obviously also met. In such cases. step 1. and 2. are simplified and step 6. is eliminated. Efficient Boundary Test To check whether a point lies within our SVO, max(abs(x), abs(y), abs(z)) > d would suffice. However, this test is overly pessimistic because we have more negative space instead of positive space. Also, assuming no compiler optimisations, we have to perform six conditional operations: each call to abs() requires one conditional operation a three-argument max() would require two more one more conditional operation is necessary for the > d comparison Assuming unsorted inputs, these six conditional jumps may wreak havoc on the performance of the branch predictor . To remove the pessimism from our test, we define a new function to be used in stead of abs : abs_{\\text{SVO}}(n) = \\begin{cases} -n - 1,& \\text{if } n < 0\\\\ n, & \\text{otherwise} \\end{cases} Implementation uint32_t abs_svo(int32_t n) { return n < 0 ? (-n -1) : n; } bool comp_against_svo_bounds(int32_t x, int32_t y, int32_t z, uint32_t d) { return (abs_svo(x) | abs_svo(y) | abs_svo(z)) >= d; } Such an implementation eliminates five out of six conditional operations on modern compilers, leaving only the final >= comparison. See this Compiler Explorer page for an example. Compiler Optimization of abs_svo Using abs_{\\text{SVO}} actually works in ours and the compiler's favor. This is due to the fact that negating a number in two's complement requires a bitwise negation and an increment. Due to our decrement of the negated number, we eliminate this need. abs_svo(int): mov eax, edi # copy function parameter into result register sar eax, 31 # fill the register with 1s if the number is negative, else with 0s xor eax, edi # xor result register with parameter, performing a conditional bitwise NOT retn # return from the function Manual Optimization of Comparison with d This only works because d is an SVO dimension and thus always guaranteed to be a power of two. The most significant bit of lower numbers is lower than the single bit of a greater power of two. To name an example, 128 will have the 128-bit set, whereas all lower numbers will consist only of less significant bits. Hence, they can be safely combined with an | operation before making the comparison. Summary The overly pessimistic initial comparison could be fixed with -surprisingly- no performance impact. Out of the six necessary conditional operations, we could optimize five away. During a microbenchmark of the original max(abs(x), abs(y), abs(z)) > d comparison vs. our optimized method, no performance difference could be found . However, keep in mind that abs() functions are often compiled to use a conditional move instruction which can be expensive on older architectures. So depending on the architecture, such a benefit could be seen. Octree Growth If we do find that a point which is to be inserted does not fit within the current octree, we must enlarge it. Single-Octant Growth Figure 1: Simple (Single-Octant) Octree Growth If only one octant is used, e.g. all positions are unsigned, then we can enlarge the octree into just one direction. The current root node goes into the lowest corner (with index 0) of the new, higher-level root node. Unilateral Octree Growth Figure 2: Unilateral Octree Growth If we use signed positions, we must grow our octree unilaterally. This means that each node receives a new parent. The four new parents are then moved into the root node at the location of their children. Here is an implementation in pseudo-C++: for (size_t i = 0; i < 8; ++i) { if (root.has(i)) { auto parent = make_new_branch(); parent[~i & 0b111] = root.extract(i); root[i] = parent; } } Within each new parent, the current nodes end up positioned in the opposite corner of where they were before. In one index from 0 to 7, each bit represents a three-dimensional coordinate. So index 4 = 0b010 represents (0, 1, 0) . By flipping all bits of the index we can quickly calculate the position inside the new parent. Note that for squashed octrees , this beautifully simple case no longer applies. We still create exactly eight new parents, but each parent will receive up to 4 of the 16 first-level branches. This and other problems make unilateral growth for squashed octrees a lengthy and complicated process. Position Normalization Once the octree has grown to a size at which it can contain our new position p = (x, y, z) , we must normalize our position. In this case normalization means that we simply subtract (x_{\\text{min}}, y_{\\text{min}}, z_{\\text{min}}) from p to obtain p_{\\text{normalized}} . This is necessary because internally, octrees don't have any concept of \"negative\" or \"positive\" positions, just indices within nodes which are all unsigned. The minimum coordinate for all dimensions is -2^d , where d is the unilateral depth of the octree. Once we subtract this minimum from our position, the position will be unsigned and ready for calculation of the octree node index. Octree Node Index The conventional method of addressing positions within a 3D-container would be by using a vector v = (x, y, z) \\in \\mathbb{Z}^3 . Finding a voxel within an octree using v would cumbersome, since it requires recursively testing whether each coordinate is in the lower or the upper half of current subtree. As long as the tree's dimensions are a power of 2, this is actually simplified since this test can be reduced to checking whether a bit is set. For example, 128 is in the upper half of the 256-tree, because the most 128-bit is set, which is not the case for 127. Idea Binary numbers can generally be interpreted as locations in binary trees: _**_ / \\ 0* 1* / \\ / \\ 00 01 10 11 As we can see, the lower bit indicates whether the position is left or right in the lower subtree and the higher bit indicates whether the position is left or right in the upper subtree. The same pattern occurs for octal digits and octrees. (x, y, z) can thus be seen as three positions in separate binary trees which we want to combine into an octree. To convert (x, y, z) to a position in an octree, the bits of (x, y, z) can simply be interleaved. The result will be a single number of octal digits, each of which represents the position within one octree node. Examples This is how coordinates can be mapped to octree indices: \\begin{align} & (6, 8, 9) = (\\color{red}{0101_2}, \\color{green}{1000_2}, \\color{blue}{1001_2}) \\\\ \\xrightarrow{\\text{interleave}} \\quad& (\\color{red}{0},\\color{green}{1},\\color{blue}{1}), (\\color{red}{1},\\color{green}{1},\\color{blue}{1}), (\\color{red}{0},\\color{green}{0},\\color{blue}{0}), (\\color{red}{1},\\color{green}{0},\\color{blue}{1}) \\\\ \\xrightarrow{\\text{concatenate}} \\quad& \\color{red}{0}\\color{green}{1}\\color{blue}{1}, \\color{red}{1}\\color{green}{1}\\color{blue}{1}, \\color{red}{0}\\color{green}{0}\\color{blue}{0}, \\color{red}{1}\\color{green}{0}\\color{blue}{1}_2 = 3705_8 = 1989 \\end{align} Note that in the above example, x is used as the most significant bit of each octal digit, followed by y and z . This is how octree node indices can be mapped to coordinates: \\begin{align} &25 = 31_8 = \\color{red}{0}\\color{green}{1}\\color{blue}{1},\\color{red}{0}\\color{green}{0}\\color{blue}{1}_2 \\\\ \\xrightarrow{\\text{to vectors}} \\quad& (\\color{red}{0}, \\color{green}{1}, \\color{blue}{1}), (\\color{red}{0}, \\color{green}{0}, \\color{blue}{1}) \\\\ \\xrightarrow{\\text{deinterleave}} \\quad& (\\color{red}{00_2}, \\color{green}{10_2}, \\color{blue}{11_2}) = (0, 2, 3) \\end{align} Implementation The following C++17 implementation shows how three coordinates (x, y, z) can be efficiently interleaved using binary Magic Numbers. The implementation expands upon one of the Bit Twiddling Hacks by Sean Eron Anderson . // interleaves a given number with two zero-bits after each input bit // the first insertion occurs between the least significant bit and the next higher bit uint64_t ileave_two0(uint32_t input) { constexpr size_t numInputs = 3; constexpr uint64_t masks[] = { 0x9249'2492'4924'9249, 0x30C3'0C30'C30C'30C3, 0xF00F'00F0'0F00'F00F, 0x00FF'0000'FF00'00FF, 0xFFFF'0000'0000'FFFF }; uint64_t n = input; for (int i = 4; i != 1; --i) { const auto shift = (numInputs - 1) * (1 << i); n |= n << shift; n &= masks[i]; } return n; } uint64_t ileave3(uint32_t x, uint32_t y, uint32_t z) { return (ileave_two0(x) << 2) | (ileave_two0(y) << 1) | ileave_two0(z); } Note An implementation for a variable amount of inputs is equally possible, but would significantly increase the code complexity. Most notably, the masks lookup table would need to be generated computationally. C++ was chosen due to its constexpr compile-time context. Traversing the Octree Once the octree node index is computed, traversing the octree becomes simple: For a given index n , we start at the most significant octal digit o and the root node. We follow the branch number o or construct it if it does not exist yet. Insert the voxel's color once a leaf node is found. Repeat until the least significant octal digit is processed. Note Once a nonexistent branch is found in step 2, all deeper branches will also be missing. In such a case, we can enter a different code path that handles this case. Node Implementation An SVO will need to store our voxel colors at some level. We can reduce memory consumption and cache misses by using a small voxel array at the second-to-final depth: // a regular node struct svo_node { svo_node *children[8]; }; // a node that stores colors instead struct svo_array_node { uint32_t colors[8]; } // a node that stores just one color, something that we want to avoid struct svo_leaf_node { uint32_t color; } This code will need to be adjusted so that the nodes are either polymorphic or type unions are used. Octree Optimization Figure 3: Octree Optimization, where b is a sub-branch (visualized using a Quadtree) Once an octree has been fully constructed, unused octants can be optimized or \"cut away\" recursively. This can be especially helpful for octrees where all voxels reside very far from the origin. For instance, we could be encoding voxels with coordinates ranging from 100,000 to 100,050. Many almost completely empty octree layers would need to be traversed to get to these locations. Trimming away such almost completely layers accelerates encoding and decoding. Algorithm s \\gets (0,0,0) If the root node r has exactly one branch b : s \\gets s + 2^{d-2} r \\gets b repeat 2. 2^d is the negated minimum point of our current octree, as described in Position Normalization . After this process has been completed, we simply store s alongside the octree. When decoding, s is added back onto all found positions.","title":"SVO Construction"},{"location":"svo/construction.html#svo-construction","text":"When constructing an SVO from a voxel list , the complexity of this process depends on the data fed to the constructing algorithm. Within the scope of this project, the uncompressed format is a list of voxels , but there are further subtle differences.","title":"SVO Construction"},{"location":"svo/construction.html#summary-of-construction","text":"The following process must be repeated for all voxels v := (p := (x, y, z), c) \\in (\\mathbb{Z}^3, \\mathbb{N}) in the list. Test signed input position p against current SVO dimensions d . If the position is outside of our boundaries, enlarge the SVO to fit p . Subtract p_{min} of the SVO from p to obtain p_{\\text{normalized}} . Convert p_{\\text{normalized}} to the octree node index n . Use n to traverse the SVO and insert the voxel at the correct location. Optional: If only one octant is used, cut branches belonging to other octants recursively. Note To handle signed values, the octree must be extended into both positive and negative octants.","title":"Summary of Construction"},{"location":"svo/construction.html#coordinate-system","text":"There are two coordinate systems with which we must concern ourselves with: world coordinate system (signed) SVO coordinate system (unsigned) The conversion between these two coordinate systems occurs in step 3. The problem which we face is that our SVO is meant to split the world coordinate system into eight equal octants, recursively. The first split occurs at the origin however, the origin (0, 0, 0) must be located in one of these octants. To solve this, we put the origin into the first octant; then all positions with no negative coordinates will lie in just one octant. This allows us to perform the optimisation from step 6 for only unsigned coordinates. It also helps us optimize our boundary test . As a result, for example, an SVO that can contain 4x4x4 voxels will have space from (-2, -2, -2) to (1, 1, 1) .","title":"Coordinate System"},{"location":"svo/construction.html#special-case-where-voxel-coordinates-are-positive","text":"If the voxels are sorted with the first voxel being the most negative corner of the model, we have a global p_{min} (see step 3.). All voxels can then be translated by -p_{min} , yielding only positions that belong in the first octant. If x, y, z are already guaranteed to be positive, this condition is obviously also met. In such cases. step 1. and 2. are simplified and step 6. is eliminated.","title":"Special Case Where Voxel Coordinates Are Positive"},{"location":"svo/construction.html#efficient-boundary-test","text":"To check whether a point lies within our SVO, max(abs(x), abs(y), abs(z)) > d would suffice. However, this test is overly pessimistic because we have more negative space instead of positive space. Also, assuming no compiler optimisations, we have to perform six conditional operations: each call to abs() requires one conditional operation a three-argument max() would require two more one more conditional operation is necessary for the > d comparison Assuming unsorted inputs, these six conditional jumps may wreak havoc on the performance of the branch predictor . To remove the pessimism from our test, we define a new function to be used in stead of abs : abs_{\\text{SVO}}(n) = \\begin{cases} -n - 1,& \\text{if } n < 0\\\\ n, & \\text{otherwise} \\end{cases}","title":"Efficient Boundary Test"},{"location":"svo/construction.html#implementation","text":"uint32_t abs_svo(int32_t n) { return n < 0 ? (-n -1) : n; } bool comp_against_svo_bounds(int32_t x, int32_t y, int32_t z, uint32_t d) { return (abs_svo(x) | abs_svo(y) | abs_svo(z)) >= d; } Such an implementation eliminates five out of six conditional operations on modern compilers, leaving only the final >= comparison. See this Compiler Explorer page for an example.","title":"Implementation"},{"location":"svo/construction.html#compiler-optimization-of-abs_svo","text":"Using abs_{\\text{SVO}} actually works in ours and the compiler's favor. This is due to the fact that negating a number in two's complement requires a bitwise negation and an increment. Due to our decrement of the negated number, we eliminate this need. abs_svo(int): mov eax, edi # copy function parameter into result register sar eax, 31 # fill the register with 1s if the number is negative, else with 0s xor eax, edi # xor result register with parameter, performing a conditional bitwise NOT retn # return from the function","title":"Compiler Optimization of abs_svo"},{"location":"svo/construction.html#manual-optimization-of-comparison-with-d","text":"This only works because d is an SVO dimension and thus always guaranteed to be a power of two. The most significant bit of lower numbers is lower than the single bit of a greater power of two. To name an example, 128 will have the 128-bit set, whereas all lower numbers will consist only of less significant bits. Hence, they can be safely combined with an | operation before making the comparison.","title":"Manual Optimization of Comparison with d"},{"location":"svo/construction.html#summary","text":"The overly pessimistic initial comparison could be fixed with -surprisingly- no performance impact. Out of the six necessary conditional operations, we could optimize five away. During a microbenchmark of the original max(abs(x), abs(y), abs(z)) > d comparison vs. our optimized method, no performance difference could be found . However, keep in mind that abs() functions are often compiled to use a conditional move instruction which can be expensive on older architectures. So depending on the architecture, such a benefit could be seen.","title":"Summary"},{"location":"svo/construction.html#octree-growth","text":"If we do find that a point which is to be inserted does not fit within the current octree, we must enlarge it.","title":"Octree Growth"},{"location":"svo/construction.html#single-octant-growth","text":"Figure 1: Simple (Single-Octant) Octree Growth If only one octant is used, e.g. all positions are unsigned, then we can enlarge the octree into just one direction. The current root node goes into the lowest corner (with index 0) of the new, higher-level root node.","title":"Single-Octant Growth"},{"location":"svo/construction.html#unilateral-octree-growth","text":"Figure 2: Unilateral Octree Growth If we use signed positions, we must grow our octree unilaterally. This means that each node receives a new parent. The four new parents are then moved into the root node at the location of their children. Here is an implementation in pseudo-C++: for (size_t i = 0; i < 8; ++i) { if (root.has(i)) { auto parent = make_new_branch(); parent[~i & 0b111] = root.extract(i); root[i] = parent; } } Within each new parent, the current nodes end up positioned in the opposite corner of where they were before. In one index from 0 to 7, each bit represents a three-dimensional coordinate. So index 4 = 0b010 represents (0, 1, 0) . By flipping all bits of the index we can quickly calculate the position inside the new parent. Note that for squashed octrees , this beautifully simple case no longer applies. We still create exactly eight new parents, but each parent will receive up to 4 of the 16 first-level branches. This and other problems make unilateral growth for squashed octrees a lengthy and complicated process.","title":"Unilateral Octree Growth"},{"location":"svo/construction.html#position-normalization","text":"Once the octree has grown to a size at which it can contain our new position p = (x, y, z) , we must normalize our position. In this case normalization means that we simply subtract (x_{\\text{min}}, y_{\\text{min}}, z_{\\text{min}}) from p to obtain p_{\\text{normalized}} . This is necessary because internally, octrees don't have any concept of \"negative\" or \"positive\" positions, just indices within nodes which are all unsigned. The minimum coordinate for all dimensions is -2^d , where d is the unilateral depth of the octree. Once we subtract this minimum from our position, the position will be unsigned and ready for calculation of the octree node index.","title":"Position Normalization"},{"location":"svo/construction.html#octree-node-index","text":"The conventional method of addressing positions within a 3D-container would be by using a vector v = (x, y, z) \\in \\mathbb{Z}^3 . Finding a voxel within an octree using v would cumbersome, since it requires recursively testing whether each coordinate is in the lower or the upper half of current subtree. As long as the tree's dimensions are a power of 2, this is actually simplified since this test can be reduced to checking whether a bit is set. For example, 128 is in the upper half of the 256-tree, because the most 128-bit is set, which is not the case for 127.","title":"Octree Node Index"},{"location":"svo/construction.html#idea","text":"Binary numbers can generally be interpreted as locations in binary trees: _**_ / \\ 0* 1* / \\ / \\ 00 01 10 11 As we can see, the lower bit indicates whether the position is left or right in the lower subtree and the higher bit indicates whether the position is left or right in the upper subtree. The same pattern occurs for octal digits and octrees. (x, y, z) can thus be seen as three positions in separate binary trees which we want to combine into an octree. To convert (x, y, z) to a position in an octree, the bits of (x, y, z) can simply be interleaved. The result will be a single number of octal digits, each of which represents the position within one octree node.","title":"Idea"},{"location":"svo/construction.html#examples","text":"This is how coordinates can be mapped to octree indices: \\begin{align} & (6, 8, 9) = (\\color{red}{0101_2}, \\color{green}{1000_2}, \\color{blue}{1001_2}) \\\\ \\xrightarrow{\\text{interleave}} \\quad& (\\color{red}{0},\\color{green}{1},\\color{blue}{1}), (\\color{red}{1},\\color{green}{1},\\color{blue}{1}), (\\color{red}{0},\\color{green}{0},\\color{blue}{0}), (\\color{red}{1},\\color{green}{0},\\color{blue}{1}) \\\\ \\xrightarrow{\\text{concatenate}} \\quad& \\color{red}{0}\\color{green}{1}\\color{blue}{1}, \\color{red}{1}\\color{green}{1}\\color{blue}{1}, \\color{red}{0}\\color{green}{0}\\color{blue}{0}, \\color{red}{1}\\color{green}{0}\\color{blue}{1}_2 = 3705_8 = 1989 \\end{align} Note that in the above example, x is used as the most significant bit of each octal digit, followed by y and z . This is how octree node indices can be mapped to coordinates: \\begin{align} &25 = 31_8 = \\color{red}{0}\\color{green}{1}\\color{blue}{1},\\color{red}{0}\\color{green}{0}\\color{blue}{1}_2 \\\\ \\xrightarrow{\\text{to vectors}} \\quad& (\\color{red}{0}, \\color{green}{1}, \\color{blue}{1}), (\\color{red}{0}, \\color{green}{0}, \\color{blue}{1}) \\\\ \\xrightarrow{\\text{deinterleave}} \\quad& (\\color{red}{00_2}, \\color{green}{10_2}, \\color{blue}{11_2}) = (0, 2, 3) \\end{align}","title":"Examples"},{"location":"svo/construction.html#implementation_1","text":"The following C++17 implementation shows how three coordinates (x, y, z) can be efficiently interleaved using binary Magic Numbers. The implementation expands upon one of the Bit Twiddling Hacks by Sean Eron Anderson . // interleaves a given number with two zero-bits after each input bit // the first insertion occurs between the least significant bit and the next higher bit uint64_t ileave_two0(uint32_t input) { constexpr size_t numInputs = 3; constexpr uint64_t masks[] = { 0x9249'2492'4924'9249, 0x30C3'0C30'C30C'30C3, 0xF00F'00F0'0F00'F00F, 0x00FF'0000'FF00'00FF, 0xFFFF'0000'0000'FFFF }; uint64_t n = input; for (int i = 4; i != 1; --i) { const auto shift = (numInputs - 1) * (1 << i); n |= n << shift; n &= masks[i]; } return n; } uint64_t ileave3(uint32_t x, uint32_t y, uint32_t z) { return (ileave_two0(x) << 2) | (ileave_two0(y) << 1) | ileave_two0(z); } Note An implementation for a variable amount of inputs is equally possible, but would significantly increase the code complexity. Most notably, the masks lookup table would need to be generated computationally. C++ was chosen due to its constexpr compile-time context.","title":"Implementation"},{"location":"svo/construction.html#traversing-the-octree","text":"Once the octree node index is computed, traversing the octree becomes simple: For a given index n , we start at the most significant octal digit o and the root node. We follow the branch number o or construct it if it does not exist yet. Insert the voxel's color once a leaf node is found. Repeat until the least significant octal digit is processed. Note Once a nonexistent branch is found in step 2, all deeper branches will also be missing. In such a case, we can enter a different code path that handles this case.","title":"Traversing the Octree"},{"location":"svo/construction.html#node-implementation","text":"An SVO will need to store our voxel colors at some level. We can reduce memory consumption and cache misses by using a small voxel array at the second-to-final depth: // a regular node struct svo_node { svo_node *children[8]; }; // a node that stores colors instead struct svo_array_node { uint32_t colors[8]; } // a node that stores just one color, something that we want to avoid struct svo_leaf_node { uint32_t color; } This code will need to be adjusted so that the nodes are either polymorphic or type unions are used.","title":"Node Implementation"},{"location":"svo/construction.html#octree-optimization","text":"Figure 3: Octree Optimization, where b is a sub-branch (visualized using a Quadtree) Once an octree has been fully constructed, unused octants can be optimized or \"cut away\" recursively. This can be especially helpful for octrees where all voxels reside very far from the origin. For instance, we could be encoding voxels with coordinates ranging from 100,000 to 100,050. Many almost completely empty octree layers would need to be traversed to get to these locations. Trimming away such almost completely layers accelerates encoding and decoding.","title":"Octree Optimization"},{"location":"svo/construction.html#algorithm","text":"s \\gets (0,0,0) If the root node r has exactly one branch b : s \\gets s + 2^{d-2} r \\gets b repeat 2. 2^d is the negated minimum point of our current octree, as described in Position Normalization . After this process has been completed, we simply store s alongside the octree. When decoding, s is added back onto all found positions.","title":"Algorithm"},{"location":"svo/squashing.html","text":"Squashed SVOs","title":"Squashed SVOs"},{"location":"svo/squashing.html#squashed-svos","text":"","title":"Squashed SVOs"},{"location":"svo/svo.html","text":"Sparse Voxel Octree An Octree - Source: Wikipedia , WhiteTimberwolf A sparse voxel octree is a data structure which stores voxels in a tree with a branching factor of 8, with its branches being potentially absent. Missing branches typically represent empty volumes where no voxels exist. The greater empty volumes are, the closer to the root can their corresponding subtrees be pruned. This results in a very efficient representation of models with a significant portion of empty space. Unlike with a voxel list, all positioning is implicit and results from the tree structure, meaning that no space has to be used for the storage of coordinates during serialization. Thus, octrees combine the two greatest advantages of voxel lists and voxel arrays: like lists, they waste little space on encoding empty voxels like for arrays, voxel coordinates are implicit and little space is wasted Extreme Cases And Limits To illustrate the following extreme cases, voxel arrays and voxel lists are also compared. The space complexity of three extreme cases is compared between the three data structures, where v is the amount of voxels. Voxel Array Voxel List Sparse Voxel Octree Empty O(1) 1 O(1) O(1) Tightly Filled O(v) O(4v) O(\\frac{8}{7} v) Stretched O(\\infty) O(1) O(\\infty) Empty Octree Entirely empty models can be encoded using just the root note, which then encodes that no subtrees exist. Tightly Filled Octree Entirely filled models will have some overhead compared to an array of voxels. For every eight nodes, there is one parent node. We can calculate the maximum possible overhead by summing up this \\frac{1}{8} overhead infinitely: \\sum_{n=1}^\\infty{\\frac{1}{8}^n} = \\frac{1}{7} So at worst, our data will increase by \\frac{1}{7} , which is much better than a 100% increase such as for binary trees. Stretched Octree The stretched case is a case where a finite amount of voxels are placed infinitely far apart. For arrays, this produces infinite space requirements because all space between these points must be filled. For octrees, more layers are necessary to encode positions further from the origin. In neither case there is an upper bound to this. In practice, octrees perform significantly better at encoding sparse data than arrays. Construction How an octree can be constructed from a list voxels is thorougly explained in SVO Construction . Serialization Figure 0: A Sparse Voxel Octree, encoded in memory To be used in a serial data format, octrees must first be serialized. Nodes will no longer be laid out freely in memory but instead be arranged one after another. To fully encode an SVO, two steps must be performed: Linearize nodes by traversing the SVO's nodes in a deterministic, reversible order. Serialize each node to binary data. Traversal Order There are two well-known strategies for traversing trees completely: Depth-First Search (DFS) Breadth-First Search (BFS) Depth-First Figure 1: Tree, traversed depth-first DFS can be performed using only a stack to keep track of the node number at each level. On the deepest level, the next node is chosen until the end is reached and the next parent node is chosen. This low memory cost (which is in fact O(\\log{n}) where n is the number of nodes) is highly advantageous when encoding enormous models. Breadth-First Figure 2: Tree, traversed breadth-first BFS comes with a higher cost since a typical algorithm appends all branches to a queue for every traversed node. This means that in the worst case, which is at the beginning of serialization eight nodes are appended on every level before any node is popped from the queue, resulting in a higher memory cost. Why To Serialize Octrees Depth-First Figure 3: A serialized octree, depth-first The scheme more practical for encoding octrees is depth-first. This is due to the fact that only a stack is necessary to keep track of the current position. The size or depth of the octree would need to double in all dimensions to necessitate a stack greater by one element. Overall, this is a very low memory profile. For breadth first, we would always load information about the entire next deeper layer into our queue, then move on. To be fair, this does allow us to discard the previous layer entirely once we move deeper, but the memory cost is still unnecessarily high. Node Encoding In the above graphs, the 1-bit encoding was demonstrated due to its simplicity. However, there is a variety of different encodings to choose from. Single-Bit Format 0 stands for air-subtree 1 stands for partially or entirely filled voxel-subtree 8 Bits per octree-node, thus this format is byte-aligned. 2-Bit Format 00 stands for air-subtree 01 stands for solid subtree 10 stands for partially filled subtree 11 variable purpose 1.5-Bit Format 00 stands for air-subtree 01 stands for solid subtree 1 stands for partially filled subtree Variable amount of bits per octree-node, neither bit- nor byte-aligned. On the last level (node = voxel), the single-bit format is used because there are no subtrees. 11 for Raw/Array Subtrees Useful to encode subtrees completely filled with high-entropy content. On the second-to-last level, 11 for raw-subtrees there is no difference between 10 and 11 , so reverting to the 1.5-bit format is viable. On the last level, the single-bit format should be used. As long as the 1.5-bit format is not used, this encoding is completely byte-aligned: * alignment to 16 -bit boundaries on most levels * alignment to 8 -bit boundaries on last level 11 for Pointers to Subtrees on the Same Level Useful for encoding multiple similar subtrees. Similarities between structures could be effectively exploited. Verifying whether subtrees are equal down to the base level has very high complexity: O(n^2 * 8^n) . The comparison depth could be reduced down to a limited number of levels or the level number could be encoded next to the pointer: {u32 indexOfOtherTree, u8 depth} . Instead of the pointer, a tree could instead encode all the places where it is additionally used. This would make decoding easier, since remembering trees on the same level is not necessary. Degenerate Cases If you paid close attention to Figure 1 and Figure 3 , you will have noticed that they contain a 00000000 node. Such nodes can in principle exist, but are a waste of space. After all, they could be trimmed away one layer above by simply encoding a 0 -bit. This nonsensical nature is why they are considered to be a degenerate case . Such cases can however be useful. They offer a natural escape sequence from the regular encoding of an SVO. They could offer special functionality as seen in 3.2.3 to the single-bit format, which does not have any unused values. Squashed Octrees Figure 5: A squashed Octree (compare to Figure 0) A squashed octree is an octree where two or more layers of the tree have been combined into a single layer. By squashing an octree once, we receive a tetrahexacontree. This term comes from \"tetrahexaconta\" (Greek for 64) and \"tree\". It builds on the idea of octrees but expands the branching factor from 8 to 8 2 , or 64. In almost all regards, a squashed octree is implemented identically to a regular octree. However, we divide space into a 4x4x4 cube instead of a 2x2x2 cube with each layer. Motivation When serializing or deserializing an octree, we must do so node by node. This involves generating a bitmask (see above sections on node encoding). For a tetrahexacontree and under use of the 1-bit format, we fill exactly one CPU register on a 64-bit architecture with our nodes. With a regular octree, we would waste all but eight bits. 64-bit architectures established themselves as the de-facto standard for desktop operating systems. Anecdotally, \"macOS Mojave would be the last version of macOS to run 32-bit apps\" - Apple . Thus, optimization of algorithms in the present day can be performed for 64-bit architectures without worrying about 32-bit users. A use of this concept can be seen in the VOLA file format. VOLA uses a 1-bit format for its nodes while squashing two layers into one. So VOLA uses a tetrahexacontree. Unfortunately the paper fails to mention how performance and compression efficiency can be gained or lost this way. Therefore, we run our own tests in the following subsections. Performance Benefits Squashed SVOs lead to very significant performance benefits. For instance, when storing our Ragged Cluster model voxel-by-voxel in our SVO, this took: for a regular SVO: 1700-1800 ms for a squashed SVO: 1048-1288 ms It would be a realistic estimate to say that a 100% speedup is possible. Spatial Costs The costs of one squash are almost neglegible. For instance, our Ragged Cluster model requires: for a regular SVO: 50,467,464 node bits in single-bit format for a squashed SVO: 50,566,592 node bits in single-bit format That is a mere 0.196% increase in bits. However, while by a slim margin, a tetrahexacontree will almost always perform slightly worse: Best Case for Regular Octrees In the best case which is an entirely empty node, an octree requires only one byte of space to encode that each of the 8 child-nodes are empty. A tetrahexacontree will however require eight times the space, meaning 64 bits that are all 0 . However, octrees are very good at trimming away large empty volumes. For our Ragged Cluser , the average sub-branch count was 6.901 , meaning that in each node we would most likely see 7 out of 8 bits set. So this best case is rarely encountered. Best Case for Squashed Octrees The only case where a squashed octree is more efficient than a regular octree is the case where all sub-branches exist. This would be one root-node and 8 branches for a regular octree. Thanks to the squash, this this would only be a single node for a tetrahexacontree, but eight times as large. For our Ragged Cluser , the average squashed sub-branch count was 35.78 . So we are far from encountering this completely-filled case. Squashing More than One Layer In principle we squash even more layers, to receive a tree with a branching factor of 512 and higher. However, we would not receive architectural benefits anymore and would lose out on even more compression efficiency. Conclusion Tetrahexacontrees provide nearly identical spatial costs while providing a very significant performance improvement. This result does have broad implications for the use of octrees in computer graphics in general. Many ray casting algorithms would likely benefits from higher branching factors. In our case, we will follow the example of the VOLA file format and use a higher branching factor in our encoding scheme. Depends on how much space is pre-allocated before the insertion of any voxels. Other data structures consume no space for such a pre-allocation. \u21a9","title":"Sparse Voxel Octree"},{"location":"svo/svo.html#sparse-voxel-octree","text":"An Octree - Source: Wikipedia , WhiteTimberwolf A sparse voxel octree is a data structure which stores voxels in a tree with a branching factor of 8, with its branches being potentially absent. Missing branches typically represent empty volumes where no voxels exist. The greater empty volumes are, the closer to the root can their corresponding subtrees be pruned. This results in a very efficient representation of models with a significant portion of empty space. Unlike with a voxel list, all positioning is implicit and results from the tree structure, meaning that no space has to be used for the storage of coordinates during serialization. Thus, octrees combine the two greatest advantages of voxel lists and voxel arrays: like lists, they waste little space on encoding empty voxels like for arrays, voxel coordinates are implicit and little space is wasted","title":"Sparse Voxel Octree"},{"location":"svo/svo.html#extreme-cases-and-limits","text":"To illustrate the following extreme cases, voxel arrays and voxel lists are also compared. The space complexity of three extreme cases is compared between the three data structures, where v is the amount of voxels. Voxel Array Voxel List Sparse Voxel Octree Empty O(1) 1 O(1) O(1) Tightly Filled O(v) O(4v) O(\\frac{8}{7} v) Stretched O(\\infty) O(1) O(\\infty)","title":"Extreme Cases And Limits"},{"location":"svo/svo.html#empty-octree","text":"Entirely empty models can be encoded using just the root note, which then encodes that no subtrees exist.","title":"Empty Octree"},{"location":"svo/svo.html#tightly-filled-octree","text":"Entirely filled models will have some overhead compared to an array of voxels. For every eight nodes, there is one parent node. We can calculate the maximum possible overhead by summing up this \\frac{1}{8} overhead infinitely: \\sum_{n=1}^\\infty{\\frac{1}{8}^n} = \\frac{1}{7} So at worst, our data will increase by \\frac{1}{7} , which is much better than a 100% increase such as for binary trees.","title":"Tightly Filled Octree"},{"location":"svo/svo.html#stretched-octree","text":"The stretched case is a case where a finite amount of voxels are placed infinitely far apart. For arrays, this produces infinite space requirements because all space between these points must be filled. For octrees, more layers are necessary to encode positions further from the origin. In neither case there is an upper bound to this. In practice, octrees perform significantly better at encoding sparse data than arrays.","title":"Stretched Octree"},{"location":"svo/svo.html#construction","text":"How an octree can be constructed from a list voxels is thorougly explained in SVO Construction .","title":"Construction"},{"location":"svo/svo.html#serialization","text":"Figure 0: A Sparse Voxel Octree, encoded in memory To be used in a serial data format, octrees must first be serialized. Nodes will no longer be laid out freely in memory but instead be arranged one after another. To fully encode an SVO, two steps must be performed: Linearize nodes by traversing the SVO's nodes in a deterministic, reversible order. Serialize each node to binary data.","title":"Serialization"},{"location":"svo/svo.html#traversal-order","text":"There are two well-known strategies for traversing trees completely: Depth-First Search (DFS) Breadth-First Search (BFS)","title":"Traversal Order"},{"location":"svo/svo.html#depth-first","text":"Figure 1: Tree, traversed depth-first DFS can be performed using only a stack to keep track of the node number at each level. On the deepest level, the next node is chosen until the end is reached and the next parent node is chosen. This low memory cost (which is in fact O(\\log{n}) where n is the number of nodes) is highly advantageous when encoding enormous models.","title":"Depth-First"},{"location":"svo/svo.html#breadth-first","text":"Figure 2: Tree, traversed breadth-first BFS comes with a higher cost since a typical algorithm appends all branches to a queue for every traversed node. This means that in the worst case, which is at the beginning of serialization eight nodes are appended on every level before any node is popped from the queue, resulting in a higher memory cost.","title":"Breadth-First"},{"location":"svo/svo.html#why-to-serialize-octrees-depth-first","text":"Figure 3: A serialized octree, depth-first The scheme more practical for encoding octrees is depth-first. This is due to the fact that only a stack is necessary to keep track of the current position. The size or depth of the octree would need to double in all dimensions to necessitate a stack greater by one element. Overall, this is a very low memory profile. For breadth first, we would always load information about the entire next deeper layer into our queue, then move on. To be fair, this does allow us to discard the previous layer entirely once we move deeper, but the memory cost is still unnecessarily high.","title":"Why To Serialize Octrees Depth-First"},{"location":"svo/svo.html#node-encoding","text":"In the above graphs, the 1-bit encoding was demonstrated due to its simplicity. However, there is a variety of different encodings to choose from.","title":"Node Encoding"},{"location":"svo/svo.html#single-bit-format","text":"0 stands for air-subtree 1 stands for partially or entirely filled voxel-subtree 8 Bits per octree-node, thus this format is byte-aligned.","title":"Single-Bit Format"},{"location":"svo/svo.html#2-bit-format","text":"00 stands for air-subtree 01 stands for solid subtree 10 stands for partially filled subtree 11 variable purpose","title":"2-Bit Format"},{"location":"svo/svo.html#15-bit-format","text":"00 stands for air-subtree 01 stands for solid subtree 1 stands for partially filled subtree Variable amount of bits per octree-node, neither bit- nor byte-aligned. On the last level (node = voxel), the single-bit format is used because there are no subtrees.","title":"1.5-Bit Format"},{"location":"svo/svo.html#11-for-rawarray-subtrees","text":"Useful to encode subtrees completely filled with high-entropy content. On the second-to-last level, 11 for raw-subtrees there is no difference between 10 and 11 , so reverting to the 1.5-bit format is viable. On the last level, the single-bit format should be used. As long as the 1.5-bit format is not used, this encoding is completely byte-aligned: * alignment to 16 -bit boundaries on most levels * alignment to 8 -bit boundaries on last level","title":"11 for Raw/Array Subtrees"},{"location":"svo/svo.html#11-for-pointers-to-subtrees-on-the-same-level","text":"Useful for encoding multiple similar subtrees. Similarities between structures could be effectively exploited. Verifying whether subtrees are equal down to the base level has very high complexity: O(n^2 * 8^n) . The comparison depth could be reduced down to a limited number of levels or the level number could be encoded next to the pointer: {u32 indexOfOtherTree, u8 depth} . Instead of the pointer, a tree could instead encode all the places where it is additionally used. This would make decoding easier, since remembering trees on the same level is not necessary.","title":"11 for Pointers to Subtrees on the Same Level"},{"location":"svo/svo.html#degenerate-cases","text":"If you paid close attention to Figure 1 and Figure 3 , you will have noticed that they contain a 00000000 node. Such nodes can in principle exist, but are a waste of space. After all, they could be trimmed away one layer above by simply encoding a 0 -bit. This nonsensical nature is why they are considered to be a degenerate case . Such cases can however be useful. They offer a natural escape sequence from the regular encoding of an SVO. They could offer special functionality as seen in 3.2.3 to the single-bit format, which does not have any unused values.","title":"Degenerate Cases"},{"location":"svo/svo.html#squashed-octrees","text":"Figure 5: A squashed Octree (compare to Figure 0) A squashed octree is an octree where two or more layers of the tree have been combined into a single layer. By squashing an octree once, we receive a tetrahexacontree. This term comes from \"tetrahexaconta\" (Greek for 64) and \"tree\". It builds on the idea of octrees but expands the branching factor from 8 to 8 2 , or 64. In almost all regards, a squashed octree is implemented identically to a regular octree. However, we divide space into a 4x4x4 cube instead of a 2x2x2 cube with each layer.","title":"Squashed Octrees"},{"location":"svo/svo.html#motivation","text":"When serializing or deserializing an octree, we must do so node by node. This involves generating a bitmask (see above sections on node encoding). For a tetrahexacontree and under use of the 1-bit format, we fill exactly one CPU register on a 64-bit architecture with our nodes. With a regular octree, we would waste all but eight bits. 64-bit architectures established themselves as the de-facto standard for desktop operating systems. Anecdotally, \"macOS Mojave would be the last version of macOS to run 32-bit apps\" - Apple . Thus, optimization of algorithms in the present day can be performed for 64-bit architectures without worrying about 32-bit users. A use of this concept can be seen in the VOLA file format. VOLA uses a 1-bit format for its nodes while squashing two layers into one. So VOLA uses a tetrahexacontree. Unfortunately the paper fails to mention how performance and compression efficiency can be gained or lost this way. Therefore, we run our own tests in the following subsections.","title":"Motivation"},{"location":"svo/svo.html#performance-benefits","text":"Squashed SVOs lead to very significant performance benefits. For instance, when storing our Ragged Cluster model voxel-by-voxel in our SVO, this took: for a regular SVO: 1700-1800 ms for a squashed SVO: 1048-1288 ms It would be a realistic estimate to say that a 100% speedup is possible.","title":"Performance Benefits"},{"location":"svo/svo.html#spatial-costs","text":"The costs of one squash are almost neglegible. For instance, our Ragged Cluster model requires: for a regular SVO: 50,467,464 node bits in single-bit format for a squashed SVO: 50,566,592 node bits in single-bit format That is a mere 0.196% increase in bits. However, while by a slim margin, a tetrahexacontree will almost always perform slightly worse:","title":"Spatial Costs"},{"location":"svo/svo.html#best-case-for-regular-octrees","text":"In the best case which is an entirely empty node, an octree requires only one byte of space to encode that each of the 8 child-nodes are empty. A tetrahexacontree will however require eight times the space, meaning 64 bits that are all 0 . However, octrees are very good at trimming away large empty volumes. For our Ragged Cluser , the average sub-branch count was 6.901 , meaning that in each node we would most likely see 7 out of 8 bits set. So this best case is rarely encountered.","title":"Best Case for Regular Octrees"},{"location":"svo/svo.html#best-case-for-squashed-octrees","text":"The only case where a squashed octree is more efficient than a regular octree is the case where all sub-branches exist. This would be one root-node and 8 branches for a regular octree. Thanks to the squash, this this would only be a single node for a tetrahexacontree, but eight times as large. For our Ragged Cluser , the average squashed sub-branch count was 35.78 . So we are far from encountering this completely-filled case.","title":"Best Case for Squashed Octrees"},{"location":"svo/svo.html#squashing-more-than-one-layer","text":"In principle we squash even more layers, to receive a tree with a branching factor of 512 and higher. However, we would not receive architectural benefits anymore and would lose out on even more compression efficiency.","title":"Squashing More than One Layer"},{"location":"svo/svo.html#conclusion","text":"Tetrahexacontrees provide nearly identical spatial costs while providing a very significant performance improvement. This result does have broad implications for the use of octrees in computer graphics in general. Many ray casting algorithms would likely benefits from higher branching factors. In our case, we will follow the example of the VOLA file format and use a higher branching factor in our encoding scheme. Depends on how much space is pre-allocated before the insertion of any voxels. Other data structures consume no space for such a pre-allocation. \u21a9","title":"Conclusion"}]}